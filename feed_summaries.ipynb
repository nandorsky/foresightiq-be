{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a654c78a-4f90-42d8-957e-13c27d10b9f4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2729a59-0c22-4b65-b917-08882bc68bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b0ddb4-9def-47de-ad84-b644a29cdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished running signals feed at 2026-02-09 09:09:52\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ Finished running signals feed at \"\n",
    "    f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208407e3-ae44-4c16-bd6c-f0b8e2a98ba5",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16d06d5-7dfc-44fc-bbfd-85a809f3b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import anthropic\n",
    "from anthropic import AsyncAnthropic\n",
    "import pyperclip\n",
    "from supabase import create_client, Client\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import math\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from playwright.sync_api import sync_playwright\n",
    "import json5\n",
    "import ast\n",
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Supabase API\n",
    "SUPABASE_URL = os.environ[\"SUPABASE_URL\"]\n",
    "SUPABASE_KEY = os.environ[\"SUPABASE_KEY\"]\n",
    "SERVICE_ROLE_KEY = os.environ[\"SUPABASE_SERVICE_ROLE_KEY\"]\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SERVICE_ROLE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c27c25-dc11-4073-b2f9-1fc49ec40f0f",
   "metadata": {},
   "source": [
    "## Clean up JSON function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1c6e68-9f7b-4c0d-8ebd-1c3a78b23c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_loads(x):\n",
    "    if not isinstance(x, str):\n",
    "        return x\n",
    "    \n",
    "    # Fix invalid \\uXXXX escapes ‚Äî replace with a safe placeholder\n",
    "    x = re.sub(r'\\\\u(?![0-9a-fA-F]{4})', r'\\\\uFFFF', x)\n",
    "\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå JSON decode failed:\", e)\n",
    "        print(\"Offending value:\", x[:300])\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ff821-0403-4f8f-82a3-372bdb8f143b",
   "metadata": {},
   "source": [
    "## Initiate AI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f800c9d-9e25-4e07-ba40-29061c10ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_MODEL = \"claude-haiku-4-5-20251001\"\n",
    "OPENAI_MODEL = \"gpt-5-mini\"\n",
    "\n",
    "# OpenAI key\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Anthropic\n",
    "anthropic_api_key = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_api_key,\n",
    ")\n",
    "\n",
    "# Gemini Key\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "# System prompt\n",
    "system = f\"\"\"\n",
    "\n",
    "You are a research analyst doing competitive intelligence research for a client.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f82aac-10fd-42de-a4ec-f1b437407de2",
   "metadata": {},
   "source": [
    "# Grab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9db8da-2b32-42f7-8fc7-beaedf277308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 5388 rows from news_feed.\n",
      "‚úÖ Retrieved 3897 rows from linkedin_feed.\n",
      "‚úÖ Retrieved 508 rows from reddit_posts.\n",
      "‚úÖ Retrieved 2561 rows from jobs.\n",
      "‚úÖ Retrieved 4564 rows from ad_library.\n",
      "‚úÖ Retrieved 12 rows from companies.\n",
      "‚úÖ Retrieved 60 rows from competitors.\n",
      "‚úÖ Retrieved 140 rows from feed_summaries.\n"
     ]
    }
   ],
   "source": [
    "def fetch_all_rows(table, filters=None, batch_size=1000):\n",
    "    all_rows = []\n",
    "    start = 0\n",
    "\n",
    "    while True:\n",
    "        query = supabase.table(table).select(\"*\").order(\"id\", desc=True)\n",
    "\n",
    "        # Apply filters if provided\n",
    "        if filters:\n",
    "            for col, val in filters.items():\n",
    "                if isinstance(val, list):\n",
    "                    query = query.in_(col, val)\n",
    "                else:\n",
    "                    query = query.eq(col, val)\n",
    "\n",
    "        # Pagination block\n",
    "        query = query.range(start, start + batch_size - 1)\n",
    "\n",
    "        resp = query.execute()\n",
    "        data = resp.data or []\n",
    "        all_rows.extend(data)\n",
    "\n",
    "        # Stop if fewer than batch_size returned\n",
    "        if len(data) < batch_size:\n",
    "            break\n",
    "\n",
    "        start += batch_size\n",
    "\n",
    "    return all_rows\n",
    "\n",
    "tables = [\"news_feed\", \"linkedin_feed\", \"reddit_posts\", \"jobs\", \"ad_library\", \"companies\", \"competitors\", \"feed_summaries\"]\n",
    "feeds = {}\n",
    "\n",
    "for table in tables:\n",
    "    # Apply filters only for content tables\n",
    "    if table not in [\"companies\", \"competitors\", \"feed_summaries\"]:\n",
    "        filters = {\n",
    "            \"relevant\": True,\n",
    "            # \"processed\": False\n",
    "        }\n",
    "    else:\n",
    "        filters = None\n",
    "\n",
    "    rows = fetch_all_rows(table, filters=filters)\n",
    "    feeds[table] = pd.DataFrame(rows)\n",
    "\n",
    "    print(f\"‚úÖ Retrieved {len(rows)} rows from {table}.\" if rows else f\"‚ö†Ô∏è No rows in {table}.\")\n",
    "\n",
    "# ---------- Assign DataFrames ----------\n",
    "news_feed = feeds[\"news_feed\"]\n",
    "linkedin_feed = feeds[\"linkedin_feed\"]\n",
    "reddit_posts = feeds[\"reddit_posts\"]\n",
    "jobs = feeds[\"jobs\"]\n",
    "ads = feeds[\"ad_library\"]\n",
    "\n",
    "feed_summaries = feeds[\"feed_summaries\"]\n",
    "companies = feeds[\"companies\"]\n",
    "competitors = feeds[\"competitors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbecf17-1911-4831-ace9-70b99dbedf0e",
   "metadata": {},
   "source": [
    "# Combine data feeds into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351526e9-0651-4858-8a67-3d7c5b45964a",
   "metadata": {},
   "source": [
    "## Add company id to dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e6412bd-544e-4d86-8d32-200e591af29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ids added to dataframes...\n"
     ]
    }
   ],
   "source": [
    "# Merge company status into competitors\n",
    "competitors_with_status = competitors.merge(\n",
    "    companies[[\"id\", \"status\"]],\n",
    "    left_on=\"company_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_company\")\n",
    ")\n",
    "\n",
    "# Build lookup\n",
    "competitor_lookup = competitors_with_status.set_index(\"id\")[[\"company_id\", \"competitor_name\", \"status\"]].to_dict(orient=\"index\")\n",
    "\n",
    "def append_company_and_competitor(df):\n",
    "    # üß§ Handle empty DataFrame early\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è DataFrame is empty ‚Äî skipping append.\")\n",
    "        return df\n",
    "\n",
    "    if \"competitor_id\" not in df.columns:\n",
    "        print(\"‚ö†Ô∏è No 'competitor_id' column ‚Äî skipping append.\")\n",
    "        return df\n",
    "\n",
    "    df[\"company_id\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"company_id\", 0))\n",
    "    df[\"competitor_name\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"competitor_name\", \"Unknown\"))\n",
    "    df[\"status\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"status\", \"Unknown\"))\n",
    "    df[\"company_id\"] = df[\"company_id\"].astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "# Apply to feeds\n",
    "news_feed = append_company_and_competitor(news_feed)\n",
    "linkedin_feed = append_company_and_competitor(linkedin_feed)\n",
    "jobs = append_company_and_competitor(jobs)\n",
    "ads = append_company_and_competitor(ads)\n",
    "print(f\"Company ids added to dataframes...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f376152-5f11-408c-9dc7-50cf66d9e5d7",
   "metadata": {},
   "source": [
    "## Convert news feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76976c1-0c36-4a6d-a2c9-11fabd9dd7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>published_date</th>\n",
       "      <th>push_to_feed</th>\n",
       "      <th>relevance_descrip</th>\n",
       "      <th>relevant</th>\n",
       "      <th>processed</th>\n",
       "      <th>content</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>insight</th>\n",
       "      <th>company_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>display_date</th>\n",
       "      <th>competitor_name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63752</td>\n",
       "      <td>2026-02-09T11:01:22.955102+00:00</td>\n",
       "      <td>Brooks Nader‚Äôs DoorDash Ad Has Alix Earle Sayi...</td>\n",
       "      <td>https://www.yahoo.com/entertainment/celebrity/...</td>\n",
       "      <td>Brooks Nader's latest ad for DoorDash has ever...</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2026-02-07T13:15:45+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Ad featuring DoorDash</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Powered by Yahoo Scout. Yahoo is using AI to g...</td>\n",
       "      <td>https://news.google.com/api/attachments/CC8iK0...</td>\n",
       "      <td>DoorDash continues to enhance brand visibility...</td>\n",
       "      <td>66</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>2026-02-07</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>trial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        created_at  \\\n",
       "0  63752  2026-02-09T11:01:22.955102+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Brooks Nader‚Äôs DoorDash Ad Has Alix Earle Sayi...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.yahoo.com/entertainment/celebrity/...   \n",
       "\n",
       "                                         description  competitor_id  \\\n",
       "0  Brooks Nader's latest ad for DoorDash has ever...          158.0   \n",
       "\n",
       "              published_date push_to_feed      relevance_descrip  relevant  \\\n",
       "0  2026-02-07T13:15:45+00:00         None  Ad featuring DoorDash      True   \n",
       "\n",
       "   processed                                            content  \\\n",
       "0      False  Powered by Yahoo Scout. Yahoo is using AI to g...   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  https://news.google.com/api/attachments/CC8iK0...   \n",
       "\n",
       "                                             insight  company_id publisher  \\\n",
       "0  DoorDash continues to enhance brand visibility...          66     Yahoo   \n",
       "\n",
       "  display_date competitor_name status  \n",
       "0   2026-02-07        DoorDash  trial  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_feed.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55159bcd-8529-499e-b947-ae92b7a0c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Newsfeed content converted to json for 5388 records.\n"
     ]
    }
   ],
   "source": [
    "news_feed_json = pd.DataFrame()\n",
    "\n",
    "if news_feed is not None and not news_feed.empty:\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [\"id\", \"competitor_id\", \"company_id\", \"url\", \"title\", \"content\", \"description\"]\n",
    "    missing_cols = [col for col in required_cols if col not in news_feed.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in news_feed: {missing_cols}\")\n",
    "    else:\n",
    "        news_feed_json[\"id\"] = news_feed[\"id\"]\n",
    "        news_feed_json[\"competitor_id\"] = news_feed[\"competitor_id\"]\n",
    "        news_feed_json[\"company_id\"] = news_feed[\"company_id\"]\n",
    "        news_feed_json[\"content\"] = news_feed[\"content\"]\n",
    "        news_feed_json[\"display_date\"] = news_feed[\"display_date\"]\n",
    "        news_feed_json[\"source\"] = \"news\"\n",
    "\n",
    "        news_feed_json[\"content_json\"] = news_feed.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                # \"content\": row[\"content\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"news\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Newsfeed content converted to json for {len(news_feed_json)} records.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è news_feed is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532da676-44ee-41e2-94e5-878924e9d27b",
   "metadata": {},
   "source": [
    "## Convert linkedin feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e550f47-2398-494a-aaa4-88f778688440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>postUrl</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_fullName</th>\n",
       "      <th>author_profile_pic</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>postedDate</th>\n",
       "      <th>...</th>\n",
       "      <th>alert_response</th>\n",
       "      <th>processed</th>\n",
       "      <th>relevant</th>\n",
       "      <th>relevance_descrip</th>\n",
       "      <th>insight</th>\n",
       "      <th>push_to_feed</th>\n",
       "      <th>display_date</th>\n",
       "      <th>company_id</th>\n",
       "      <th>competitor_name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30362</td>\n",
       "      <td>2026-02-09T11:05:19.833765+00:00</td>\n",
       "      <td>https://www.linkedin.com/posts/louise-wills-09...</td>\n",
       "      <td>83358831.0</td>\n",
       "      <td>Organizations that are deploying specialized A...</td>\n",
       "      <td>Louise Wills</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/C5603AQFF...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>Helping my customers to be the best that they ...</td>\n",
       "      <td>2026-02-09T00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AI adoption related to health</td>\n",
       "      <td>Emphasis on investment in AI roles accelerates...</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>23</td>\n",
       "      <td>Oracle Health</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        created_at  \\\n",
       "0  30362  2026-02-09T11:05:19.833765+00:00   \n",
       "\n",
       "                                             postUrl   author_id  \\\n",
       "0  https://www.linkedin.com/posts/louise-wills-09...  83358831.0   \n",
       "\n",
       "                                                text author_fullName  \\\n",
       "0  Organizations that are deploying specialized A...    Louise Wills   \n",
       "\n",
       "                                  author_profile_pic  competitor_id  \\\n",
       "0  https://media.licdn.com/dms/image/v2/C5603AQFF...          152.0   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Helping my customers to be the best that they ...   \n",
       "\n",
       "                  postedDate  ... alert_response processed  relevant  \\\n",
       "0  2026-02-09T00:00:00+00:00  ...           None     False      True   \n",
       "\n",
       "               relevance_descrip  \\\n",
       "0  AI adoption related to health   \n",
       "\n",
       "                                             insight push_to_feed  \\\n",
       "0  Emphasis on investment in AI roles accelerates...         None   \n",
       "\n",
       "  display_date company_id  competitor_name  status  \n",
       "0   2026-02-09         23    Oracle Health  active  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_feed.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37e2b0a-b0e2-4061-a0d0-3d449dcc511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Linkedin content converted to json...\n"
     ]
    }
   ],
   "source": [
    "linkedin_feed_json = pd.DataFrame()\n",
    "\n",
    "if linkedin_feed is not None and not linkedin_feed.empty:\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [\"id\", \"competitor_id\", \"author_fullName\", \"text\", \"postUrl\"]\n",
    "    missing_cols = [col for col in required_cols if col not in linkedin_feed.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in linkedin_feed: {missing_cols}\")\n",
    "    else:\n",
    "        linkedin_feed_json[\"id\"] = linkedin_feed[\"id\"]\n",
    "        linkedin_feed_json[\"competitor_id\"] = linkedin_feed[\"competitor_id\"]\n",
    "        linkedin_feed_json[\"company_id\"] = linkedin_feed[\"company_id\"]\n",
    "        linkedin_feed_json[\"display_date\"] = linkedin_feed[\"display_date\"]\n",
    "        linkedin_feed_json[\"source\"] = \"linkedin\"\n",
    "\n",
    "        linkedin_feed_json[\"content_json\"] = linkedin_feed.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"author_fullName\": row[\"author_fullName\"],\n",
    "                \"text\": row[\"text\"],\n",
    "                \"url\": row[\"postUrl\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"linkedin\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"‚úÖ Linkedin content converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è linkedin_feed is empty ‚Äî skipping JSON conversion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b6383-0bf7-4514-9df9-7a65b712b1e9",
   "metadata": {},
   "source": [
    "## Convert reddit feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee6efa3-d6c7-46a8-ab5b-057daa367b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>post_created_utc</th>\n",
       "      <th>post_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>relevant</th>\n",
       "      <th>post_selftext</th>\n",
       "      <th>post_author</th>\n",
       "      <th>push_to_feed</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>processed</th>\n",
       "      <th>relevance_descrip</th>\n",
       "      <th>insight</th>\n",
       "      <th>display_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26796</td>\n",
       "      <td>2026-02-09T11:17:17.220735+00:00</td>\n",
       "      <td>[For Hire] HealthTech dev team ready to suppor...</td>\n",
       "      <td>https://www.reddit.com/r/HealthTech/comments/1...</td>\n",
       "      <td>2026-02-09T09:06:30+00:00</td>\n",
       "      <td>1qzzfz7</td>\n",
       "      <td>23</td>\n",
       "      <td>healthtech</td>\n",
       "      <td>True</td>\n",
       "      <td>Hi everyone,\\n\\nI work with a HealthTech-focus...</td>\n",
       "      <td>Feisty_Honeydew_2866</td>\n",
       "      <td>None</td>\n",
       "      <td>[healthtech]</td>\n",
       "      <td>False</td>\n",
       "      <td>Discusses EHR integrations, relevant expertise</td>\n",
       "      <td>EHR integrations and AI-driven workflows are k...</td>\n",
       "      <td>2026-02-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        created_at  \\\n",
       "0  26796  2026-02-09T11:17:17.220735+00:00   \n",
       "\n",
       "                                          post_title  \\\n",
       "0  [For Hire] HealthTech dev team ready to suppor...   \n",
       "\n",
       "                                            post_url  \\\n",
       "0  https://www.reddit.com/r/HealthTech/comments/1...   \n",
       "\n",
       "            post_created_utc  post_id  company_id   subreddit  relevant  \\\n",
       "0  2026-02-09T09:06:30+00:00  1qzzfz7          23  healthtech      True   \n",
       "\n",
       "                                       post_selftext           post_author  \\\n",
       "0  Hi everyone,\\n\\nI work with a HealthTech-focus...  Feisty_Honeydew_2866   \n",
       "\n",
       "  push_to_feed matched_keywords  processed  \\\n",
       "0         None     [healthtech]      False   \n",
       "\n",
       "                                relevance_descrip  \\\n",
       "0  Discusses EHR integrations, relevant expertise   \n",
       "\n",
       "                                             insight display_date  \n",
       "0  EHR integrations and AI-driven workflows are k...   2026-02-09  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_posts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf36fa8-c052-4c7b-8650-b80fe3043057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 508 Reddit records converted...\n"
     ]
    }
   ],
   "source": [
    "reddit_posts_json = pd.DataFrame()\n",
    "\n",
    "if reddit_posts is not None and not reddit_posts.empty:\n",
    "    required_cols = [\"id\", \"company_id\", \"post_selftext\", \"post_url\"]\n",
    "    missing_cols = [col for col in required_cols if col not in reddit_posts.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in reddit_posts: {missing_cols}\")\n",
    "    else:\n",
    "        reddit_posts_json[\"id\"] = reddit_posts[\"id\"]\n",
    "        reddit_posts_json[\"competitor_id\"] = reddit_posts[\"company_id\"]\n",
    "        reddit_posts_json[\"company_id\"] = reddit_posts[\"company_id\"]\n",
    "        reddit_posts_json[\"display_date\"] = reddit_posts[\"display_date\"]\n",
    "        reddit_posts_json[\"source\"] = \"reddit\"\n",
    "\n",
    "        reddit_posts_json[\"content_json\"] = reddit_posts.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"text\": row[\"post_selftext\"],\n",
    "                \"url\": row[\"post_url\"],\n",
    "                \"competitor_id\": row[\"company_id\"],\n",
    "                \"company_id\": row[\"company_id\"],\n",
    "                \"source\": \"reddit\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(reddit_posts_json)} Reddit records converted...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è reddit_posts is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4eed56-3eea-428a-8b75-d46d51160223",
   "metadata": {},
   "source": [
    "## Convert jobs feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "233cfeb9-ce29-4e3d-aeb7-1a6e847bfe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>job_id</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>postedAt</th>\n",
       "      <th>key_insights</th>\n",
       "      <th>push_to_feed</th>\n",
       "      <th>processed</th>\n",
       "      <th>relevant</th>\n",
       "      <th>relevance_descrip</th>\n",
       "      <th>insight</th>\n",
       "      <th>display_date</th>\n",
       "      <th>company_id</th>\n",
       "      <th>competitor_name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9214</td>\n",
       "      <td>2026-02-09T11:05:31.776446+00:00</td>\n",
       "      <td>Territory Sales Representative / Restaurant Sp...</td>\n",
       "      <td>About SpotOn We‚Äôre not just building restauran...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4368047543/</td>\n",
       "      <td>None</td>\n",
       "      <td>157</td>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Job related to restaurant services</td>\n",
       "      <td>SpotOn emphasizes high-touch service to boost ...</td>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>66</td>\n",
       "      <td>SpotOn</td>\n",
       "      <td>trial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                        created_at  \\\n",
       "0  9214  2026-02-09T11:05:31.776446+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Territory Sales Representative / Restaurant Sp...   \n",
       "\n",
       "                                         description  \\\n",
       "0  About SpotOn We‚Äôre not just building restauran...   \n",
       "\n",
       "                                              url job_id  competitor_id  \\\n",
       "0  https://www.linkedin.com/jobs/view/4368047543/   None            157   \n",
       "\n",
       "     postedAt key_insights push_to_feed  processed  relevant  \\\n",
       "0  2026-02-02         None         None      False      True   \n",
       "\n",
       "                    relevance_descrip  \\\n",
       "0  Job related to restaurant services   \n",
       "\n",
       "                                             insight display_date  company_id  \\\n",
       "0  SpotOn emphasizes high-touch service to boost ...   2026-02-02          66   \n",
       "\n",
       "  competitor_name status  \n",
       "0          SpotOn  trial  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1639e13-5c54-472e-a110-a40eeabdf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 2561 job postings converted to json...\n"
     ]
    }
   ],
   "source": [
    "jobs_json = pd.DataFrame()\n",
    "\n",
    "if jobs is not None and not jobs.empty:\n",
    "    required_cols = [\"id\", \"competitor_id\", \"company_id\", \"title\", \"description\", \"url\"]\n",
    "    missing_cols = [col for col in required_cols if col not in jobs.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in jobs: {missing_cols}\")\n",
    "    else:\n",
    "        jobs_json[\"id\"] = jobs[\"id\"]\n",
    "        jobs_json[\"competitor_id\"] = jobs[\"competitor_id\"]\n",
    "        jobs_json[\"company_id\"] = jobs[\"company_id\"]\n",
    "        jobs_json[\"display_date\"] = jobs[\"display_date\"]\n",
    "        jobs_json[\"source\"] = \"jobs\"\n",
    "\n",
    "        jobs_json[\"content_json\"] = jobs.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"jobs\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(jobs_json)} job postings converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è jobs is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea185e4-b01a-4216-982d-7a2414a735f8",
   "metadata": {},
   "source": [
    "## Convert ads feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e4ac2b6-660d-415d-b0d1-784bf90b4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 4564 ads converted to json...\n"
     ]
    }
   ],
   "source": [
    "ads_json = pd.DataFrame()\n",
    "\n",
    "if ads is not None and not ads.empty:\n",
    "    required_cols = [\"id\", \"competitor_id\", \"json_response\", ]\n",
    "    missing_cols = [col for col in required_cols if col not in ads.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in jobs: {missing_cols}\")\n",
    "    else:\n",
    "        ads_json[\"id\"] = ads[\"id\"]\n",
    "        ads_json[\"competitor_id\"] = ads[\"competitor_id\"]\n",
    "        ads_json[\"company_id\"] = ads[\"company_id\"]\n",
    "        ads_json[\"display_date\"] = ads[\"display_date\"]\n",
    "        ads_json[\"source\"] = \"ads\"\n",
    "\n",
    "        ads_json[\"content_json\"] = ads.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"json_response\": row[\"json_response\"],\n",
    "                \"source\": \"ads\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(ads_json)} ads converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ads is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce2128-6410-4f7c-bc17-21b1ff8b6451",
   "metadata": {},
   "source": [
    "## Combine dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d22cd637-053c-4363-8648-5bdc9ca681b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data frame combination completed with 16918 rows created\n"
     ]
    }
   ],
   "source": [
    "data_feed_combined = pd.concat([\n",
    "    news_feed_json,\n",
    "    linkedin_feed_json,\n",
    "    reddit_posts_json,\n",
    "    jobs_json,\n",
    "    ads_json\n",
    "], ignore_index=True)\n",
    "print(f\"‚úÖ Data frame combination completed with {len(data_feed_combined)} rows created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3994a5-54b8-4b6d-a14c-02a195103fb9",
   "metadata": {},
   "source": [
    "## Add company description to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450f3113-d3a1-46d0-9a15-a335c0631d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16918\n"
     ]
    }
   ],
   "source": [
    "df = data_feed_combined.merge(\n",
    "    companies[['id', 'company_custom_prompt']],\n",
    "    left_on='company_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .drop(columns=['id_y'])\n",
    "    .rename(columns={'id_x': 'id'})\n",
    ")\n",
    "df\n",
    "data_feed_combined = df\n",
    "print(f\"{len(data_feed_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebdec4-cc5a-4af6-a211-fd05880d7193",
   "metadata": {},
   "source": [
    "## Group datafeeds together to prep for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b358c972-c702-4387-933e-7fd2664ba142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataframe grouped together with 3045 rows created...\n"
     ]
    }
   ],
   "source": [
    "data_feed = (\n",
    "    data_feed_combined\n",
    "    .groupby([\"display_date\",\"company_id\"], as_index=False)\n",
    "    .agg({\"content_json\": list})\n",
    ")\n",
    "print(f\"‚úÖ Dataframe grouped together with {len(data_feed)} rows created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ec0642-73f5-4ade-87ef-ce29a3ba8e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_date</th>\n",
       "      <th>company_id</th>\n",
       "      <th>content_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>73</td>\n",
       "      <td>[{\"content_id\": 63476, \"url\": \"https://news.ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>72</td>\n",
       "      <td>[{\"content_id\": 9135, \"title\": \"Mobile QA Auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>71</td>\n",
       "      <td>[{\"content_id\": 9165, \"title\": \"Volunteer Seni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 63617, \"url\": \"https://www.pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 63201, \"url\": \"https://www.web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>73</td>\n",
       "      <td>[{\"content_id\": 73620, \"json_response\": \"{\\\"cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>72</td>\n",
       "      <td>[{\"content_id\": 9036, \"title\": \"SEO/GEO Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>71</td>\n",
       "      <td>[{\"content_id\": 62868, \"url\": \"https://www.new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 63737, \"url\": \"https://tribune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 62995, \"url\": \"https://www.gam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     display_date  company_id  \\\n",
       "3044   2026-02-09          73   \n",
       "3043   2026-02-09          72   \n",
       "3042   2026-02-09          71   \n",
       "3041   2026-02-09          66   \n",
       "3040   2026-02-09          23   \n",
       "3039   2026-02-08          73   \n",
       "3038   2026-02-08          72   \n",
       "3037   2026-02-08          71   \n",
       "3036   2026-02-08          66   \n",
       "3035   2026-02-08          23   \n",
       "\n",
       "                                           content_json  \n",
       "3044  [{\"content_id\": 63476, \"url\": \"https://news.ci...  \n",
       "3043  [{\"content_id\": 9135, \"title\": \"Mobile QA Auto...  \n",
       "3042  [{\"content_id\": 9165, \"title\": \"Volunteer Seni...  \n",
       "3041  [{\"content_id\": 63617, \"url\": \"https://www.pro...  \n",
       "3040  [{\"content_id\": 63201, \"url\": \"https://www.web...  \n",
       "3039  [{\"content_id\": 73620, \"json_response\": \"{\\\"cr...  \n",
       "3038  [{\"content_id\": 9036, \"title\": \"SEO/GEO Specia...  \n",
       "3037  [{\"content_id\": 62868, \"url\": \"https://www.new...  \n",
       "3036  [{\"content_id\": 63737, \"url\": \"https://tribune...  \n",
       "3035  [{\"content_id\": 62995, \"url\": \"https://www.gam...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feed = data_feed.sort_values(\n",
    "    by=\"display_date\",\n",
    "    ascending=False\n",
    ")\n",
    "data_feed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5399396-f4eb-4b58-ba81-7fcb1ff48f3a",
   "metadata": {},
   "source": [
    "### Pull latest date when feed summary was last ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917732ac-493e-40b3-8654-2ecf46e8cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2026-02-06'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_date = feed_summaries[\"date\"].max()\n",
    "most_recent_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88f4e772-3789-478e-b5ca-79ed721b1e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_date</th>\n",
       "      <th>company_id</th>\n",
       "      <th>content_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>73</td>\n",
       "      <td>[{\"content_id\": 63476, \"url\": \"https://news.ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>72</td>\n",
       "      <td>[{\"content_id\": 9135, \"title\": \"Mobile QA Auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>71</td>\n",
       "      <td>[{\"content_id\": 9165, \"title\": \"Volunteer Seni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 63617, \"url\": \"https://www.pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>2026-02-09</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 63201, \"url\": \"https://www.web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>73</td>\n",
       "      <td>[{\"content_id\": 73620, \"json_response\": \"{\\\"cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>72</td>\n",
       "      <td>[{\"content_id\": 9036, \"title\": \"SEO/GEO Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>71</td>\n",
       "      <td>[{\"content_id\": 62868, \"url\": \"https://www.new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 63737, \"url\": \"https://tribune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>2026-02-08</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 62995, \"url\": \"https://www.gam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     display_date  company_id  \\\n",
       "3044   2026-02-09          73   \n",
       "3043   2026-02-09          72   \n",
       "3042   2026-02-09          71   \n",
       "3041   2026-02-09          66   \n",
       "3040   2026-02-09          23   \n",
       "3039   2026-02-08          73   \n",
       "3038   2026-02-08          72   \n",
       "3037   2026-02-08          71   \n",
       "3036   2026-02-08          66   \n",
       "3035   2026-02-08          23   \n",
       "\n",
       "                                           content_json  \n",
       "3044  [{\"content_id\": 63476, \"url\": \"https://news.ci...  \n",
       "3043  [{\"content_id\": 9135, \"title\": \"Mobile QA Auto...  \n",
       "3042  [{\"content_id\": 9165, \"title\": \"Volunteer Seni...  \n",
       "3041  [{\"content_id\": 63617, \"url\": \"https://www.pro...  \n",
       "3040  [{\"content_id\": 63201, \"url\": \"https://www.web...  \n",
       "3039  [{\"content_id\": 73620, \"json_response\": \"{\\\"cr...  \n",
       "3038  [{\"content_id\": 9036, \"title\": \"SEO/GEO Specia...  \n",
       "3037  [{\"content_id\": 62868, \"url\": \"https://www.new...  \n",
       "3036  [{\"content_id\": 63737, \"url\": \"https://tribune...  \n",
       "3035  [{\"content_id\": 62995, \"url\": \"https://www.gam...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_data_feed = data_feed[\n",
    "    data_feed[\"display_date\"] > most_recent_date\n",
    "]\n",
    "most_recent_data_feed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf9939-04c0-4dc7-937b-d7f5bb38fe5d",
   "metadata": {},
   "source": [
    "### Run through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b8b0e9e-6fcb-4a54-9560-0c83158f50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/15 (7%)\n",
      "‚úÖ Completed 2/15 (13%)\n",
      "‚úÖ Completed 3/15 (20%)\n",
      "‚úÖ Completed 4/15 (27%)\n",
      "‚úÖ Completed 5/15 (33%)\n",
      "‚úÖ Completed 6/15 (40%)\n",
      "‚úÖ Completed 7/15 (47%)\n",
      "‚úÖ Completed 8/15 (53%)\n",
      "‚úÖ Completed 9/15 (60%)\n",
      "‚úÖ Completed 10/15 (67%)\n",
      "‚úÖ Completed 11/15 (73%)\n",
      "‚úÖ Completed 12/15 (80%)\n",
      "‚úÖ Completed 13/15 (87%)\n",
      "‚úÖ Completed 14/15 (93%)\n",
      "‚úÖ Completed 15/15 (100%)\n"
     ]
    }
   ],
   "source": [
    "client = AsyncOpenAI(api_key=openai_api_key)\n",
    "MODEL_NAME = OPENAI_MODEL\n",
    "MAX_CONCURRENCY = 100\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "async def fetch_response(prompt, company_id, display_date, progress):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            text = response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for company_id {company_id}: {e}\")\n",
    "\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            done = progress[\"done\"]\n",
    "            total = progress[\"total\"]\n",
    "            print(f\"‚úÖ Completed {done}/{total} ({done/total:.0%})\")\n",
    "\n",
    "        return {\n",
    "            \"display_date\": display_date,\n",
    "            \"company_id\": company_id,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    progress = {\"done\": 0, \"total\": len(df)}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "\n",
    "You are a competitive intelligence analyst briefing C-suite executives.\n",
    "Your job is to surface signals that could affect strategic decisions in the next 30-90 days.\n",
    "Executives have 60 seconds‚Äîlead with what matters most.\n",
    "\n",
    "## Content\n",
    "Here is the content (including titles and sources):\n",
    "{row['content_json']}\n",
    "\n",
    "## Critical Grounding Rules\n",
    "- **ONLY extract insights explicitly present in the content above**\n",
    "- **ONLY use URLs provided in the content‚Äînever generate or infer URLs**\n",
    "- If the content contains fewer than 3 meaningful signals, return only what exists\n",
    "- If the content contains no actionable competitive signals, respond: \"No significant competitive signals in today's update.\"\n",
    "- Never fabricate, infer, or hallucinate sources, companies, or insights not explicitly stated\n",
    "\n",
    "## Directions\n",
    "- Extract up to THREE of the most critical competitive signals from this daily update\n",
    "- Prioritize: product launches, pricing changes, strategic pivots, market moves\n",
    "- Lead each bullet with company name, then **bold the key insight**\n",
    "- The bolded insight must be a **short headline phrase**, not a clause or sentence\n",
    "- Do NOT bold supporting detail, explanations, or qualifiers\n",
    "- Keep it to one continuous sentence‚Äîno dashes or arrows\n",
    "- The bolded insight should communicate the core \"so what\" at a glance\n",
    "- Keep bullets to **10‚Äì15 words max** (excluding source link)\n",
    "- **Consolidate related updates from the same company into one bullet**\n",
    "- If updates are unrelated, use separate bullets\n",
    "- **When referencing two companies together, use & not /** (e.g., Uber & DoorDash)\n",
    "- Drop generic updates (UX improvements, minor ops) unless they signal strategy\n",
    "- If possible provide a mix of insights from the various sources (job insights, ads, news articles, reddit threads)\n",
    "- **Always attribute the insight to where it was found**\n",
    "\n",
    "## Before responding, verify that:\n",
    "- Every bullet references content explicitly provided above\n",
    "- Every URL matches a URL from the input content\n",
    "- There are no more than 3 bullets\n",
    "- No extra lines exist outside those bullets\n",
    "\n",
    "If any bullet references external information not in the content, delete it.\n",
    "\n",
    "## Source Attribution Rules\n",
    "- Append a source reference at the end of each bullet\n",
    "- **Use ONLY URLs provided in the content above‚Äîdo not generate URLs**\n",
    "- Render the source as a **Markdown link** with a short readable label\n",
    "- If the source is an ad campaign, the hyperlink text should be the name of the channel followed by 'ad' (e.g., Facebook Ad)\n",
    "- Do not include tracking parameters or long query strings in URLs\n",
    "\n",
    "## Format\n",
    "Company **2‚Äì5 word insight in bold** with supporting detail in same sentence [Source](URL)\n",
    "\n",
    "## Good Examples\n",
    "- NYC **tip law sticks with 10%** default mandate now in effect [NYC ruling](https://www.nyc.gov/site/dca/index.page)\n",
    "- Square **sales hiring surge** with senior enterprise roles added nationwide [Job postings](https://block.com/careers)\n",
    "- ServiceTitan **Insurance Queue live** with AmeriPro Roofing as first customer for roofing claims [LinkedIn Ad](https://www.linkedin.com/ad-library/detail/1122486033)\n",
    "\n",
    "## Bad Examples\n",
    "- NYC **tip law sticks with 10% default mandate now in effect** (too many bolded words)\n",
    "- Square **ramping merchant acquisition through senior sales hires and ad spend** (bold is a clause)\n",
    "- **DoorDash** expanding retail with Hibbett (bold should be insight, not company)\n",
    "\n",
    "Provide output in markdown.\n",
    "\n",
    "        \"\"\"\n",
    "        tasks.append(\n",
    "            fetch_response(\n",
    "                prompt,\n",
    "                row[\"company_id\"],\n",
    "                row[\"display_date\"],\n",
    "                progress\n",
    "            )\n",
    "        )\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = await process_all(most_recent_data_feed)\n",
    "summaries_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fe177-4f2d-4189-b5ef-e5a7365a0760",
   "metadata": {},
   "source": [
    "# Prep data to write back to Supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc77e62-e99e-431a-abc4-f8ecf7b32ec7",
   "metadata": {},
   "source": [
    "## Send to supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9575cc15-6959-4e20-a755-aa10d84d3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete ‚Äî 15 rows inserted\n"
     ]
    }
   ],
   "source": [
    "filtered_df = summaries_df[\n",
    "    summaries_df[\"company_id\"].notna() &\n",
    "    (summaries_df[\"company_id\"] != 0)\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, row in filtered_df.iterrows():\n",
    "    rows.append({\n",
    "        \"company_id\": int(row[\"company_id\"]),\n",
    "        \"date\": row[\"display_date\"],\n",
    "        \"summary\": row[\"response\"],\n",
    "    })\n",
    "\n",
    "response = (\n",
    "    supabase\n",
    "    .table(\"feed_summaries\")\n",
    "    .insert(rows)\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "print(f\"Insert complete ‚Äî {len(rows)} rows inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fde945-12f7-4003-b0ca-87e38c1942a6",
   "metadata": {},
   "source": [
    "## Commented code to use 2.5 pro LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84bcb36b-299a-45fd-9fde-54d139813ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.generativeai as genai\n",
    "\n",
    "# genai.configure(api_key=google_api_key)\n",
    "\n",
    "# # SWITCHED TO PRO\n",
    "# MODEL_NAME = \"gemini-2.5-pro\"\n",
    "\n",
    "# MAX_CONCURRENCY = 50\n",
    "\n",
    "# semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "# lock = asyncio.Lock()\n",
    "\n",
    "# # 2. Initialize the model with JSON mode enabled\n",
    "# model = genai.GenerativeModel(\n",
    "#     model_name=MODEL_NAME,\n",
    "#     generation_config={\n",
    "#         \"temperature\": 0,\n",
    "#         \"response_mime_type\": \"text/plain\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# async def fetch_response(prompt, headline, signal_id, progress):\n",
    "#     async with semaphore:\n",
    "#         text = None\n",
    "#         try:\n",
    "#             response = await model.generate_content_async(prompt)\n",
    "#             text = response.text\n",
    "             \n",
    "#         except Exception as e:\n",
    "#             text = None\n",
    "#             print(f\"‚ö†Ô∏è Error for id {headline}: {e}\")\n",
    "\n",
    "#         async with lock:\n",
    "#             progress[\"done\"] += 1\n",
    "#             print(f\"‚úÖ Completed {progress['done']}/{progress['total']}\")\n",
    "\n",
    "#         return {\n",
    "#             \"headline\": headline,\n",
    "#             \"signal_id\" : signal_id,\n",
    "#             \"response\": text\n",
    "#         }\n",
    "\n",
    "# async def process_all(df):\n",
    "#     total = len(df)\n",
    "#     progress = {\"done\": 0, \"total\": total}\n",
    "#     tasks = []\n",
    "\n",
    "#     for _, row in df.iterrows():\n",
    "#         prompt = f\"\"\"\n",
    "#             Analyze the following content and produce a detailed competitive-intelligence extract written in clean, valid Markdown.\n",
    "#             Don't say things like \"we\" or \"our\", this is for a client, you aren't writing this as if you are part of the team.\n",
    "#             Use bullets for everything, do not number anything.\n",
    "            \n",
    "#             You are a competitive analyst extracting actionable intelligence for strategic decision-makers who need to understand:\n",
    "#             1. What the competitor is doing\n",
    "#             2. Why it matters to us\n",
    "#             3. What we should watch or do about it\n",
    "#             4. Make sure the insights are focused on the competitor(s) mentioned in the title and summary section\n",
    "            \n",
    "#             Your output must follow these formatting rules:\n",
    "#             - Use ## for all major section headings\n",
    "#             - Use standard markdown bullet points (- or *) for all lists\n",
    "#             - Keep bullets SHORT - one clear point per bullet, ideally one sentence max\n",
    "#             - Bold key phrases using **double asterisks** to enable skimming\n",
    "#             - each heading should only have 3-5 key points\n",
    "\n",
    "#             CITATION STRUCTURE - STRICT RULE\n",
    "#             When citing specific facts, quotes, or claims, you MUST use this exact format:\n",
    "            \n",
    "#             [text](URL)\n",
    "            \n",
    "#             Do NOT use any other format as it will break the frontend of the app.\n",
    "            \n",
    "#             - Example: \"Freshworks reports [15% revenue growth](https://...) during 2025 Q3.*\"\n",
    "            \n",
    "#             REQUIRED STRUCTURE (in this exact order):\n",
    "\n",
    "#             ## Overview\n",
    "            \n",
    "#             [2-3 bullet points the strategic implication, their vulnerabilities, and recommended competitive response]\n",
    "            \n",
    "#             ## What You Need to Know\n",
    "            \n",
    "#             [3-4 bullet points that captures the competitive situation, momentum, and key context]\n",
    "            \n",
    "#             ## The Threat to Watch\n",
    "\n",
    "#             - Short, punchy bullets (1-2 sentences each)\n",
    "#             - 3-5 key competitive threats or moves\n",
    "#             - Focus on impact to your business\n",
    "#             - Call out strategic bets, resource allocation, pricing/GTM tactics\n",
    "#             - Note capability gaps or weaknesses\n",
    "            \n",
    "#             ## What to Monitor\n",
    "            \n",
    "#             - Short bulleted items - one specific signal per line\n",
    "#             - 3-5 concrete, actionable monitoring points\n",
    "#             - Each should be scannable at a glance\n",
    "            \n",
    "#             ADDITIONAL GUIDANCE:\n",
    "#             - Include relevant financial metrics, growth rates, or market position data\n",
    "#             - Note product/technology bets and positioning claims\n",
    "#             - Highlight partnership or GTM initiatives\n",
    "#             - Identify execution risks or organizational challenges\n",
    "#             - Every bullet should be independently useful - no filler\n",
    "#             - Source links should be linked to the actual text inline\n",
    "#                 - Example: \"Freshworks reports [15% revenue growth](https://...) during 2025 Q3.*\"\n",
    "\n",
    "#             CITATION FORMAT (STRICT ‚Äî WRAP THE CLAIM TEXT)\n",
    "            \n",
    "#             ‚úÖ Correct:\n",
    "#             - Freshworks reports [15% revenue growth](https://...) during 2025 Q3.\n",
    "#             - Oracle is hiring to scale [a global, personalized health ecosystem](https://...)\n",
    "#             - The company launched [‚ÄúAutopilot for Finance‚Äù](https://...) for mid-market teams.\n",
    "            \n",
    "#             Aim for 250-350 words total. Optimize for speed-reading and scannability.\n",
    "            \n",
    "#             Now analyze this content:\n",
    "\n",
    "#             {row['content_json']}\n",
    "#             \"\"\"\n",
    "#         # print(prompt)\n",
    "#         tasks.append(fetch_response(prompt, row[\"headline\"], row[\"signal_id\"], progress))\n",
    "\n",
    "#     results = await asyncio.gather(*tasks)\n",
    "#     return results\n",
    "\n",
    "# signal_enrichment = await process_all(signal_content_grouped)\n",
    "# signal_enrichment_df = pd.DataFrame(signal_enrichment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
