{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a654c78a-4f90-42d8-957e-13c27d10b9f4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b0ddb4-9def-47de-ad84-b644a29cdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished running signals feed at 2026-02-06 19:22:34\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ Finished running signals feed at \"\n",
    "    f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208407e3-ae44-4c16-bd6c-f0b8e2a98ba5",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16d06d5-7dfc-44fc-bbfd-85a809f3b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import anthropic\n",
    "from anthropic import AsyncAnthropic\n",
    "import pyperclip\n",
    "from supabase import create_client, Client\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import math\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from playwright.sync_api import sync_playwright\n",
    "import json5\n",
    "import ast\n",
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Supabase API\n",
    "SUPABASE_URL = os.environ[\"SUPABASE_URL\"]\n",
    "SUPABASE_KEY = os.environ[\"SUPABASE_KEY\"]\n",
    "SERVICE_ROLE_KEY = os.environ[\"SUPABASE_SERVICE_ROLE_KEY\"]\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SERVICE_ROLE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c27c25-dc11-4073-b2f9-1fc49ec40f0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clean up JSON function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1c6e68-9f7b-4c0d-8ebd-1c3a78b23c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_loads(x):\n",
    "    if not isinstance(x, str):\n",
    "        return x\n",
    "    \n",
    "    # Fix invalid \\uXXXX escapes ‚Äî replace with a safe placeholder\n",
    "    x = re.sub(r'\\\\u(?![0-9a-fA-F]{4})', r'\\\\uFFFF', x)\n",
    "\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå JSON decode failed:\", e)\n",
    "        print(\"Offending value:\", x[:300])\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ff821-0403-4f8f-82a3-372bdb8f143b",
   "metadata": {},
   "source": [
    "## Initiate AI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f800c9d-9e25-4e07-ba40-29061c10ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_MODEL = \"claude-haiku-4-5-20251001\"\n",
    "OPENAI_MODEL = \"gpt-5-mini\"\n",
    "\n",
    "# OpenAI key\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Anthropic\n",
    "anthropic_api_key = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_api_key,\n",
    ")\n",
    "\n",
    "# Gemini Key\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "# System prompt\n",
    "system = f\"\"\"\n",
    "\n",
    "You are a research analyst doing competitive intelligence research for a client.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f82aac-10fd-42de-a4ec-f1b437407de2",
   "metadata": {},
   "source": [
    "# Grab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9db8da-2b32-42f7-8fc7-beaedf277308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 55 rows from news_feed.\n",
      "‚úÖ Retrieved 7 rows from linkedin_feed.\n",
      "‚úÖ Retrieved 4 rows from reddit_posts.\n",
      "‚úÖ Retrieved 79 rows from jobs.\n",
      "‚úÖ Retrieved 111 rows from ad_library.\n",
      "‚úÖ Retrieved 12 rows from companies.\n",
      "‚úÖ Retrieved 60 rows from competitors.\n",
      "‚úÖ Retrieved 931 rows from signals.\n"
     ]
    }
   ],
   "source": [
    "def fetch_all_rows(table, filters=None, batch_size=1000):\n",
    "    all_rows = []\n",
    "    start = 0\n",
    "\n",
    "    while True:\n",
    "        query = supabase.table(table).select(\"*\").order(\"id\", desc=True)\n",
    "\n",
    "        # Apply filters if provided\n",
    "        if filters:\n",
    "            for col, val in filters.items():\n",
    "                if isinstance(val, list):\n",
    "                    query = query.in_(col, val)\n",
    "                else:\n",
    "                    query = query.eq(col, val)\n",
    "\n",
    "        # Pagination block\n",
    "        query = query.range(start, start + batch_size - 1)\n",
    "\n",
    "        resp = query.execute()\n",
    "        data = resp.data or []\n",
    "        all_rows.extend(data)\n",
    "\n",
    "        # Stop if fewer than batch_size returned\n",
    "        if len(data) < batch_size:\n",
    "            break\n",
    "\n",
    "        start += batch_size\n",
    "\n",
    "    return all_rows\n",
    "\n",
    "tables = [\"news_feed\", \"linkedin_feed\", \"reddit_posts\", \"jobs\", \"ad_library\", \"companies\", \"competitors\", \"signals\"]\n",
    "feeds = {}\n",
    "\n",
    "for table in tables:\n",
    "    # Apply filters only for content tables\n",
    "    if table not in [\"companies\", \"competitors\", \"signals\"]:\n",
    "        filters = {\n",
    "            \"relevant\": True,\n",
    "            \"processed\": False\n",
    "        }\n",
    "    else:\n",
    "        filters = None\n",
    "\n",
    "    rows = fetch_all_rows(table, filters=filters)\n",
    "    feeds[table] = pd.DataFrame(rows)\n",
    "\n",
    "    print(f\"‚úÖ Retrieved {len(rows)} rows from {table}.\" if rows else f\"‚ö†Ô∏è No rows in {table}.\")\n",
    "\n",
    "# ---------- Assign DataFrames ----------\n",
    "news_feed = feeds[\"news_feed\"]\n",
    "linkedin_feed = feeds[\"linkedin_feed\"]\n",
    "reddit_posts = feeds[\"reddit_posts\"]\n",
    "jobs = feeds[\"jobs\"]\n",
    "ads = feeds[\"ad_library\"]\n",
    "existing_signals = feeds[\"signals\"]\n",
    "\n",
    "companies = feeds[\"companies\"]\n",
    "competitors = feeds[\"competitors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbecf17-1911-4831-ace9-70b99dbedf0e",
   "metadata": {},
   "source": [
    "# Combine data feeds into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351526e9-0651-4858-8a67-3d7c5b45964a",
   "metadata": {},
   "source": [
    "## Add company id to dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6412bd-544e-4d86-8d32-200e591af29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ids added to dataframes...\n"
     ]
    }
   ],
   "source": [
    "# Merge company status into competitors\n",
    "competitors_with_status = competitors.merge(\n",
    "    companies[[\"id\", \"status\"]],\n",
    "    left_on=\"company_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_company\")\n",
    ")\n",
    "\n",
    "# Build lookup\n",
    "competitor_lookup = competitors_with_status.set_index(\"id\")[[\"company_id\", \"competitor_name\", \"status\"]].to_dict(orient=\"index\")\n",
    "\n",
    "def append_company_and_competitor(df):\n",
    "    # üß§ Handle empty DataFrame early\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è DataFrame is empty ‚Äî skipping append.\")\n",
    "        return df\n",
    "\n",
    "    if \"competitor_id\" not in df.columns:\n",
    "        print(\"‚ö†Ô∏è No 'competitor_id' column ‚Äî skipping append.\")\n",
    "        return df\n",
    "\n",
    "    df[\"company_id\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"company_id\", 0))\n",
    "    df[\"competitor_name\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"competitor_name\", \"Unknown\"))\n",
    "    df[\"status\"] = df[\"competitor_id\"].map(lambda x: competitor_lookup.get(x, {}).get(\"status\", \"Unknown\"))\n",
    "    df[\"company_id\"] = df[\"company_id\"].astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "# Apply to feeds\n",
    "news_feed = append_company_and_competitor(news_feed)\n",
    "linkedin_feed = append_company_and_competitor(linkedin_feed)\n",
    "jobs = append_company_and_competitor(jobs)\n",
    "ads = append_company_and_competitor(ads)\n",
    "print(f\"Company ids added to dataframes...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f376152-5f11-408c-9dc7-50cf66d9e5d7",
   "metadata": {},
   "source": [
    "## Convert news feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55159bcd-8529-499e-b947-ae92b7a0c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Newsfeed content converted to json for 55 records.\n"
     ]
    }
   ],
   "source": [
    "news_feed_json = pd.DataFrame()\n",
    "\n",
    "if news_feed is not None and not news_feed.empty:\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [\"id\", \"competitor_id\", \"company_id\", \"url\", \"title\", \"content\", \"description\"]\n",
    "    missing_cols = [col for col in required_cols if col not in news_feed.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in news_feed: {missing_cols}\")\n",
    "    else:\n",
    "        news_feed_json[\"id\"] = news_feed[\"id\"]\n",
    "        news_feed_json[\"competitor_id\"] = news_feed[\"competitor_id\"]\n",
    "        news_feed_json[\"company_id\"] = news_feed[\"company_id\"]\n",
    "        news_feed_json[\"content\"] = news_feed[\"content\"]\n",
    "        news_feed_json[\"source\"] = \"news\"\n",
    "\n",
    "        news_feed_json[\"content_json\"] = news_feed.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"content\": row[\"content\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"news\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Newsfeed content converted to json for {len(news_feed_json)} records.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è news_feed is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532da676-44ee-41e2-94e5-878924e9d27b",
   "metadata": {},
   "source": [
    "## Convert linkedin feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f37e2b0a-b0e2-4061-a0d0-3d449dcc511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Linkedin content converted to json...\n"
     ]
    }
   ],
   "source": [
    "linkedin_feed_json = pd.DataFrame()\n",
    "\n",
    "if linkedin_feed is not None and not linkedin_feed.empty:\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [\"id\", \"competitor_id\", \"author_fullName\", \"text\", \"postUrl\"]\n",
    "    missing_cols = [col for col in required_cols if col not in linkedin_feed.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in linkedin_feed: {missing_cols}\")\n",
    "    else:\n",
    "        linkedin_feed_json[\"id\"] = linkedin_feed[\"id\"]\n",
    "        linkedin_feed_json[\"competitor_id\"] = linkedin_feed[\"competitor_id\"]\n",
    "        linkedin_feed_json[\"company_id\"] = linkedin_feed[\"company_id\"]\n",
    "        linkedin_feed_json[\"source\"] = \"linkedin\"\n",
    "\n",
    "        linkedin_feed_json[\"content_json\"] = linkedin_feed.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"author_fullName\": row[\"author_fullName\"],\n",
    "                \"text\": row[\"text\"],\n",
    "                \"url\": row[\"postUrl\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"linkedin\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"‚úÖ Linkedin content converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è linkedin_feed is empty ‚Äî skipping JSON conversion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b6383-0bf7-4514-9df9-7a65b712b1e9",
   "metadata": {},
   "source": [
    "## Convert reddit feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf36fa8-c052-4c7b-8650-b80fe3043057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 4 Reddit records converted...\n"
     ]
    }
   ],
   "source": [
    "reddit_posts_json = pd.DataFrame()\n",
    "\n",
    "if reddit_posts is not None and not reddit_posts.empty:\n",
    "    required_cols = [\"id\", \"company_id\", \"post_selftext\", \"post_url\"]\n",
    "    missing_cols = [col for col in required_cols if col not in reddit_posts.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in reddit_posts: {missing_cols}\")\n",
    "    else:\n",
    "        reddit_posts_json[\"id\"] = reddit_posts[\"id\"]\n",
    "        reddit_posts_json[\"competitor_id\"] = reddit_posts[\"company_id\"]\n",
    "        reddit_posts_json[\"company_id\"] = reddit_posts[\"company_id\"] \n",
    "        reddit_posts_json[\"source\"] = \"reddit\"\n",
    "\n",
    "        reddit_posts_json[\"content_json\"] = reddit_posts.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"text\": row[\"post_selftext\"],\n",
    "                \"url\": row[\"post_url\"],\n",
    "                \"competitor_id\": row[\"company_id\"],\n",
    "                \"company_id\": row[\"company_id\"],\n",
    "                \"source\": \"reddit\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(reddit_posts_json)} Reddit records converted...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è reddit_posts is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4eed56-3eea-428a-8b75-d46d51160223",
   "metadata": {},
   "source": [
    "## Convert jobs feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1639e13-5c54-472e-a110-a40eeabdf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 79 job postings converted to json...\n"
     ]
    }
   ],
   "source": [
    "jobs_json = pd.DataFrame()\n",
    "\n",
    "if jobs is not None and not jobs.empty:\n",
    "    required_cols = [\"id\", \"competitor_id\", \"company_id\", \"title\", \"description\", \"url\"]\n",
    "    missing_cols = [col for col in required_cols if col not in jobs.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in jobs: {missing_cols}\")\n",
    "    else:\n",
    "        jobs_json[\"id\"] = jobs[\"id\"]\n",
    "        jobs_json[\"competitor_id\"] = jobs[\"competitor_id\"]\n",
    "        jobs_json[\"company_id\"] = jobs[\"company_id\"]\n",
    "        jobs_json[\"source\"] = \"jobs\"\n",
    "\n",
    "        jobs_json[\"content_json\"] = jobs.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "                \"description\": row[\"description\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"competitor_id\": row[\"competitor_id\"],\n",
    "                \"source\": \"jobs\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(jobs_json)} job postings converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è jobs is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea185e4-b01a-4216-982d-7a2414a735f8",
   "metadata": {},
   "source": [
    "## Convert ads feed to json ready df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4ac2b6-660d-415d-b0d1-784bf90b4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 111 ads converted to json...\n"
     ]
    }
   ],
   "source": [
    "ads_json = pd.DataFrame()\n",
    "\n",
    "if ads is not None and not ads.empty:\n",
    "    required_cols = [\"id\", \"competitor_id\", \"json_response\", ]\n",
    "    missing_cols = [col for col in required_cols if col not in ads.columns]\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing columns in jobs: {missing_cols}\")\n",
    "    else:\n",
    "        ads_json[\"id\"] = ads[\"id\"]\n",
    "        ads_json[\"competitor_id\"] = ads[\"competitor_id\"]\n",
    "        ads_json[\"company_id\"] = ads[\"company_id\"]\n",
    "        ads_json[\"source\"] = \"ads\"\n",
    "\n",
    "        ads_json[\"content_json\"] = ads.apply(\n",
    "            lambda row: json.dumps({\n",
    "                \"content_id\": row[\"id\"],\n",
    "                \"json_response\": row[\"json_response\"],\n",
    "                \"source\": \"ads\"\n",
    "            }),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ {len(ads_json)} ads converted to json...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ads is empty ‚Äî skipping JSON conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce2128-6410-4f7c-bc17-21b1ff8b6451",
   "metadata": {},
   "source": [
    "## Combine dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22cd637-053c-4363-8648-5bdc9ca681b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data frame combination completed with 256 rows created\n"
     ]
    }
   ],
   "source": [
    "data_feed_combined = pd.concat([\n",
    "    news_feed_json,\n",
    "    linkedin_feed_json,\n",
    "    reddit_posts_json,\n",
    "    jobs_json,\n",
    "    ads_json\n",
    "], ignore_index=True)\n",
    "print(f\"‚úÖ Data frame combination completed with {len(data_feed_combined)} rows created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3994a5-54b8-4b6d-a14c-02a195103fb9",
   "metadata": {},
   "source": [
    "## Add company description to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450f3113-d3a1-46d0-9a15-a335c0631d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "      <th>content_json</th>\n",
       "      <th>company_custom_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62011</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>Every item on this page was chosen by an edito...</td>\n",
       "      <td>news</td>\n",
       "      <td>{\"content_id\": 62011, \"url\": \"https://www.thep...</td>\n",
       "      <td>Toast POS is a cloud-based point-of-sale and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62009</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>Now through Feb. 14, get $10 off your first re...</td>\n",
       "      <td>news</td>\n",
       "      <td>{\"content_id\": 62009, \"url\": \"https://www.cnet...</td>\n",
       "      <td>Toast POS is a cloud-based point-of-sale and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62003</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>A generic bouquet wrapped in plastic and a box...</td>\n",
       "      <td>news</td>\n",
       "      <td>{\"content_id\": 62003, \"url\": \"https://shopping...</td>\n",
       "      <td>Toast POS is a cloud-based point-of-sale and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62002</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>[Skip to content](https://thebeat951.com/music...</td>\n",
       "      <td>news</td>\n",
       "      <td>{\"content_id\": 62002, \"url\": \"https://thebeat9...</td>\n",
       "      <td>Toast POS is a cloud-based point-of-sale and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62000</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>50 Cent is delivering the beef directly to his...</td>\n",
       "      <td>news</td>\n",
       "      <td>{\"content_id\": 62000, \"url\": \"https://thegrio....</td>\n",
       "      <td>Toast POS is a cloud-based point-of-sale and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>82248</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ads</td>\n",
       "      <td>{\"content_id\": 82248, \"json_response\": \"{\\\"adv...</td>\n",
       "      <td>MX Build combines field service management wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>82168</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ads</td>\n",
       "      <td>{\"content_id\": 82168, \"json_response\": \"{\\\"adv...</td>\n",
       "      <td>MX Build combines field service management wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>82166</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ads</td>\n",
       "      <td>{\"content_id\": 82166, \"json_response\": \"{\\\"adv...</td>\n",
       "      <td>MX Build combines field service management wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>82160</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ads</td>\n",
       "      <td>{\"content_id\": 82160, \"json_response\": \"{\\\"adv...</td>\n",
       "      <td>MX Build combines field service management wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>82155</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ads</td>\n",
       "      <td>{\"content_id\": 82155, \"json_response\": \"{\\\"adv...</td>\n",
       "      <td>MX Build combines field service management wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  competitor_id  company_id  \\\n",
       "0    62011            158          66   \n",
       "1    62009            158          66   \n",
       "2    62003            158          66   \n",
       "3    62002            158          66   \n",
       "4    62000            158          66   \n",
       "..     ...            ...         ...   \n",
       "251  82248            163          72   \n",
       "252  82168            166          72   \n",
       "253  82166            166          72   \n",
       "254  82160            166          72   \n",
       "255  82155            166          72   \n",
       "\n",
       "                                               content source  \\\n",
       "0    Every item on this page was chosen by an edito...   news   \n",
       "1    Now through Feb. 14, get $10 off your first re...   news   \n",
       "2    A generic bouquet wrapped in plastic and a box...   news   \n",
       "3    [Skip to content](https://thebeat951.com/music...   news   \n",
       "4    50 Cent is delivering the beef directly to his...   news   \n",
       "..                                                 ...    ...   \n",
       "251                                                NaN    ads   \n",
       "252                                                NaN    ads   \n",
       "253                                                NaN    ads   \n",
       "254                                                NaN    ads   \n",
       "255                                                NaN    ads   \n",
       "\n",
       "                                          content_json  \\\n",
       "0    {\"content_id\": 62011, \"url\": \"https://www.thep...   \n",
       "1    {\"content_id\": 62009, \"url\": \"https://www.cnet...   \n",
       "2    {\"content_id\": 62003, \"url\": \"https://shopping...   \n",
       "3    {\"content_id\": 62002, \"url\": \"https://thebeat9...   \n",
       "4    {\"content_id\": 62000, \"url\": \"https://thegrio....   \n",
       "..                                                 ...   \n",
       "251  {\"content_id\": 82248, \"json_response\": \"{\\\"adv...   \n",
       "252  {\"content_id\": 82168, \"json_response\": \"{\\\"adv...   \n",
       "253  {\"content_id\": 82166, \"json_response\": \"{\\\"adv...   \n",
       "254  {\"content_id\": 82160, \"json_response\": \"{\\\"adv...   \n",
       "255  {\"content_id\": 82155, \"json_response\": \"{\\\"adv...   \n",
       "\n",
       "                                 company_custom_prompt  \n",
       "0    Toast POS is a cloud-based point-of-sale and r...  \n",
       "1    Toast POS is a cloud-based point-of-sale and r...  \n",
       "2    Toast POS is a cloud-based point-of-sale and r...  \n",
       "3    Toast POS is a cloud-based point-of-sale and r...  \n",
       "4    Toast POS is a cloud-based point-of-sale and r...  \n",
       "..                                                 ...  \n",
       "251  MX Build combines field service management wit...  \n",
       "252  MX Build combines field service management wit...  \n",
       "253  MX Build combines field service management wit...  \n",
       "254  MX Build combines field service management wit...  \n",
       "255  MX Build combines field service management wit...  \n",
       "\n",
       "[256 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_feed_combined.merge(\n",
    "    companies[['id', 'company_custom_prompt']],\n",
    "    left_on='company_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop id_y and rename id_x back to id\n",
    "df = (\n",
    "    df\n",
    "    .drop(columns=['id_y'])\n",
    "    .rename(columns={'id_x': 'id'})\n",
    ")\n",
    "df\n",
    "data_feed_combined = df\n",
    "data_feed_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e37e85-bc0e-4826-9297-23c710f897dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Map new content against existing insight(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa04b87-a784-4a1e-bc46-71422a6399a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Assign data_feed a new name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba558c9a-af6e-44c7-b209-24ece7f04a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataframe grouped together with 38 rows created...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>content_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ads</td>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 82441, \"json_response\": \"{\\\"cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  competitor_id  company_id  \\\n",
       "0    ads            152          23   \n",
       "\n",
       "                                        content_json  \n",
       "0  [{\"content_id\": 82441, \"json_response\": \"{\\\"cr...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_match_candidates = (\n",
    "    data_feed_combined\n",
    "    .groupby([\"source\", \"competitor_id\", \"company_id\"], as_index=False)\n",
    "    .agg({\"content_json\": list})\n",
    ")\n",
    "print(f\"‚úÖ Dataframe grouped together with {len(signal_match_candidates)} rows created...\")\n",
    "signal_match_candidates.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62301f7e-3f6f-4183-a674-78b2e3074a0e",
   "metadata": {},
   "source": [
    "## Append signals to data_feed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1869a80-940b-4d04-bdcc-b2e20a0d1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>details</th>\n",
       "      <th>company_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52646</td>\n",
       "      <td>DoorDash is hiring Tesla's robotics leader to ...</td>\n",
       "      <td>DoorDash has appointed former Tesla robotics a...</td>\n",
       "      <td>## What You Need to Know\\n- DoorDash has appoi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2809</td>\n",
       "      <td>Skanska is hiring sustainability roles to win ...</td>\n",
       "      <td>Skanska is emphasizing climate‚Äëneutral and 'cl...</td>\n",
       "      <td>## Overview\\n\\n*   Skanska is embedding **sust...</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2808</td>\n",
       "      <td>Skanska is building Skanska Direkt to capture ...</td>\n",
       "      <td>Skanska is launching Skanska Direkt to focus o...</td>\n",
       "      <td>## Overview\\n*   Skanska is executing a **dual...</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2807</td>\n",
       "      <td>Skanska is hiring cloud and IT talent to moder...</td>\n",
       "      <td>Skanska is building cloud, ERP, and field IT c...</td>\n",
       "      <td>## Overview\\n\\n*   Skanska is embedding **sust...</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2806</td>\n",
       "      <td>Skanska is hiring heavy‚Äëcivil leaders to expan...</td>\n",
       "      <td>Skanska is recruiting senior project managers ...</td>\n",
       "      <td>## Overview\\n\\n*   Skanska is **aggressively r...</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  52646  DoorDash is hiring Tesla's robotics leader to ...   \n",
       "1   2809  Skanska is hiring sustainability roles to win ...   \n",
       "2   2808  Skanska is building Skanska Direkt to capture ...   \n",
       "3   2807  Skanska is hiring cloud and IT talent to moder...   \n",
       "4   2806  Skanska is hiring heavy‚Äëcivil leaders to expan...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  DoorDash has appointed former Tesla robotics a...   \n",
       "1  Skanska is emphasizing climate‚Äëneutral and 'cl...   \n",
       "2  Skanska is launching Skanska Direkt to focus o...   \n",
       "3  Skanska is building cloud, ERP, and field IT c...   \n",
       "4  Skanska is recruiting senior project managers ...   \n",
       "\n",
       "                                             details  company_id  \n",
       "0  ## What You Need to Know\\n- DoorDash has appoi...         NaN  \n",
       "1  ## Overview\\n\\n*   Skanska is embedding **sust...        73.0  \n",
       "2  ## Overview\\n*   Skanska is executing a **dual...        73.0  \n",
       "3  ## Overview\\n\\n*   Skanska is embedding **sust...        73.0  \n",
       "4  ## Overview\\n\\n*   Skanska is **aggressively r...        73.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure signals_df has the columns we need\n",
    "signals_subset = existing_signals[[\"id\", \"title\", \"summary\",\"details\", \"company_id\"]]\n",
    "signals_subset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9c9acc-7d80-4618-8658-41c07dcf6f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>content_json</th>\n",
       "      <th>signals_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ads</td>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>[{\"content_id\": 82441, \"json_response\": \"{\\\"cr...</td>\n",
       "      <td>[{'id': 2751, 'title': 'Freelance writers are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ads</td>\n",
       "      <td>156</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 82387, \"json_response\": \"{\\\"ad...</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ads</td>\n",
       "      <td>157</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 82397, \"json_response\": \"{\\\"ad...</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ads</td>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>[{\"content_id\": 82420, \"json_response\": \"{\\\"ad...</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ads</td>\n",
       "      <td>162</td>\n",
       "      <td>72</td>\n",
       "      <td>[{\"content_id\": 82503, \"json_response\": \"{\\\"cr...</td>\n",
       "      <td>[{'id': 2802, 'title': 'MX Build is offering b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  competitor_id  company_id  \\\n",
       "0    ads            152          23   \n",
       "1    ads            156          66   \n",
       "2    ads            157          66   \n",
       "3    ads            158          66   \n",
       "4    ads            162          72   \n",
       "\n",
       "                                        content_json  \\\n",
       "0  [{\"content_id\": 82441, \"json_response\": \"{\\\"cr...   \n",
       "1  [{\"content_id\": 82387, \"json_response\": \"{\\\"ad...   \n",
       "2  [{\"content_id\": 82397, \"json_response\": \"{\\\"ad...   \n",
       "3  [{\"content_id\": 82420, \"json_response\": \"{\\\"ad...   \n",
       "4  [{\"content_id\": 82503, \"json_response\": \"{\\\"cr...   \n",
       "\n",
       "                                        signals_json  \n",
       "0  [{'id': 2751, 'title': 'Freelance writers are ...  \n",
       "1  [{'id': 2800, 'title': 'DoorDash is blaming me...  \n",
       "2  [{'id': 2800, 'title': 'DoorDash is blaming me...  \n",
       "3  [{'id': 2800, 'title': 'DoorDash is blaming me...  \n",
       "4  [{'id': 2802, 'title': 'MX Build is offering b...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group signals by company_id into list of dicts \n",
    "signals_map = (\n",
    "    signals_subset\n",
    "    .groupby(\"company_id\")\n",
    "    .apply(lambda g: g.to_dict(orient=\"records\"), include_groups=False)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Add new column to data_feed\n",
    "signal_match_candidates[\"signals_json\"] = signal_match_candidates[\"company_id\"].map(signals_map).apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "signal_match_candidates.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c0ec3-6776-4c31-a283-2403f0ad1417",
   "metadata": {},
   "source": [
    "## Run against LLM to check signal match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7bdb7bc-9b7d-4599-897b-239f337b5839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/38 (3%)\n",
      "‚úÖ Completed 2/38 (5%)\n",
      "‚úÖ Completed 3/38 (8%)\n",
      "‚úÖ Completed 4/38 (11%)\n",
      "‚úÖ Completed 5/38 (13%)\n",
      "‚úÖ Completed 6/38 (16%)\n",
      "‚úÖ Completed 7/38 (18%)\n",
      "‚úÖ Completed 8/38 (21%)\n",
      "‚úÖ Completed 9/38 (24%)\n",
      "‚úÖ Completed 10/38 (26%)\n",
      "‚úÖ Completed 11/38 (29%)\n",
      "‚úÖ Completed 12/38 (32%)\n",
      "‚úÖ Completed 13/38 (34%)\n",
      "‚úÖ Completed 14/38 (37%)\n",
      "‚úÖ Completed 15/38 (39%)\n",
      "‚úÖ Completed 16/38 (42%)\n",
      "‚úÖ Completed 17/38 (45%)\n",
      "‚úÖ Completed 18/38 (47%)\n",
      "‚úÖ Completed 19/38 (50%)\n",
      "‚úÖ Completed 20/38 (53%)\n",
      "‚úÖ Completed 21/38 (55%)\n",
      "‚úÖ Completed 22/38 (58%)\n",
      "‚úÖ Completed 23/38 (61%)\n",
      "‚úÖ Completed 24/38 (63%)\n",
      "‚úÖ Completed 25/38 (66%)\n",
      "‚úÖ Completed 26/38 (68%)\n",
      "‚úÖ Completed 27/38 (71%)\n",
      "‚úÖ Completed 28/38 (74%)\n",
      "‚úÖ Completed 29/38 (76%)\n",
      "‚úÖ Completed 30/38 (79%)\n",
      "‚úÖ Completed 31/38 (82%)\n",
      "‚úÖ Completed 32/38 (84%)\n",
      "‚úÖ Completed 33/38 (87%)\n",
      "‚úÖ Completed 34/38 (89%)\n",
      "‚úÖ Completed 35/38 (92%)\n",
      "‚úÖ Completed 36/38 (95%)\n",
      "‚úÖ Completed 37/38 (97%)\n",
      "‚úÖ Completed 38/38 (100%)\n"
     ]
    }
   ],
   "source": [
    "client = AsyncOpenAI(api_key=openai_api_key)\n",
    "MODEL_NAME = OPENAI_MODEL\n",
    "MAX_CONCURRENCY = 100\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "async def fetch_response(prompt, row_id, company_id, source, signals_json, progress):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            text = response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for id {row_id}: {e}\")\n",
    "\n",
    "        # Update progress safely\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            done = progress[\"done\"]\n",
    "            total = progress[\"total\"]\n",
    "            print(f\"‚úÖ Completed {done}/{total} ({done/total:.0%})\")\n",
    "\n",
    "        return {\n",
    "            \"competitor_id\": row_id,\n",
    "            \"company_id\": company_id,\n",
    "            \"source\": source,\n",
    "            \"signals_json\": signals_json,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "            You are a senior competitive intelligence analyst reporting to C-suite executives.\n",
    "            \n",
    "            Your job is to evaluate EACH new content item independently and decide whether it should be mapped to an existing signal.\n",
    "            \n",
    "            You must follow these strict rules:\n",
    "\n",
    "            1. **Be extremely selective. Default to NOT mapping.**\n",
    "            2. Only map a content item to a signal if there is a **clear, direct, and explicit overlap**\n",
    "               in (a) topic, (b) company action, or (c) strategic theme.\n",
    "            3. Weak, indirect, vague, or broad connections DO NOT count.\n",
    "            4. If you are unsure, the answer is False.\n",
    "            5. You MUST still select the closest signal (best thematic fit) even if the result is False.\n",
    "            6. Output one result PER CONTENT ITEM.\n",
    "            \n",
    "            STRICT STRUCTURE + VALIDATION RULES (MANDATORY):\n",
    "            \n",
    "            7. You MUST return structured JSON only.\n",
    "            8. For each content item, you MUST output the fields:\n",
    "               - \"content_id\": the NUMERIC ID from the input.\n",
    "               - \"signal_id\": the NUMERIC signal ID you consider the closest thematic fit.\n",
    "               - \"should_map\": a boolean.\n",
    "            \n",
    "            9. You MUST follow these strict constraints for \"content_id\" and \"signal_id\":\n",
    "               - They MUST be integers.\n",
    "               - They MUST come directly from the input.\n",
    "               - You MUST NOT generate, guess, invent, or hallucinate IDs.\n",
    "               - You MUST NOT substitute titles, summaries, strings, or text in place of IDs.\n",
    "               - If you cannot determine the numeric ID from the input, you MUST set it to null.\n",
    "            \n",
    "            10. NEVER output:\n",
    "                - article titles\n",
    "                - summaries\n",
    "                - URLs\n",
    "                - descriptions\n",
    "                - category labels\n",
    "                - string content\n",
    "                in the \"content_id\" or \"signal_id\" fields.  \n",
    "                These fields must be strictly integer or null.\n",
    "            \n",
    "            This is not optional. Any violation of these numeric rules invalidates the output.\n",
    "\n",
    "            Here is the list of new content items:\n",
    "            {row['content_json']}\n",
    "            \n",
    "            Here are the existing signals:\n",
    "            {row['signals_json']}\n",
    "            \n",
    "            Respond ONLY with a JSON array.\n",
    "            Each element must be structured like:\n",
    "            \n",
    "            {{\n",
    "              \"should_map\": true/false,\n",
    "              \"signal_id\": \"<closest matching signal id>\",\n",
    "              \"content_id\": \"<content_id>\",\n",
    "              \"signal_title\": \"<closest signal title>\",\n",
    "              \"content_title\": \"<title of this content item>\",\n",
    "              \"reason\": \"Short explanation. If false, explain why the overlap is weak.\"\n",
    "            }}\n",
    "            \n",
    "            Return EXACTLY one object per content item, in the same order they appear.\n",
    "            \"\"\"\n",
    "        # print(prompt)\n",
    "        tasks.append(fetch_response(prompt, row[\"competitor_id\"], row[\"company_id\"], row[\"source\"], row[\"signals_json\"], progress))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "signal_match_results = await process_all(signal_match_candidates)\n",
    "signal_match_results_df = pd.DataFrame(signal_match_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfd85b9e-ce0d-4410-9d71-8fb7c3063b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>source</th>\n",
       "      <th>signals_json</th>\n",
       "      <th>response</th>\n",
       "      <th>response_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>ads</td>\n",
       "      <td>[{'id': 2751, 'title': 'Freelance writers are ...</td>\n",
       "      <td>[\\n  {\\n    \"should_map\": true,\\n    \"signal_i...</td>\n",
       "      <td>[{'should_map': True, 'signal_id': 2145, 'cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156</td>\n",
       "      <td>66</td>\n",
       "      <td>ads</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "      <td>[\\n  {\\n    \"should_map\": true,\\n    \"signal_i...</td>\n",
       "      <td>[{'should_map': True, 'signal_id': 2532, 'cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>66</td>\n",
       "      <td>ads</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "      <td>[\\n  {\\n    \"should_map\": true,\\n    \"signal_i...</td>\n",
       "      <td>[{'should_map': True, 'signal_id': 2054, 'cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>ads</td>\n",
       "      <td>[{'id': 2800, 'title': 'DoorDash is blaming me...</td>\n",
       "      <td>[\\n  {\\n    \"should_map\": true,\\n    \"signal_i...</td>\n",
       "      <td>[{'should_map': True, 'signal_id': 2640, 'cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162</td>\n",
       "      <td>72</td>\n",
       "      <td>ads</td>\n",
       "      <td>[{'id': 2802, 'title': 'MX Build is offering b...</td>\n",
       "      <td>[\\n  {\\n    \"should_map\": true,\\n    \"signal_i...</td>\n",
       "      <td>[{'should_map': True, 'signal_id': 2719, 'cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   competitor_id  company_id source  \\\n",
       "0            152          23    ads   \n",
       "1            156          66    ads   \n",
       "2            157          66    ads   \n",
       "3            158          66    ads   \n",
       "4            162          72    ads   \n",
       "\n",
       "                                        signals_json  \\\n",
       "0  [{'id': 2751, 'title': 'Freelance writers are ...   \n",
       "1  [{'id': 2800, 'title': 'DoorDash is blaming me...   \n",
       "2  [{'id': 2800, 'title': 'DoorDash is blaming me...   \n",
       "3  [{'id': 2800, 'title': 'DoorDash is blaming me...   \n",
       "4  [{'id': 2802, 'title': 'MX Build is offering b...   \n",
       "\n",
       "                                            response  \\\n",
       "0  [\\n  {\\n    \"should_map\": true,\\n    \"signal_i...   \n",
       "1  [\\n  {\\n    \"should_map\": true,\\n    \"signal_i...   \n",
       "2  [\\n  {\\n    \"should_map\": true,\\n    \"signal_i...   \n",
       "3  [\\n  {\\n    \"should_map\": true,\\n    \"signal_i...   \n",
       "4  [\\n  {\\n    \"should_map\": true,\\n    \"signal_i...   \n",
       "\n",
       "                                    response_cleaned  \n",
       "0  [{'should_map': True, 'signal_id': 2145, 'cont...  \n",
       "1  [{'should_map': True, 'signal_id': 2532, 'cont...  \n",
       "2  [{'should_map': True, 'signal_id': 2054, 'cont...  \n",
       "3  [{'should_map': True, 'signal_id': 2640, 'cont...  \n",
       "4  [{'should_map': True, 'signal_id': 2719, 'cont...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up JSON\n",
    "def safe_load(x):\n",
    "    if not x or str(x).strip() == \"\":\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return json5.loads(x)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "signal_match_results_df[\"response_cleaned\"] = signal_match_results_df[\"response\"].apply(safe_load)\n",
    "signal_match_results_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975d5b8-9897-44b1-8774-e228ace1a74e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Update supabase, map new content to existing signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9bff785-752e-4c95-b0bd-2ed45b1989f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted 78 ads ‚Üí signal links into ad_library_signals\n",
      "‚úÖ Inserted 69 jobs ‚Üí signal links into jobs_feed_signals\n",
      "‚úÖ Inserted 4 linkedin ‚Üí signal links into linkedin_feed_signals\n",
      "‚ùå Error inserting into news_feed_signals: {'code': '23503', 'details': 'Key (news_feed_id)=(61956) is not present in table \"news_feed\".', 'hint': None, 'message': 'insert or update on table \"news_feed_signals\" violates foreign key constraint \"news_feed_signals_2_news_feed_id_fkey\"'}\n",
      "‚úÖ Inserted 3 reddit ‚Üí signal links into reddit_feed_signals\n"
     ]
    }
   ],
   "source": [
    "mapped_signal_links = []\n",
    "\n",
    "for _, row in signal_match_results_df.iterrows():\n",
    "    source = row.get(\"source\")\n",
    "    competitor_id = row.get(\"competitor_id\")\n",
    "    company_id = row.get(\"company_id\")\n",
    "\n",
    "    # response_cleaned is a list of mapping dicts\n",
    "    mappings = row.get(\"response_cleaned\", [])\n",
    "\n",
    "    if not isinstance(mappings, list):\n",
    "        continue\n",
    "\n",
    "    for m in mappings:\n",
    "        # Only keep mappings where should_map=True\n",
    "        if m.get(\"should_map\") is True:\n",
    "            mapped_signal_links.append({\n",
    "                \"source\": source,\n",
    "                \"competitor_id\": competitor_id,\n",
    "                \"company_id\": company_id,\n",
    "                \"content_id\": m.get(\"content_id\"),\n",
    "                \"signal_id\": m.get(\"signal_id\")\n",
    "            })\n",
    "\n",
    "if not mapped_signal_links:\n",
    "    print(\"‚ö†Ô∏è No signal links created\")\n",
    "else:\n",
    "    # Group by source\n",
    "    grouped = {}\n",
    "    for row in mapped_signal_links:\n",
    "        src = row.get(\"source\")\n",
    "        grouped.setdefault(src, []).append(row)\n",
    "\n",
    "    for source, rows in grouped.items():\n",
    "        # Correct table map\n",
    "        table_map = {\n",
    "            \"news\": (\"news_feed_signals\", \"news_feed_id\"),\n",
    "            \"linkedin\": (\"linkedin_feed_signals\", \"linkedin_feed_id\"),\n",
    "            \"reddit\": (\"reddit_feed_signals\", \"reddit_feed_id\"),\n",
    "            \"jobs\": (\"jobs_feed_signals\", \"jobs_feed_id\"),\n",
    "            \"ads\": (\"ad_library_signals\", \"ad_library_feed_id\"),\n",
    "        }\n",
    "\n",
    "        if source not in table_map:\n",
    "            print(f\"‚ö†Ô∏è Skipping unknown source '{source}'\")\n",
    "            continue\n",
    "\n",
    "        table_name, content_field = table_map[source]\n",
    "\n",
    "        # Build insert rows\n",
    "        insert_rows = []\n",
    "        for r in rows:\n",
    "            signal_id = r.get(\"signal_id\")\n",
    "            content_id = r.get(\"content_id\")\n",
    "\n",
    "            if signal_id is None or content_id is None:\n",
    "                continue\n",
    "\n",
    "            insert_rows.append({\n",
    "                \"signal_id\": signal_id,\n",
    "                content_field: content_id\n",
    "            })\n",
    "\n",
    "        if not insert_rows:\n",
    "            print(f\"‚ö†Ô∏è No valid rows for source '{source}'\")\n",
    "            continue\n",
    "\n",
    "        # INSERT (no upsert)\n",
    "        try:\n",
    "            supabase.table(table_name).insert(insert_rows).execute()\n",
    "            print(f\"‚úÖ Inserted {len(insert_rows)} {source} ‚Üí signal links into {table_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inserting into {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1007b8-bf53-4e8c-9c24-e5958b00ef7a",
   "metadata": {},
   "source": [
    "## Update signal details with new content sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6efbbc6d-9bcf-4396-9650-47328202d464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>signals_json</th>\n",
       "      <th>content_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851</td>\n",
       "      <td>{'signal_id': 1851, 'title': 'Nabla is hiring ...</td>\n",
       "      <td>[{\"content_id\": 8848, \"title\": \"Mid-Market Cus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id                                       signals_json  \\\n",
       "0       1851  {'signal_id': 1851, 'title': 'Nabla is hiring ...   \n",
       "\n",
       "                                        content_json  \n",
       "0  [{\"content_id\": 8848, \"title\": \"Mid-Market Cus...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert mapped signal links to a df\n",
    "updated_signals = pd.DataFrame(mapped_signal_links)\n",
    "\n",
    "# Attach content_json\n",
    "updated_signals_with_json = updated_signals.merge(\n",
    "    data_feed_combined[[\"id\", \"source\", \"content_json\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"content_id\", \"source\"],\n",
    "    right_on=[\"id\", \"source\"]\n",
    ").drop(columns=[\"id\"])\n",
    "\n",
    "# Prepare signal metadata\n",
    "signal_meta = signals_subset.rename(columns={\"id\": \"signal_id\"})\n",
    "\n",
    "# Merge signal metadata ‚Üí updated_signals\n",
    "merged = updated_signals_with_json.merge(\n",
    "    signal_meta,\n",
    "    how=\"left\",\n",
    "    on=\"signal_id\"\n",
    ")\n",
    "\n",
    "# Build JSON field\n",
    "merged[\"signals_json\"] = merged.apply(\n",
    "    lambda row: {\n",
    "        \"signal_id\": row[\"signal_id\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"summary\": row[\"summary\"],\n",
    "        \"details\": row[\"details\"],\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "updated_signals_with_json = merged\n",
    "\n",
    "# Group by signals\n",
    "updated_signals_with_json_grouped = (\n",
    "    updated_signals_with_json\n",
    "    .groupby(\"signal_id\")\n",
    "    .agg({\n",
    "        \"signals_json\": \"first\",\n",
    "        \"content_json\": list\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "updated_signals_with_json_grouped.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7188c0-bf24-497b-85f2-fb92114bf265",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Run through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b123e95-fe8e-47d5-9fe3-9f411e4c407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/65\n",
      "‚úÖ Completed 2/65\n",
      "‚úÖ Completed 3/65\n",
      "‚úÖ Completed 4/65\n",
      "‚úÖ Completed 5/65\n",
      "‚úÖ Completed 6/65\n",
      "‚úÖ Completed 7/65\n",
      "‚úÖ Completed 8/65\n",
      "‚úÖ Completed 9/65\n",
      "‚úÖ Completed 10/65\n",
      "‚úÖ Completed 11/65\n",
      "‚úÖ Completed 12/65\n",
      "‚úÖ Completed 13/65\n",
      "‚úÖ Completed 14/65\n",
      "‚úÖ Completed 15/65\n",
      "‚úÖ Completed 16/65\n",
      "‚úÖ Completed 17/65\n",
      "‚úÖ Completed 18/65\n",
      "‚úÖ Completed 19/65\n",
      "‚úÖ Completed 20/65\n",
      "‚úÖ Completed 21/65\n",
      "‚úÖ Completed 22/65\n",
      "‚úÖ Completed 23/65\n",
      "‚úÖ Completed 24/65\n",
      "‚úÖ Completed 25/65\n",
      "‚úÖ Completed 26/65\n",
      "‚úÖ Completed 27/65\n",
      "‚úÖ Completed 28/65\n",
      "‚úÖ Completed 29/65\n",
      "‚úÖ Completed 30/65\n",
      "‚úÖ Completed 31/65\n",
      "‚úÖ Completed 32/65\n",
      "‚úÖ Completed 33/65\n",
      "‚úÖ Completed 34/65\n",
      "‚úÖ Completed 35/65\n",
      "‚úÖ Completed 36/65\n",
      "‚úÖ Completed 37/65\n",
      "‚úÖ Completed 38/65\n",
      "‚úÖ Completed 39/65\n",
      "‚úÖ Completed 40/65\n",
      "‚úÖ Completed 41/65\n",
      "‚úÖ Completed 42/65\n",
      "‚úÖ Completed 43/65\n",
      "‚úÖ Completed 44/65\n",
      "‚úÖ Completed 45/65\n",
      "‚úÖ Completed 46/65\n",
      "‚úÖ Completed 47/65\n",
      "‚úÖ Completed 48/65\n",
      "‚úÖ Completed 49/65\n",
      "‚úÖ Completed 50/65\n",
      "‚úÖ Completed 51/65\n",
      "‚úÖ Completed 52/65\n",
      "‚úÖ Completed 53/65\n",
      "‚úÖ Completed 54/65\n",
      "‚úÖ Completed 55/65\n",
      "‚úÖ Completed 56/65\n",
      "‚úÖ Completed 57/65\n",
      "‚úÖ Completed 58/65\n",
      "‚úÖ Completed 59/65\n",
      "‚úÖ Completed 60/65\n",
      "‚úÖ Completed 61/65\n",
      "‚úÖ Completed 62/65\n",
      "‚úÖ Completed 63/65\n",
      "‚úÖ Completed 64/65\n",
      "‚úÖ Completed 65/65\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "MAX_CONCURRENCY = 50\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "# 2. Initialize the model with JSON mode enabled\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-pro\" ,\n",
    "    generation_config={\n",
    "        \"temperature\": 0,\n",
    "        # \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"application/json\"\n",
    "    }\n",
    ")\n",
    "\n",
    "async def fetch_response(prompt, signal_id, signals_json, progress):\n",
    "    async with semaphore:\n",
    "        text = None\n",
    "        try:\n",
    "            # 3. Gemini Async Call\n",
    "            # Note: We use the `await` syntax for the async version of the method\n",
    "            response = await model.generate_content_async(prompt)\n",
    "            text = response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error on signal {signal_id}: {e}\")\n",
    "\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            print(f\"‚úÖ Completed {progress['done']}/{progress['total']}\")\n",
    "\n",
    "        return {\n",
    "            \"signal_id\": signal_id,\n",
    "            \"signals_json\": signals_json,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "            You are updating an existing competitive-intelligence signal.\n",
    "            \n",
    "            Below is the existing signal JSON, which contains a summary and a 'details' field written in Markdown using the exact CI structure from the extraction prompt:\n",
    "            \n",
    "            {row['signals_json']}\n",
    "            \n",
    "            Below is NEW content that must be incorporated *into* this existing signal without altering the structure:\n",
    "            \n",
    "            {row['content_json']}\n",
    "            \n",
    "            YOUR TASK:\n",
    "            Integrate the new insights into the existing signal by **appending new bullets** into the appropriate sections, while preserving the original structure and wording.\n",
    "            \n",
    "            ### CRITICAL RULES (DO NOT VIOLATE)\n",
    "            \n",
    "            1. **You can edit, rewrite, reorder, or rephrase ANY existing text if needed.**\n",
    "            \n",
    "            2. **Maintain the exact four-section structure:**\n",
    "               - ## What You Need to Know\n",
    "               - ## The Threat to Watch\n",
    "               - ## What to Monitor\n",
    "               - ## Bottom Line \n",
    "               (These already exist in the details; do not recreate them.)\n",
    "            \n",
    "            3. **APPEND ONLY**\n",
    "               - Add or modify bullets in correct section.\n",
    "               - Use the exact same Markdown bullet style (hyphen at start).\n",
    "               - Match tone and bullet length from the original extraction prompt.\n",
    "               - Bold key phrases using **double asterisks** to enable skimming\n",
    "               - Make sure to cite specific facts, quotes, or claims, include inline source links using this format:\n",
    "                   - Example: [POS ad promotion](https://www.linkedin.com/ad-library/detail/968519826?trk=ad_library_ad_preview_content_image)\n",
    "                   - Format: [link text](https://example.com)\n",
    "            - Link format: competitor claims/quotes should link to original source; financial data should link to the report/filing\n",
    "            - Example: \"Freshworks reported **15% constant currency revenue growth** [Q3 earnings](https://...)\"\n",
    "               \n",
    "            4. **SUMMARY**\n",
    "               - Update the existing summary to *include the new idea*.\n",
    "               - Summary must remain 1‚Äì2 sentences, maximum.\n",
    "               - Do NOT delete the original meaning or rewrite from scratch.\n",
    "               - When referring to a competitor, do not say 'they' or 'them', refer to the competitor by their name.\n",
    "            \n",
    "            5. **CONTENT INTEGRITY**\n",
    "               - Keep all existing Markdown and links.\n",
    "               - Do not add new sections.\n",
    "               - Do not say ‚Äúnew‚Äù or ‚Äúadditional.‚Äù\n",
    "               - Try to keeping each section to about 3-5 bullets.\n",
    "\n",
    "            6. For update_sig indicate if you just Enriched the content or there is actually a significant new update that my clinet should know about.\n",
    "                If there is not a big update, just put 'enriched', if there is put 'updated'.\n",
    "            \n",
    "            ### OUTPUT FORMAT\n",
    "            Respond ONLY with valid JSON, a list containing exactly ONE object:\n",
    "            \n",
    "            [\n",
    "              {{\n",
    "                \"summary\": \"<updated summary that keeps all original meaning but adds new insight>\",\n",
    "                \"details\": \"<update content with new sources integrated>\",\n",
    "                \"update_sig\": \"<enriched OR updated>\",\n",
    "                \"update_descrip\": \"<if updated, what the major update was, state the before and after so we know the difference>\",\n",
    "              }}\n",
    "            ]\n",
    "            \n",
    "            Do NOT include commentary, explanation, or text outside the JSON.\n",
    "            \"\"\"\n",
    "\n",
    "        tasks.append(\n",
    "            fetch_response(\n",
    "                prompt,\n",
    "                row[\"signal_id\"],\n",
    "                row[\"signals_json\"],\n",
    "                progress\n",
    "            )\n",
    "        )\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Execution\n",
    "updated_signal_details = await process_all(updated_signals_with_json_grouped)\n",
    "updated_signal_details_df = pd.DataFrame(updated_signal_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177da30f-7aa0-4c32-a32d-4363203db1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>signals_json</th>\n",
       "      <th>response</th>\n",
       "      <th>response_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851</td>\n",
       "      <td>{'signal_id': 1851, 'title': 'Nabla is hiring ...</td>\n",
       "      <td>[\\n  {\\n    \"summary\": \"Nabla is rapidly hirin...</td>\n",
       "      <td>[{'summary': 'Nabla is rapidly hiring clinical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id                                       signals_json  \\\n",
       "0       1851  {'signal_id': 1851, 'title': 'Nabla is hiring ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  [\\n  {\\n    \"summary\": \"Nabla is rapidly hirin...   \n",
       "\n",
       "                                    response_cleaned  \n",
       "0  [{'summary': 'Nabla is rapidly hiring clinical...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean json\n",
    "updated_signal_details_df[\"response_cleaned\"] = updated_signal_details_df[\"response\"].apply(safe_load)\n",
    "updated_signal_details_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fdd37-c760-4018-b9d7-79fc8e6f800d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Update supabase with new details content for these signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad37dcf-4d8d-4e71-ad14-d55ef52867d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Updating 65 signals in 1 batches...\n",
      "   ‚úÖ Batch 1/1: 65 rows\n",
      "======================================\n",
      "üéâ FINISHED ‚Äî 65 total rows updated\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "def extract_summary_and_details(cleaned):\n",
    "    if not cleaned or not isinstance(cleaned, list) or len(cleaned) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    item = cleaned[0] if isinstance(cleaned[0], dict) else {}\n",
    "    return (\n",
    "        item.get(\"summary\"),\n",
    "        item.get(\"details\"),\n",
    "        item.get(\"update_sig\"),\n",
    "        item.get(\"update_descrip\"),\n",
    "    )\n",
    "\n",
    "def batch_update_signals(df, batch_size=100):\n",
    "    total_rows = len(df)\n",
    "    num_batches = math.ceil(total_rows / batch_size)\n",
    "\n",
    "    print(f\"üöÄ Updating {total_rows} signals in {num_batches} batches...\")\n",
    "\n",
    "    updated_count = 0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch = df.iloc[i * batch_size : (i + 1) * batch_size]\n",
    "        update_rows = []\n",
    "\n",
    "        now_utc = datetime.now(timezone.utc).isoformat(sep=\" \", timespec=\"microseconds\")\n",
    "\n",
    "        for _, row in batch.iterrows():\n",
    "            signal_id = int(row[\"signal_id\"])\n",
    "            cleaned = row.get(\"response_cleaned\")\n",
    "\n",
    "            summary, details, update_sig, update_descrip = extract_summary_and_details(cleaned)\n",
    "\n",
    "            update_rows.append({\n",
    "                \"id\": signal_id,\n",
    "                \"summary\": summary,\n",
    "                \"details\": details,\n",
    "                \"update_sig\": update_sig,\n",
    "                \"update_descrip\": update_descrip,\n",
    "                \"last_updated\": now_utc\n",
    "            })\n",
    "\n",
    "        resp = (\n",
    "            supabase\n",
    "            .table(\"signals\")\n",
    "            .upsert(update_rows, on_conflict=\"id\")\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        updated_count += len(resp.data or [])\n",
    "        print(f\"   ‚úÖ Batch {i+1}/{num_batches}: {len(update_rows)} rows\")\n",
    "\n",
    "    print(\"======================================\")\n",
    "    print(f\"üéâ FINISHED ‚Äî {updated_count} total rows updated\")\n",
    "    print(\"======================================\")\n",
    "\n",
    "batch_update_signals(updated_signal_details_df, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1acda9-034f-4b3e-97e7-709657d8306f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Remove content_ids from dataframe where true [remove this?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c30db23-fe2b-440d-afc8-29d295eae304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed 203 processed content rows\n",
      "‚úÖ Data feed now has 53 rows remaining\n"
     ]
    }
   ],
   "source": [
    "# 1. Build set of mapped content_ids\n",
    "mapped_content_ids = {\n",
    "    int(row[\"content_id\"]) \n",
    "    for row in mapped_signal_links\n",
    "}\n",
    "\n",
    "# 2. Drop those rows from data_feed_combined\n",
    "before = len(data_feed_combined)\n",
    "\n",
    "data_feed_combined = data_feed_combined[\n",
    "    ~data_feed_combined[\"id\"].astype(int).isin(mapped_content_ids)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "after = len(data_feed_combined)\n",
    "\n",
    "print(f\"‚úÖ Removed {before - after} processed content rows\")\n",
    "print(f\"‚úÖ Data feed now has {len(data_feed_combined)} rows remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295563e6-b251-4a11-ba7d-f137b9972694",
   "metadata": {},
   "source": [
    "# Create new insights using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b30245-912e-44b7-bfaa-b53a37a39479",
   "metadata": {},
   "source": [
    "## Group datafeeds together to prep for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b358c972-c702-4387-933e-7fd2664ba142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataframe grouped together with 11 rows created...\n"
     ]
    }
   ],
   "source": [
    "data_feed = (\n",
    "    data_feed_combined\n",
    "    .groupby([\"source\", \"competitor_id\", \"company_id\", \"company_custom_prompt\"], as_index=False)\n",
    "    .agg({\"content_json\": list})\n",
    ")\n",
    "print(f\"‚úÖ Dataframe grouped together with {len(data_feed)} rows created...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf9939-04c0-4dc7-937b-d7f5bb38fe5d",
   "metadata": {},
   "source": [
    "### Run through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8b0e9e-6fcb-4a54-9560-0c83158f50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/11 (9%)\n",
      "‚úÖ Completed 2/11 (18%)\n",
      "‚úÖ Completed 3/11 (27%)\n",
      "‚úÖ Completed 4/11 (36%)\n",
      "‚úÖ Completed 5/11 (45%)\n",
      "‚úÖ Completed 6/11 (55%)\n",
      "‚úÖ Completed 7/11 (64%)\n",
      "‚úÖ Completed 8/11 (73%)\n",
      "‚úÖ Completed 9/11 (82%)\n",
      "‚úÖ Completed 10/11 (91%)\n",
      "‚úÖ Completed 11/11 (100%)\n"
     ]
    }
   ],
   "source": [
    "client = AsyncOpenAI(api_key=openai_api_key)\n",
    "MODEL_NAME = OPENAI_MODEL\n",
    "MAX_CONCURRENCY = 100\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "async def fetch_response(prompt, row_id, company_id, progress):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            text = response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for id {row_id}: {e}\")\n",
    "\n",
    "        # Update progress safely\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            done = progress[\"done\"]\n",
    "            total = progress[\"total\"]\n",
    "            print(f\"‚úÖ Completed {done}/{total} ({done/total:.0%})\")\n",
    "\n",
    "        return {\n",
    "            \"competitor_id\": row_id,\n",
    "            \"company_id\": company_id,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "            You are a competitive intelligence analyst reporting to C-suite executives on behalf of your client.\n",
    "\n",
    "            About your client: {row['company_custom_prompt']}.\n",
    "\n",
    "            **Your task:**\n",
    "            Each piece of content you are being given is from one of your clients competitors.\n",
    "            Analyze the following content (news articles, LinkedIn posts, Reddit posts, social ads, job postings, etc) to identify key strategic and competitive insights that are relevant or related to your client.\n",
    "            You do not have to include every piece of content in your analysis.\n",
    "            There will be pieces of content that are not important or relevant. You can leave those out.\n",
    "            \n",
    "            For each insight you identify:\n",
    "            - Create a headline that states **what they're doing AND why** (the strategic endgame)\n",
    "            - Write a one sentence insight that explains the implication for the reader\n",
    "            - List the supporting sources below (title and URL)\n",
    "            - You can use the same source in different themes if needed\n",
    "            - However, only use each source a maximum of once per theme\n",
    "            - If possible, include the competitors name in the headline\n",
    "            \n",
    "            ## Headline Formula:\n",
    "            **\"[action/method] to [strategic goal/endgame]\"**\n",
    "            \n",
    "            A good headline answers: What are they doing, and what are they trying to achieve or protect?\n",
    "            \n",
    "            ## Headline Guidelines:\n",
    "            ‚úÖ DO name both the **method** and the **goal/endgame**\n",
    "            ‚úÖ DO imply the threat or opportunity for the reader\n",
    "            ‚úÖ DO use verbs that show transition or intent (shifting, locking in, betting on, racing to, pivoting)\n",
    "            ‚úÖ DO infer strategy from job postings (hiring patterns reveal GTM shifts, capability bets)\n",
    "            ‚úÖ OK to use competitor name\n",
    "            \n",
    "            ‚ùå DON'T just list activities without the \"why\"\n",
    "            ‚ùå DON'T describe topics‚Äîstate the strategic play\n",
    "            ‚ùå DON'T use vague jargon (\"AI Platform,\" \"Integration Central\")\n",
    "            ‚ùå DON'T write headlines that could apply to any company\n",
    "            \n",
    "            ## Good Examples:\n",
    "            - Ambience Healthcare relocating its global HQ to Nashville to embed inside the U.S. healthcare\n",
    "            - Nabla scaling executive and technical leadership to accelerate enterprise rollout\n",
    "            - Microsoft Healthcare building voice-based AI stress detection to enter clinical remote monitoring\n",
    "            - Square building proprietary POS hardware to increase lock‚Äëin\n",
    "            \n",
    "            ## Bad Examples:\n",
    "            - AI Platform at Scale\" (no method, no goal)\n",
    "            - Scaling commercial GTM and building market credibility\" (lists activities, doesn't say why)\n",
    "            - Owning integrations: developer APIs, hardware and deeper partner ties\" (describes what, not why it matters)\n",
    "            - New Product Features\" (too generic)\n",
    "            - Investing in data, streaming, and observability (too generic)\n",
    "            \n",
    "            ## Insight Guidelines:\n",
    "            ‚úÖ 1 sentence max, preferably no more than 5-7 words, any longer its hard to quickly skim\n",
    "            ‚úÖ State the implication for the reader (threat, opportunity, or vulnerability)\n",
    "            ‚úÖ If there's a weakness in the competitor's play, name it\n",
    "            ‚úÖ Do not say \"They are\" or \"our\", when referring to a competitor use their name.\n",
    "            \n",
    "            **Your job:** Synthesize patterns into strategic insights that tell executives what a competitor is trying to achieve and what that means for them.\n",
    "\n",
    "            ## Output Schema\n",
    "            Return only valid JSON matching this structure:\n",
    "                {{\n",
    "                  \"insight_id\": 1,\n",
    "                  \"company_id\": {row['company_id']},\n",
    "                  \"headline\": \"Title here\",\n",
    "                  \"insight\": \"Concise strategic insight\",\n",
    "                  \"supporting_content\": [\n",
    "                    {{\n",
    "                      \"title\": \"Title 1\",\n",
    "                      \"url\": \"https://example.com/article1\",\n",
    "                      \"relevance\": \"Brief note on how this article supports the theme\",\n",
    "                      \"content_id\": \"content_id from the data\",\n",
    "                      \"source\": \"source from the data\",\n",
    "                    }}\n",
    "                  ]\n",
    "                }}\n",
    "            \n",
    "            ## Content\n",
    "            Here is the content: {row['content_json']}\n",
    "\n",
    "            ‚ö†Ô∏è Important:\n",
    "            - **Do not fabricate** any fields like `source`, `url`, `company_id` or `content_id`. Use them exactly as provided in the input data.\n",
    "            - Input the competitor_id field as an integer, not a string\n",
    "            - If multiple items support the same theme, include each under `supporting_content`.\n",
    "            - Return only valid JSON matching the exact schema below.\n",
    "            - Each \"supporting_content\" item must be unique.\n",
    "            - Do NOT repeat the same source, URL, or content_id more than once within a theme.\n",
    "            - If multiple sentences or mentions refer to the same source, merge them into a single supporting_content entry with a concise combined \"relevance\" summary.\n",
    "\n",
    "            ## Output Format Example\n",
    "            This should be the structure of the output:\n",
    "                {{\n",
    "                  \"insight_id\": 1,\n",
    "                  \"company_id\": source from the data field `company_id`,\n",
    "                  \"headline\": \"Strategic title here\",\n",
    "                  \"insight\": \"A concise strategic insight or interpretation of what this theme means for the competitive landscape\",\n",
    "                  \"supporting_content\": [\n",
    "                    {{\n",
    "                      \"title\": \"Title 1\",\n",
    "                      \"url\": \"https://example.com/article1\",\n",
    "                      \"relevance\": \"Brief note on how this article supports the theme\",\n",
    "                      \"content_id\": \"content_id from the data\",\n",
    "                      \"source\": \"source from the data\",\n",
    "                    }},\n",
    "                    {{\n",
    "                      \"title\": \"Title 2\",\n",
    "                      \"url\": \"https://example.com/article2\",\n",
    "                      \"relevance\": \"Brief note on how this article supports the theme\",\n",
    "                      \"content_id\": \"content_id from the data\",\n",
    "                      \"source\": \"source from the data\",\n",
    "                    }}\n",
    "                  ]\n",
    "                }},\n",
    "                {{\n",
    "                  \"insight_id\": 2,\n",
    "                  \"company_id\": source from the data field `company_id`,\n",
    "                  \"headline\": \"Another strategic theme\",\n",
    "                  \"insight\": \"Strategic interpretation of this pattern\",\n",
    "                  \"supporting_content\": [\n",
    "                    {{\n",
    "                      \"title\": \"Title 3\",\n",
    "                      \"url\": \"https://example.com/article3\",\n",
    "                      \"relevance\": \"Connection to theme\",\n",
    "                      \"source\": \"source from the data\",\n",
    "                      \"content_id\": \"content_id from the data\",\n",
    "                    }}\n",
    "                      ]\n",
    "                }}\n",
    "            \"\"\"\n",
    "        tasks.append(fetch_response(prompt, row[\"competitor_id\"], row[\"company_id\"], progress))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = await process_all(data_feed)\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428bbe6-097f-48bb-9472-f6b8587b324a",
   "metadata": {},
   "source": [
    "## Clean up json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb5ce3d-fab8-4aa5-8d5f-54335ea2c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>response</th>\n",
       "      <th>signals_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>72</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 1726411658241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173</td>\n",
       "      <td>23</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 1506665873936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>73</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 170, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>73</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 171, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>73</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 172, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80</td>\n",
       "      <td>23</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 80, 'headline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 152, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>158</td>\n",
       "      <td>66</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 158, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160</td>\n",
       "      <td>71</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 160, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170</td>\n",
       "      <td>73</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 170, 'headlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>[\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...</td>\n",
       "      <td>[{'insight_id': 1, 'company_id': 23, 'headline...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    competitor_id  company_id  \\\n",
       "0             165          72   \n",
       "1             173          23   \n",
       "2             170          73   \n",
       "3             171          73   \n",
       "4             172          73   \n",
       "5              80          23   \n",
       "6             152          23   \n",
       "7             158          66   \n",
       "8             160          71   \n",
       "9             170          73   \n",
       "10             23          23   \n",
       "\n",
       "                                             response  \\\n",
       "0   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "1   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "2   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "3   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "4   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "5   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "6   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "7   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "8   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "9   [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "10  [\\n  {\\n    \"insight_id\": 1,\\n    \"company_id\"...   \n",
       "\n",
       "                                           signals_v1  \n",
       "0   [{'insight_id': 1, 'company_id': 1726411658241...  \n",
       "1   [{'insight_id': 1, 'company_id': 1506665873936...  \n",
       "2   [{'insight_id': 1, 'company_id': 170, 'headlin...  \n",
       "3   [{'insight_id': 1, 'company_id': 171, 'headlin...  \n",
       "4   [{'insight_id': 1, 'company_id': 172, 'headlin...  \n",
       "5   [{'insight_id': 1, 'company_id': 80, 'headline...  \n",
       "6   [{'insight_id': 1, 'company_id': 152, 'headlin...  \n",
       "7   [{'insight_id': 1, 'company_id': 158, 'headlin...  \n",
       "8   [{'insight_id': 1, 'company_id': 160, 'headlin...  \n",
       "9   [{'insight_id': 1, 'company_id': 170, 'headlin...  \n",
       "10  [{'insight_id': 1, 'company_id': 23, 'headline...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"signals_v1\"] = results_df[\"response\"].apply(safe_json_loads)\n",
    "results_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca0f87-32ab-4ac5-bac7-959fcdfd46c8",
   "metadata": {},
   "source": [
    "# Combine similar themes and content via LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05879913-efce-45b2-bbc8-e773d3361f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_signal_report = (\n",
    "    results_df\n",
    "    .groupby(\"company_id\", as_index=False)\n",
    "    .agg({\n",
    "        \"competitor_id\": list,\n",
    "        \"signals_v1\": list,\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92e22e-0e48-4283-b1a1-d05a0b95afab",
   "metadata": {},
   "source": [
    "## Prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "871dd8a1-37d2-47ae-ab21-719d4c1f2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompt has been locked and loaded.\n"
     ]
    }
   ],
   "source": [
    "final_signals_prompt = f\"\"\"\n",
    "You have been given a JSON list of key insights from a competitive intelligence report for you client.\n",
    "\n",
    "Each object in the list represents an insight about your client's competitor.\n",
    "\n",
    "Your task is to combine and clean up redundant or overlapping insights **within each competitor's list** while keeping the JSON format clean and consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Instructions\n",
    "\n",
    "1. **Input Format**\n",
    "   - The input JSON is a list of objects or lists, each representing one competitor's collection of insights.\n",
    "   - Each insight object contains:\n",
    "     - `theme_id`\n",
    "     - `company_id`\n",
    "     - `headline`\n",
    "     - `insight`\n",
    "     - `supporting_content` (an array of source objects)\n",
    "\n",
    "2. **What to Do**\n",
    "   - For each competitor:\n",
    "     * Identify insights that are highly similar or cover the same topic.\n",
    "       - Example: ‚ÄúSqures AI adoption threatens scribe headcount‚Äù and ‚ÄúSquares AI scribes replacing human scribes‚Äù are redundant.\n",
    "     * Merge those into a single, stronger insight.\n",
    "     * Each insight can have a mix of different types of sources (news, linkedin posts, reddit posts, etc). They do not have to contain all the same type of source like they do in the initial data file.\n",
    "\n",
    "3. **How to Merge**\n",
    "   - **`headline`:** Write a new, concise, and accurate headline summarizing the merged idea.\n",
    "   - **`insight`:** Combine and synthesize the text of all related insights into a single coherent paragraph.\n",
    "   - **`supporting_content`:** Merge the arrays from all related insights (deduplicate identical links if possible).\n",
    "   - **IDs:** Keep the `theme_id` and `company_id` from the first theme in the merged group.\n",
    "\n",
    "4. **Keep Unique Insights**\n",
    "   - Insights that are distinct should remain unmerged and unchanged.\n",
    "\n",
    "5. **Writing a great headline**\n",
    "             \n",
    "## Headline Formula:\n",
    "**\"[Company] is [doing X] to [achieve Y]\"**\n",
    "**\"[Insight] is [happening] to [achieve Y]\"**\n",
    "\n",
    "A good headline answers: What are they doing, and why does it matter?\n",
    "\n",
    "## Headline Guidelines:\n",
    "‚úÖ DO write in plain language‚Äîif it sounds like jargon, rewrite it\n",
    "‚úÖ DO state the action and the consequence in one sentence\n",
    "‚úÖ DO keep it short (under 15 words ideal)\n",
    "‚úÖ DO use present progressive (\"is using,\" \"is targeting,\" \"is pushing\")\n",
    "‚úÖ When possible, use name the company at the start if the company name is available\n",
    "\n",
    "‚ùå DON'T use filler adjectives (aggressively, strategically, actively)\n",
    "‚ùå DON'T use business jargon (GTM, leverage, scale, accelerate, lock-in)\n",
    "‚ùå DON'T use colons or dashes to separate company from headline\n",
    "‚ùå DON'T list tactics‚Äîstate what they're doing and who it affects\n",
    "‚ùå DON'T write anything you wouldn't say out loud to a colleague\n",
    "\n",
    "## Good Examples:\n",
    "- DoorDash is using vague drop-off policies to avoid refunds and shift costs to restaurants\n",
    "- DoorDash is recruiting liquor stores with paid ads to grow selection and block rival growth\n",
    "- Nabla is hiring sales leaders in the US to push into enterprise healthcare\n",
    "- Healthcare AI startups are losing customer trust as AI tools falter\n",
    "\n",
    "## Bad Examples:\n",
    "- \"DoorDash: Leveraging Policy Ambiguity to Reduce Payout Exposure\" (jargon, colon format)\n",
    "- \"Scaling commercial GTM and building market credibility\" (no company, no plain language)\n",
    "- \"Aggressively targeting alcohol merchants to expand assortment\" (filler adjective, missing company)\n",
    "- \"Square building proprietary POS hardware to increase lock-in\" (missing \"is\", jargon)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Output Format Requirements\n",
    "\n",
    "* The final output must be valid JSON.\n",
    "* It should remain a **list**, where each element represents one company's full list of insights.\n",
    "* Do **not** reintroduce a `\"strategic_themes\"` wrapper or any extra keys.\n",
    "* Each insight should include exactly:\n",
    "  - `insight_id`\n",
    "  - `company_id`\n",
    "  - `headline` (keep this short, ideally only about 5-7 words)\n",
    "  - `insight` (this should be one sentence max)\n",
    "  - `supporting_content` (with title, url, relevance, content_id, source)\n",
    "\n",
    "Example structure:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"insight_id\": 1,\n",
    "    \"company_id\": 78,\n",
    "    \"headline\": \"Ambience prioritizing remote-friendly hiring\",\n",
    "    \"insight\": \"Ambience is positioning itself as hybrid/remote-friendly...\",\n",
    "    \"supporting_content\": [\n",
    "      {{\n",
    "        \"title\": \"Ambience Healthcare - Jobs\",\n",
    "        \"url\": \"https://jobs.ashbyhq.com/ambiencehealthcare...\",\n",
    "        \"relevance\": \"Careers page highlights...\",\n",
    "        \"content_id\": 33573,\n",
    "        \"source\": \"news\"\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  [\n",
    "    {{\n",
    "      \"insight_id\": 1,\n",
    "      \"company_id\": 23,\n",
    "      \"headline\": \"AI adoption threatens scribe headcount\",\n",
    "      \"insight\": \"Healthcare organizations and EHR vendors adopting AI scribing...\",\n",
    "      \"supporting_content\": [...]\n",
    "    }},\n",
    "    {{\n",
    "      \"insight_id\": 2,\n",
    "      \"company_id\": 23,\n",
    "      \"headline\": \"Scribe burnout driving turnover\",\n",
    "      \"insight\": \"High patient volumes and low pay create burnout...\",\n",
    "      \"supporting_content\": [...]\n",
    "    }}\n",
    "  ]\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "Please analyze and return the updated, merged JSON using **only** this structure.\n",
    "\"\"\"\n",
    "print(\"‚úÖ Prompt has been locked and loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba3f1c-ce86-4042-b5ce-bf776b45506a",
   "metadata": {},
   "source": [
    "## Run through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bd7d351-ece9-41d6-91c4-903fbce2a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/5 (20%)\n",
      "‚úÖ Completed 2/5 (40%)\n",
      "‚úÖ Completed 3/5 (60%)\n",
      "‚úÖ Completed 4/5 (80%)\n",
      "‚úÖ Completed 5/5 (100%)\n",
      "‚úÖ Created signal_v2 DataFrame with 5 rows\n"
     ]
    }
   ],
   "source": [
    "async def fetch_signals_v2(prompt, company_id, progress):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"gpt-5-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            text = response.choices[0].message.content\n",
    "\n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for company_id {company_id}: {e}\")\n",
    "\n",
    "        # ---- Update progress safely ----\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            done = progress[\"done\"]\n",
    "            total = progress[\"total\"]\n",
    "            print(f\"‚úÖ Completed {done}/{total} ({done/total:.0%})\")\n",
    "\n",
    "        # ---- Return standardized row ----\n",
    "        return {\n",
    "            \"company_id\": company_id,\n",
    "            \"signals_v2\": text\n",
    "        }\n",
    "        \n",
    "async def process_all_signals(df, final_signals_prompt):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        company_id = row[\"company_id\"]\n",
    "        signals_text = row[\"signals_v1\"]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        {final_signals_prompt}\n",
    "\n",
    "        **Key Insights JSON:**\n",
    "        {signals_text}\n",
    "        \"\"\"\n",
    "\n",
    "        tasks.append(\n",
    "            fetch_signals_v2(prompt, company_id, progress)\n",
    "        )\n",
    "\n",
    "    # Run all tasks\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "results = await process_all_signals(draft_signal_report, final_signals_prompt)\n",
    "\n",
    "# Convert to DataFrame\n",
    "signal_v2 = pd.DataFrame(results)\n",
    "print(f\"‚úÖ Created signal_v2 DataFrame with {len(signal_v2)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fe177-4f2d-4189-b5ef-e5a7365a0760",
   "metadata": {},
   "source": [
    "# Prep data to write back to Supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7c580-b25f-4ead-8336-faff6fe1220a",
   "metadata": {},
   "source": [
    "## Convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b970ef9f-d5d4-4839-8a7b-e0a472e1c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created flattened DataFrame with 33 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insight_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content_title</th>\n",
       "      <th>url</th>\n",
       "      <th>relevance</th>\n",
       "      <th>content_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Epical Health is running sustained Google Ads</td>\n",
       "      <td>Epical Health is running sustained Google ad c...</td>\n",
       "      <td>Epical Health creative CR04920972368668524545</td>\n",
       "      <td>https://adstransparency.google.com/advertiser/...</td>\n",
       "      <td>Ad entry shows active campaign starting 2025-0...</td>\n",
       "      <td>82348</td>\n",
       "      <td>ads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   insight_id  company_id competitor_id  \\\n",
       "0           1          23          None   \n",
       "\n",
       "                                           title  \\\n",
       "0  Epical Health is running sustained Google Ads   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Epical Health is running sustained Google ad c...   \n",
       "\n",
       "                                   content_title  \\\n",
       "0  Epical Health creative CR04920972368668524545   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://adstransparency.google.com/advertiser/...   \n",
       "\n",
       "                                           relevance content_id source  \n",
       "0  Ad entry shows active campaign starting 2025-0...      82348    ads  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for _, row in signal_v2.iterrows():\n",
    "    company_id = row[\"company_id\"]\n",
    "    themes_raw = row[\"signals_v2\"]\n",
    "\n",
    "    # Parse JSON string safely\n",
    "    try:\n",
    "        themes = json.loads(themes_raw)\n",
    "    except (TypeError, json.JSONDecodeError):\n",
    "        continue\n",
    "\n",
    "    # Skip if not a list\n",
    "    if not isinstance(themes, list):\n",
    "        continue\n",
    "\n",
    "    # Handle nested list-of-lists structure\n",
    "    for inner in themes:\n",
    "        # if a single theme dict was wrapped in another list, flatten it\n",
    "        if isinstance(inner, list):\n",
    "            inner_themes = inner\n",
    "        else:\n",
    "            inner_themes = [inner]\n",
    "\n",
    "        for theme in inner_themes:\n",
    "            if not isinstance(theme, dict):\n",
    "                continue\n",
    "\n",
    "            headline = theme.get(\"headline\")\n",
    "            insight = theme.get(\"insight\")\n",
    "            theme_id = theme.get(\"insight_id\")\n",
    "\n",
    "            for item in theme.get(\"supporting_content\", []):\n",
    "                records.append({\n",
    "                    \"insight_id\": theme_id,\n",
    "                    \"company_id\": company_id,\n",
    "                    \"competitor_id\": item.get(\"competitor_id\"),\n",
    "                    \"title\": headline,\n",
    "                    \"summary\": insight,\n",
    "                    \"content_title\": item.get(\"title\"),\n",
    "                    \"url\": item.get(\"url\"),\n",
    "                    \"relevance\": item.get(\"relevance\"),\n",
    "                    \"content_id\": item.get(\"content_id\"),\n",
    "                    \"source\": item.get(\"source\")\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "content_data_feed = pd.DataFrame(records)\n",
    "\n",
    "print(f\"‚úÖ Created flattened DataFrame with {len(content_data_feed)} rows.\")\n",
    "content_data_feed.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0611f3-9c2a-4c17-80e4-4fc6cf532362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insight_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>competitor_id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content_title</th>\n",
       "      <th>url</th>\n",
       "      <th>relevance</th>\n",
       "      <th>content_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Epical Health is running sustained Google Ads</td>\n",
       "      <td>Epical Health is running sustained Google ad c...</td>\n",
       "      <td>Epical Health creative CR04920972368668524545</td>\n",
       "      <td>https://adstransparency.google.com/advertiser/...</td>\n",
       "      <td>Ad entry shows active campaign starting 2025-0...</td>\n",
       "      <td>82348</td>\n",
       "      <td>ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Epical Health is running sustained Google Ads</td>\n",
       "      <td>Epical Health is running sustained Google ad c...</td>\n",
       "      <td>Epical Health image creative (archive/simgad/1...</td>\n",
       "      <td>https://adstransparency.google.com/advertiser/...</td>\n",
       "      <td>Image-format creative active 2025-07-06 to 202...</td>\n",
       "      <td>82341</td>\n",
       "      <td>ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Epical Health is running sustained Google Ads</td>\n",
       "      <td>Epical Health is running sustained Google ad c...</td>\n",
       "      <td>Epical Health creative CR04201105845217394689</td>\n",
       "      <td>https://adstransparency.google.com/advertiser/...</td>\n",
       "      <td>Text-format creative with start 2026-01-24 and...</td>\n",
       "      <td>82330</td>\n",
       "      <td>ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Abridge is being grouped with workforce‚Äëamplif...</td>\n",
       "      <td>Analyst coverage groups Abridge with other wor...</td>\n",
       "      <td>Key takeaways from the First Analysis Healthca...</td>\n",
       "      <td>https://www.linkedin.com/posts/first-analysis_...</td>\n",
       "      <td>Groups Abridge with other 'LaborProductivity /...</td>\n",
       "      <td>30179</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>Suki is hiring public‚Äëhealth talent for govern...</td>\n",
       "      <td>Suki is recruiting hires with public‚Äëhealth ex...</td>\n",
       "      <td>Beyond excited to be spending Valentine‚Äôs Day ...</td>\n",
       "      <td>https://www.linkedin.com/posts/sara-e-lamb_kel...</td>\n",
       "      <td>A Suki employee highlights prior PEPFAR/USAID ...</td>\n",
       "      <td>30174</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   insight_id  company_id competitor_id  \\\n",
       "0           1          23          None   \n",
       "1           1          23          None   \n",
       "2           1          23          None   \n",
       "3           1          23          None   \n",
       "4           2          23          None   \n",
       "\n",
       "                                               title  \\\n",
       "0      Epical Health is running sustained Google Ads   \n",
       "1      Epical Health is running sustained Google Ads   \n",
       "2      Epical Health is running sustained Google Ads   \n",
       "3  Abridge is being grouped with workforce‚Äëamplif...   \n",
       "4  Suki is hiring public‚Äëhealth talent for govern...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Epical Health is running sustained Google ad c...   \n",
       "1  Epical Health is running sustained Google ad c...   \n",
       "2  Epical Health is running sustained Google ad c...   \n",
       "3  Analyst coverage groups Abridge with other wor...   \n",
       "4  Suki is recruiting hires with public‚Äëhealth ex...   \n",
       "\n",
       "                                       content_title  \\\n",
       "0      Epical Health creative CR04920972368668524545   \n",
       "1  Epical Health image creative (archive/simgad/1...   \n",
       "2      Epical Health creative CR04201105845217394689   \n",
       "3  Key takeaways from the First Analysis Healthca...   \n",
       "4  Beyond excited to be spending Valentine‚Äôs Day ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://adstransparency.google.com/advertiser/...   \n",
       "1  https://adstransparency.google.com/advertiser/...   \n",
       "2  https://adstransparency.google.com/advertiser/...   \n",
       "3  https://www.linkedin.com/posts/first-analysis_...   \n",
       "4  https://www.linkedin.com/posts/sara-e-lamb_kel...   \n",
       "\n",
       "                                           relevance content_id    source  \n",
       "0  Ad entry shows active campaign starting 2025-0...      82348       ads  \n",
       "1  Image-format creative active 2025-07-06 to 202...      82341       ads  \n",
       "2  Text-format creative with start 2026-01-24 and...      82330       ads  \n",
       "3  Groups Abridge with other 'LaborProductivity /...      30179  linkedin  \n",
       "4  A Suki employee highlights prior PEPFAR/USAID ...      30174  linkedin  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_data_feed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfa237-85e5-4ceb-94c0-e863bf7be107",
   "metadata": {},
   "source": [
    "### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af2e3387-c490-4d85-b7bd-964a8d8c0b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 signals created...\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates by headline to avoid inserting twice\n",
    "unique_signals = content_data_feed[[\"title\", \"summary\", \"company_id\"]].drop_duplicates().to_dict(orient=\"records\")\n",
    "print(f\"{len(unique_signals)} signals created...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a136e-b6a7-4b23-a906-fabc3c4e3030",
   "metadata": {},
   "source": [
    "## Write insights to db, grab ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8166d0db-403e-4b42-a140-ee822548a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted 18 signals.\n"
     ]
    }
   ],
   "source": [
    "# Insert headlines and grab ids\n",
    "insert_response = supabase.table(\"signals\").insert(unique_signals).execute()\n",
    "signals_inserted = insert_response.data\n",
    "print(f\"‚úÖ Inserted {len(signals_inserted)} signals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eef28f6-ca47-4941-b6e1-591fa4861297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associated ids with headlines...\n"
     ]
    }
   ],
   "source": [
    "headline_to_id = {row[\"title\"]: row[\"id\"] for row in signals_inserted}\n",
    "print(f\"Associated ids with headlines...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b0a3d-150e-4db4-95c5-8b3f44b76428",
   "metadata": {},
   "source": [
    "## Update db associating content to insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72d18518-a3f0-4b02-8c36-b524acf0ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Updated db with 33 insights...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Create join table entries for `news_feed_signals` ---\n",
    "join_rows = []\n",
    "for _, row in content_data_feed.iterrows():\n",
    "    headline = row[\"title\"]\n",
    "    if headline not in headline_to_id:\n",
    "        continue\n",
    "    join_rows.append({\n",
    "        \"headline\": headline,\n",
    "        \"signal_id\": headline_to_id[headline],\n",
    "        \"content_id\": row[\"content_id\"],\n",
    "        \"source\": row[\"source\"]\n",
    "    })\n",
    "print(f\" Updated db with {len(join_rows)} insights...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc77e62-e99e-431a-abc4-f8ecf7b32ec7",
   "metadata": {},
   "source": [
    "## Send to supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9575cc15-6959-4e20-a755-aa10d84d3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted 9 ads ‚Üí signal links into ad_library_signals\n",
      "‚úÖ Inserted 3 linkedin ‚Üí signal links into linkedin_feed_signals\n",
      "‚úÖ Inserted 1 reddit ‚Üí signal links into reddit_feed_signals\n",
      "‚úÖ Inserted 7 news ‚Üí signal links into news_feed_signals\n",
      "‚úÖ Inserted 13 jobs ‚Üí signal links into jobs_feed_signals\n"
     ]
    }
   ],
   "source": [
    "if not join_rows:\n",
    "    print(\"‚ö†Ô∏è No join records created\")\n",
    "else:\n",
    "    # Group join_rows by source\n",
    "    grouped = {}\n",
    "    for row in join_rows:\n",
    "        src = row.get(\"source\")\n",
    "        grouped.setdefault(src, []).append(row)\n",
    "\n",
    "    for source, rows in grouped.items():\n",
    "        # Correct table map\n",
    "        table_map = {\n",
    "            \"news\": (\"news_feed_signals\", \"news_feed_id\"),\n",
    "            \"linkedin\": (\"linkedin_feed_signals\", \"linkedin_feed_id\"),\n",
    "            \"reddit\": (\"reddit_feed_signals\", \"reddit_feed_id\"),\n",
    "            \"jobs\": (\"jobs_feed_signals\", \"jobs_feed_id\"),\n",
    "            \"ads\": (\"ad_library_signals\", \"ad_library_feed_id\"),\n",
    "        }\n",
    "\n",
    "        if source not in table_map:\n",
    "            print(f\"‚ö†Ô∏è Skipping unknown source '{source}'\")\n",
    "            continue\n",
    "\n",
    "        table_name, content_field = table_map[source]\n",
    "\n",
    "        # Build insert rows\n",
    "        insert_rows = []\n",
    "        for r in rows:\n",
    "            signal_id = r.get(\"signal_id\")\n",
    "            content_id = r.get(\"content_id\")\n",
    "\n",
    "            if signal_id is None or content_id is None:\n",
    "                continue\n",
    "\n",
    "            insert_rows.append({\n",
    "                \"signal_id\": signal_id,\n",
    "                content_field: content_id\n",
    "            })\n",
    "\n",
    "        if not insert_rows:\n",
    "            print(f\"‚ö†Ô∏è No valid rows for source '{source}'\")\n",
    "            continue\n",
    "\n",
    "        # INSERT (no upsert)\n",
    "        try:\n",
    "            supabase.table(table_name).insert(insert_rows).execute()\n",
    "            print(f\"‚úÖ Inserted {len(insert_rows)} {source} ‚Üí signal links into {table_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inserting into {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8baff76-09d6-480f-b063-432d3ab0fdd6",
   "metadata": {},
   "source": [
    "# Enhance signal records with details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e924c37d-94d7-4e2d-8bf1-ce9f5d6cbcef",
   "metadata": {},
   "source": [
    "## Add Headline and signal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e511f90-9774-4993-aa74-d29e779f2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 18 signals...\n"
     ]
    }
   ],
   "source": [
    "# Convert join_rows to df\n",
    "join_df = pd.DataFrame(join_rows)\n",
    "print(f\"There are currently {join_df[\"signal_id\"].nunique()} signals...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e55c3826-54b6-4ed5-a788-0062cfdc9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are are now 18 signals...\n"
     ]
    }
   ],
   "source": [
    "# Convert both fields to integers so they can map\n",
    "join_df[\"content_id\"] = pd.to_numeric(join_df[\"content_id\"], errors=\"coerce\")\n",
    "data_feed_combined[\"id\"] = pd.to_numeric(data_feed_combined[\"id\"], errors=\"coerce\")\n",
    "\n",
    "# Merge dataframes\n",
    "data_feed_with_headlines = join_df.merge(\n",
    "    data_feed_combined[[\"id\", \"content_json\", \"company_id\", \"competitor_id\"]],\n",
    "    left_on=\"content_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"There are are now {data_feed_with_headlines[\"signal_id\"].nunique()} signals...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ad19b-65aa-46b6-bf11-b8710b9ec031",
   "metadata": {},
   "source": [
    "## Group by signal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28d8075d-b0e6-4eea-a851-52e794bd765f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>content_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>content_json</th>\n",
       "      <th>company_id</th>\n",
       "      <th>competitor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2810</td>\n",
       "      <td>[Epical Health is running sustained Google Ads...</td>\n",
       "      <td>[82348, 82341, 82330]</td>\n",
       "      <td>[ads, ads, ads]</td>\n",
       "      <td>[82348, 82341, 82330]</td>\n",
       "      <td>[{\"content_id\": 82348, \"json_response\": \"{\\\"ad...</td>\n",
       "      <td>[23, 23, 23]</td>\n",
       "      <td>[173, 173, 173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2811</td>\n",
       "      <td>[Abridge is being grouped with workforce‚Äëampli...</td>\n",
       "      <td>[30179]</td>\n",
       "      <td>[linkedin]</td>\n",
       "      <td>[30179]</td>\n",
       "      <td>[{\"content_id\": 30179, \"author_fullName\": \"Fir...</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2812</td>\n",
       "      <td>[Suki is hiring public‚Äëhealth talent for gover...</td>\n",
       "      <td>[30174]</td>\n",
       "      <td>[linkedin]</td>\n",
       "      <td>[30174]</td>\n",
       "      <td>[{\"content_id\": 30174, \"author_fullName\": \"Sar...</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2813</td>\n",
       "      <td>[Research report is grouping cloud and EHR ven...</td>\n",
       "      <td>[30131]</td>\n",
       "      <td>[linkedin]</td>\n",
       "      <td>[30131]</td>\n",
       "      <td>[{\"content_id\": 30131, \"author_fullName\": \"Joh...</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2814</td>\n",
       "      <td>[Clinicians are choosing iPad Minis for bedsid...</td>\n",
       "      <td>[24944]</td>\n",
       "      <td>[reddit]</td>\n",
       "      <td>[24944]</td>\n",
       "      <td>[{\"content_id\": 24944, \"text\": \"I recently acc...</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id                                           headline  \\\n",
       "0       2810  [Epical Health is running sustained Google Ads...   \n",
       "1       2811  [Abridge is being grouped with workforce‚Äëampli...   \n",
       "2       2812  [Suki is hiring public‚Äëhealth talent for gover...   \n",
       "3       2813  [Research report is grouping cloud and EHR ven...   \n",
       "4       2814  [Clinicians are choosing iPad Minis for bedsid...   \n",
       "\n",
       "              content_id           source                     id  \\\n",
       "0  [82348, 82341, 82330]  [ads, ads, ads]  [82348, 82341, 82330]   \n",
       "1                [30179]       [linkedin]                [30179]   \n",
       "2                [30174]       [linkedin]                [30174]   \n",
       "3                [30131]       [linkedin]                [30131]   \n",
       "4                [24944]         [reddit]                [24944]   \n",
       "\n",
       "                                        content_json    company_id  \\\n",
       "0  [{\"content_id\": 82348, \"json_response\": \"{\\\"ad...  [23, 23, 23]   \n",
       "1  [{\"content_id\": 30179, \"author_fullName\": \"Fir...          [23]   \n",
       "2  [{\"content_id\": 30174, \"author_fullName\": \"Sar...          [23]   \n",
       "3  [{\"content_id\": 30131, \"author_fullName\": \"Joh...          [23]   \n",
       "4  [{\"content_id\": 24944, \"text\": \"I recently acc...          [23]   \n",
       "\n",
       "     competitor_id  \n",
       "0  [173, 173, 173]  \n",
       "1             [80]  \n",
       "2             [80]  \n",
       "3            [152]  \n",
       "4             [23]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_to_group = [\n",
    "    \"headline\",\n",
    "    \"content_id\",\n",
    "    \"source\",\n",
    "    \"id\",\n",
    "    \"content_json\",\n",
    "    \"company_id\",\n",
    "    \"competitor_id\",\n",
    "]\n",
    "\n",
    "# Group by signal_id and aggregate each field into lists\n",
    "signal_content_grouped = (\n",
    "    data_feed_with_headlines\n",
    "    .groupby(\"signal_id\")[fields_to_group]\n",
    "    .agg(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "signal_content_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d6340f-a6ef-422c-8348-3310c23cc222",
   "metadata": {},
   "source": [
    "# Send to LLM to add details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fde945-12f7-4003-b0ca-87e38c1942a6",
   "metadata": {},
   "source": [
    "## Hit the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84bcb36b-299a-45fd-9fde-54d139813ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/18\n",
      "‚úÖ Completed 2/18\n",
      "‚úÖ Completed 3/18\n",
      "‚úÖ Completed 4/18\n",
      "‚úÖ Completed 5/18\n",
      "‚úÖ Completed 6/18\n",
      "‚úÖ Completed 7/18\n",
      "‚úÖ Completed 8/18\n",
      "‚úÖ Completed 9/18\n",
      "‚úÖ Completed 10/18\n",
      "‚úÖ Completed 11/18\n",
      "‚úÖ Completed 12/18\n",
      "‚úÖ Completed 13/18\n",
      "‚úÖ Completed 14/18\n",
      "‚úÖ Completed 15/18\n",
      "‚úÖ Completed 16/18\n",
      "‚úÖ Completed 17/18\n",
      "‚úÖ Completed 18/18\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# SWITCHED TO PRO\n",
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "\n",
    "MAX_CONCURRENCY = 50\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "# 2. Initialize the model with JSON mode enabled\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0,\n",
    "        \"response_mime_type\": \"text/plain\"\n",
    "    }\n",
    ")\n",
    "\n",
    "async def fetch_response(prompt, headline, signal_id, progress):\n",
    "    async with semaphore:\n",
    "        text = None\n",
    "        try:\n",
    "            response = await model.generate_content_async(prompt)\n",
    "            text = response.text\n",
    "             \n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for id {headline}: {e}\")\n",
    "\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            print(f\"‚úÖ Completed {progress['done']}/{progress['total']}\")\n",
    "\n",
    "        return {\n",
    "            \"headline\": headline,\n",
    "            \"signal_id\" : signal_id,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "            Analyze the following content and produce a detailed competitive-intelligence extract written in clean, valid Markdown.\n",
    "            Don't say things like \"we\" or \"our\", this is for a client, you aren't writing this as if you are part of the team.\n",
    "            Use bullets for everything, do not number anything.\n",
    "            \n",
    "            You are a competitive analyst extracting actionable intelligence for strategic decision-makers who need to understand:\n",
    "            1. What the competitor is doing\n",
    "            2. Why it matters to us\n",
    "            3. What we should watch or do about it\n",
    "            4. Make sure the insights are focused on the competitor(s) mentioned in the title and summary section\n",
    "            \n",
    "            Your output must follow these formatting rules:\n",
    "            - Use ## for all major section headings\n",
    "            - Use standard markdown bullet points (- or *) for all lists\n",
    "            - Keep bullets SHORT - one clear point per bullet, ideally one sentence max\n",
    "            - Bold key phrases using **double asterisks** to enable skimming\n",
    "            - each heading should only have 3-5 key points\n",
    "\n",
    "            CITATION STRUCTURE - STRICT RULE\n",
    "            When citing specific facts, quotes, or claims, you MUST use this exact format:\n",
    "            \n",
    "            [text](URL)\n",
    "            \n",
    "            Do NOT use any other format as it will break the frontend of the app.\n",
    "            \n",
    "            - Example: \"Freshworks reports [15% revenue growth](https://...) during 2025 Q3.*\"\n",
    "            \n",
    "            REQUIRED STRUCTURE (in this exact order):\n",
    "\n",
    "            ## Overview\n",
    "            \n",
    "            [2-3 bullet points the strategic implication, their vulnerabilities, and recommended competitive response]\n",
    "            \n",
    "            ## What You Need to Know\n",
    "            \n",
    "            [3-4 bullet points that captures the competitive situation, momentum, and key context]\n",
    "            \n",
    "            ## The Threat to Watch\n",
    "\n",
    "            - Short, punchy bullets (1-2 sentences each)\n",
    "            - 3-5 key competitive threats or moves\n",
    "            - Focus on impact to your business\n",
    "            - Call out strategic bets, resource allocation, pricing/GTM tactics\n",
    "            - Note capability gaps or weaknesses\n",
    "            \n",
    "            ## What to Monitor\n",
    "            \n",
    "            - Short bulleted items - one specific signal per line\n",
    "            - 3-5 concrete, actionable monitoring points\n",
    "            - Each should be scannable at a glance\n",
    "            \n",
    "            ADDITIONAL GUIDANCE:\n",
    "            - Include relevant financial metrics, growth rates, or market position data\n",
    "            - Note product/technology bets and positioning claims\n",
    "            - Highlight partnership or GTM initiatives\n",
    "            - Identify execution risks or organizational challenges\n",
    "            - Every bullet should be independently useful - no filler\n",
    "            - Source links should be linked to the actual text inline\n",
    "                - Example: \"Freshworks reports [15% revenue growth](https://...) during 2025 Q3.*\"\n",
    "\n",
    "            CITATION FORMAT (STRICT ‚Äî WRAP THE CLAIM TEXT)\n",
    "            \n",
    "            ‚úÖ Correct:\n",
    "            - Freshworks reports [15% revenue growth](https://...) during 2025 Q3.\n",
    "            - Oracle is hiring to scale [a global, personalized health ecosystem](https://...)\n",
    "            - The company launched [‚ÄúAutopilot for Finance‚Äù](https://...) for mid-market teams.\n",
    "            \n",
    "            Aim for 250-350 words total. Optimize for speed-reading and scannability.\n",
    "            \n",
    "            Now analyze this content:\n",
    "\n",
    "            {row['content_json']}\n",
    "            \"\"\"\n",
    "        # print(prompt)\n",
    "        tasks.append(fetch_response(prompt, row[\"headline\"], row[\"signal_id\"], progress))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "signal_enrichment = await process_all(signal_content_grouped)\n",
    "signal_enrichment_df = pd.DataFrame(signal_enrichment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "072becd4-6318-401f-ad3d-2487732194ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Epical Health is running sustained Google Ads...</td>\n",
       "      <td>2810</td>\n",
       "      <td>## Overview\\n\\n*   Epical Health is executing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  signal_id  \\\n",
       "0  [Epical Health is running sustained Google Ads...       2810   \n",
       "\n",
       "                                            response  \n",
       "0  ## Overview\\n\\n*   Epical Health is executing ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_enrichment_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3248e-5b98-4089-a56e-7e0315b5e294",
   "metadata": {},
   "source": [
    "## Update signals in supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1c65f97-a2d9-496d-841f-9744ae5049ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated signal_id 2810\n",
      "‚úÖ Updated signal_id 2811\n",
      "‚úÖ Updated signal_id 2812\n",
      "‚úÖ Updated signal_id 2813\n",
      "‚úÖ Updated signal_id 2814\n",
      "‚úÖ Updated signal_id 2815\n",
      "‚úÖ Updated signal_id 2816\n",
      "‚úÖ Updated signal_id 2817\n",
      "‚úÖ Updated signal_id 2818\n",
      "‚úÖ Updated signal_id 2819\n",
      "‚úÖ Updated signal_id 2820\n",
      "‚úÖ Updated signal_id 2821\n",
      "‚úÖ Updated signal_id 2822\n",
      "‚úÖ Updated signal_id 2823\n",
      "‚úÖ Updated signal_id 2824\n",
      "‚úÖ Updated signal_id 2825\n",
      "‚úÖ Updated signal_id 2826\n",
      "‚úÖ Updated signal_id 2827\n"
     ]
    }
   ],
   "source": [
    "def update_signal_details(df):\n",
    "    for _, row in df.iterrows():\n",
    "        signal_id = int(row[\"signal_id\"])\n",
    "        details = row[\"response\"]\n",
    "        # summary = row[\"summary\"]\n",
    "\n",
    "        if not signal_id or pd.isna(signal_id):\n",
    "            print(f\"‚ö†Ô∏è Skipping row with no signal_id: {row}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            resp = (\n",
    "                supabase.table(\"signals\")\n",
    "                .update({\n",
    "                        \"details\": details,\n",
    "                        # \"summary\": summary\n",
    "                    })\n",
    "                .eq(\"id\", signal_id)\n",
    "                .execute()\n",
    "            )\n",
    "            print(f\"‚úÖ Updated signal_id {signal_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error updating signal_id {signal_id}: {e}\")\n",
    "\n",
    "# Run updates\n",
    "update_signal_details(signal_enrichment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035df4d-4c35-4ef6-b36b-9b1940bcf407",
   "metadata": {},
   "source": [
    "## Update all IDs to processed == true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f93cf8e-74e2-4944-8bab-95dbed6499a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Updating 55 rows in news_feed...\n",
      "‚úÖ Updated processed = TRUE for news_feed.\n",
      "üîß Updating 7 rows in linkedin_feed...\n",
      "‚úÖ Updated processed = TRUE for linkedin_feed.\n",
      "üîß Updating 4 rows in reddit_posts...\n",
      "‚úÖ Updated processed = TRUE for reddit_posts.\n",
      "üîß Updating 79 rows in jobs...\n",
      "‚úÖ Updated processed = TRUE for jobs.\n",
      "üîß Updating 111 rows in ad_library...\n",
      "‚úÖ Updated processed = TRUE for ad_library.\n"
     ]
    }
   ],
   "source": [
    "# --- Tables you want to update ---\n",
    "update_tables = [\"news_feed\", \"linkedin_feed\", \"reddit_posts\", \"jobs\", \"ad_library\"]\n",
    "\n",
    "for table in update_tables:\n",
    "    df = feeds.get(table)\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(f\"‚ö†Ô∏è No data to update for {table}\")\n",
    "        continue\n",
    "\n",
    "    # Extract all IDs returned in your earlier query\n",
    "    ids_to_update = df[\"id\"].tolist()\n",
    "\n",
    "    print(f\"üîß Updating {len(ids_to_update)} rows in {table}...\")\n",
    "\n",
    "    # Batch update using .in_()\n",
    "    resp = (\n",
    "        supabase.table(table)\n",
    "        .update({\"processed\": True})\n",
    "        .in_(\"id\", ids_to_update)\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Updated processed = TRUE for {table}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f871bca-87b5-43a5-b258-a6ee85177e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished running signals feed at 2026-02-06 19:29:21\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Finished running signals feed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697f49d-9295-491c-9974-7b83cfebabb6",
   "metadata": {},
   "source": [
    "# Update signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a307bdb-1ee9-4f98-adcb-b137dd17742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_signals = feeds[\"signals\"]\n",
    "len(existing_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1a6f98e-2a6c-46af-8625-4c4499a3a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed 1/931 (0%)\n",
      "‚úÖ Completed 2/931 (0%)\n",
      "‚úÖ Completed 3/931 (0%)\n",
      "‚úÖ Completed 4/931 (0%)\n",
      "‚úÖ Completed 5/931 (1%)\n",
      "‚úÖ Completed 6/931 (1%)\n",
      "‚úÖ Completed 7/931 (1%)\n",
      "‚úÖ Completed 8/931 (1%)\n",
      "‚úÖ Completed 9/931 (1%)\n",
      "‚úÖ Completed 10/931 (1%)\n",
      "‚úÖ Completed 11/931 (1%)\n",
      "‚úÖ Completed 12/931 (1%)\n",
      "‚úÖ Completed 13/931 (1%)\n",
      "‚úÖ Completed 14/931 (2%)\n",
      "‚úÖ Completed 15/931 (2%)\n",
      "‚úÖ Completed 16/931 (2%)\n",
      "‚úÖ Completed 17/931 (2%)\n",
      "‚úÖ Completed 18/931 (2%)\n",
      "‚úÖ Completed 19/931 (2%)\n",
      "‚úÖ Completed 20/931 (2%)\n",
      "‚úÖ Completed 21/931 (2%)\n",
      "‚úÖ Completed 22/931 (2%)\n",
      "‚úÖ Completed 23/931 (2%)\n",
      "‚úÖ Completed 24/931 (3%)\n",
      "‚úÖ Completed 25/931 (3%)\n",
      "‚úÖ Completed 26/931 (3%)\n",
      "‚úÖ Completed 27/931 (3%)\n",
      "‚úÖ Completed 28/931 (3%)\n",
      "‚úÖ Completed 29/931 (3%)\n",
      "‚úÖ Completed 30/931 (3%)\n",
      "‚úÖ Completed 31/931 (3%)\n",
      "‚úÖ Completed 32/931 (3%)\n",
      "‚úÖ Completed 33/931 (4%)\n",
      "‚úÖ Completed 34/931 (4%)\n",
      "‚úÖ Completed 35/931 (4%)\n",
      "‚úÖ Completed 36/931 (4%)\n",
      "‚úÖ Completed 37/931 (4%)\n",
      "‚úÖ Completed 38/931 (4%)\n",
      "‚úÖ Completed 39/931 (4%)\n",
      "‚úÖ Completed 40/931 (4%)\n",
      "‚úÖ Completed 41/931 (4%)\n",
      "‚úÖ Completed 42/931 (5%)\n",
      "‚úÖ Completed 43/931 (5%)\n",
      "‚úÖ Completed 44/931 (5%)\n",
      "‚úÖ Completed 45/931 (5%)\n",
      "‚úÖ Completed 46/931 (5%)\n",
      "‚úÖ Completed 47/931 (5%)\n",
      "‚úÖ Completed 48/931 (5%)\n",
      "‚úÖ Completed 49/931 (5%)\n",
      "‚úÖ Completed 50/931 (5%)\n",
      "‚úÖ Completed 51/931 (5%)\n",
      "‚úÖ Completed 52/931 (6%)\n",
      "‚úÖ Completed 53/931 (6%)\n",
      "‚úÖ Completed 54/931 (6%)\n",
      "‚úÖ Completed 55/931 (6%)\n",
      "‚úÖ Completed 56/931 (6%)\n",
      "‚úÖ Completed 57/931 (6%)\n",
      "‚úÖ Completed 58/931 (6%)\n",
      "‚úÖ Completed 59/931 (6%)\n",
      "‚úÖ Completed 60/931 (6%)\n",
      "‚úÖ Completed 61/931 (7%)\n",
      "‚úÖ Completed 62/931 (7%)\n",
      "‚úÖ Completed 63/931 (7%)\n",
      "‚úÖ Completed 64/931 (7%)\n",
      "‚úÖ Completed 65/931 (7%)\n",
      "‚úÖ Completed 66/931 (7%)\n",
      "‚úÖ Completed 67/931 (7%)\n",
      "‚úÖ Completed 68/931 (7%)\n",
      "‚úÖ Completed 69/931 (7%)\n",
      "‚úÖ Completed 70/931 (8%)\n",
      "‚úÖ Completed 71/931 (8%)\n",
      "‚úÖ Completed 72/931 (8%)\n",
      "‚úÖ Completed 73/931 (8%)\n",
      "‚úÖ Completed 74/931 (8%)\n",
      "‚úÖ Completed 75/931 (8%)\n",
      "‚úÖ Completed 76/931 (8%)\n",
      "‚úÖ Completed 77/931 (8%)\n",
      "‚úÖ Completed 78/931 (8%)\n",
      "‚úÖ Completed 79/931 (8%)\n",
      "‚úÖ Completed 80/931 (9%)\n",
      "‚úÖ Completed 81/931 (9%)\n",
      "‚úÖ Completed 82/931 (9%)\n",
      "‚úÖ Completed 83/931 (9%)\n",
      "‚úÖ Completed 84/931 (9%)\n",
      "‚úÖ Completed 85/931 (9%)\n",
      "‚úÖ Completed 86/931 (9%)\n",
      "‚úÖ Completed 87/931 (9%)\n",
      "‚úÖ Completed 88/931 (9%)\n",
      "‚úÖ Completed 89/931 (10%)\n",
      "‚úÖ Completed 90/931 (10%)\n",
      "‚úÖ Completed 91/931 (10%)\n",
      "‚úÖ Completed 92/931 (10%)\n",
      "‚úÖ Completed 93/931 (10%)\n",
      "‚úÖ Completed 94/931 (10%)\n",
      "‚úÖ Completed 95/931 (10%)\n",
      "‚úÖ Completed 96/931 (10%)\n",
      "‚úÖ Completed 97/931 (10%)\n",
      "‚úÖ Completed 98/931 (11%)\n",
      "‚úÖ Completed 99/931 (11%)\n",
      "‚úÖ Completed 100/931 (11%)\n",
      "‚úÖ Completed 101/931 (11%)\n",
      "‚úÖ Completed 102/931 (11%)\n",
      "‚úÖ Completed 103/931 (11%)\n",
      "‚úÖ Completed 104/931 (11%)\n",
      "‚úÖ Completed 105/931 (11%)\n",
      "‚úÖ Completed 106/931 (11%)\n",
      "‚úÖ Completed 107/931 (11%)\n",
      "‚úÖ Completed 108/931 (12%)\n",
      "‚úÖ Completed 109/931 (12%)\n",
      "‚úÖ Completed 110/931 (12%)\n",
      "‚úÖ Completed 111/931 (12%)\n",
      "‚úÖ Completed 112/931 (12%)\n",
      "‚úÖ Completed 113/931 (12%)\n",
      "‚úÖ Completed 114/931 (12%)\n",
      "‚úÖ Completed 115/931 (12%)\n",
      "‚úÖ Completed 116/931 (12%)\n",
      "‚úÖ Completed 117/931 (13%)\n",
      "‚úÖ Completed 118/931 (13%)\n",
      "‚úÖ Completed 119/931 (13%)\n",
      "‚úÖ Completed 120/931 (13%)\n",
      "‚úÖ Completed 121/931 (13%)\n",
      "‚úÖ Completed 122/931 (13%)\n",
      "‚úÖ Completed 123/931 (13%)\n",
      "‚úÖ Completed 124/931 (13%)\n",
      "‚úÖ Completed 125/931 (13%)\n",
      "‚úÖ Completed 126/931 (14%)\n",
      "‚úÖ Completed 127/931 (14%)\n",
      "‚úÖ Completed 128/931 (14%)\n",
      "‚úÖ Completed 129/931 (14%)\n",
      "‚úÖ Completed 130/931 (14%)\n",
      "‚úÖ Completed 131/931 (14%)\n",
      "‚úÖ Completed 132/931 (14%)\n",
      "‚úÖ Completed 133/931 (14%)\n",
      "‚úÖ Completed 134/931 (14%)\n",
      "‚úÖ Completed 135/931 (15%)\n",
      "‚úÖ Completed 136/931 (15%)\n",
      "‚úÖ Completed 137/931 (15%)\n",
      "‚úÖ Completed 138/931 (15%)\n",
      "‚úÖ Completed 139/931 (15%)\n",
      "‚úÖ Completed 140/931 (15%)\n",
      "‚úÖ Completed 141/931 (15%)\n",
      "‚úÖ Completed 142/931 (15%)\n",
      "‚úÖ Completed 143/931 (15%)\n",
      "‚úÖ Completed 144/931 (15%)\n",
      "‚úÖ Completed 145/931 (16%)\n",
      "‚úÖ Completed 146/931 (16%)\n",
      "‚úÖ Completed 147/931 (16%)\n",
      "‚úÖ Completed 148/931 (16%)\n",
      "‚úÖ Completed 149/931 (16%)\n",
      "‚úÖ Completed 150/931 (16%)\n",
      "‚úÖ Completed 151/931 (16%)\n",
      "‚úÖ Completed 152/931 (16%)\n",
      "‚úÖ Completed 153/931 (16%)\n",
      "‚úÖ Completed 154/931 (17%)\n",
      "‚úÖ Completed 155/931 (17%)\n",
      "‚úÖ Completed 156/931 (17%)\n",
      "‚úÖ Completed 157/931 (17%)\n",
      "‚úÖ Completed 158/931 (17%)\n",
      "‚úÖ Completed 159/931 (17%)\n",
      "‚úÖ Completed 160/931 (17%)\n",
      "‚úÖ Completed 161/931 (17%)\n",
      "‚úÖ Completed 162/931 (17%)\n",
      "‚úÖ Completed 163/931 (18%)\n",
      "‚úÖ Completed 164/931 (18%)\n",
      "‚úÖ Completed 165/931 (18%)\n",
      "‚úÖ Completed 166/931 (18%)\n",
      "‚úÖ Completed 167/931 (18%)\n",
      "‚úÖ Completed 168/931 (18%)\n",
      "‚úÖ Completed 169/931 (18%)\n",
      "‚úÖ Completed 170/931 (18%)\n",
      "‚úÖ Completed 171/931 (18%)\n",
      "‚úÖ Completed 172/931 (18%)\n",
      "‚úÖ Completed 173/931 (19%)\n",
      "‚úÖ Completed 174/931 (19%)\n",
      "‚úÖ Completed 175/931 (19%)\n",
      "‚úÖ Completed 176/931 (19%)\n",
      "‚úÖ Completed 177/931 (19%)\n",
      "‚úÖ Completed 178/931 (19%)\n",
      "‚úÖ Completed 179/931 (19%)\n",
      "‚úÖ Completed 180/931 (19%)\n",
      "‚úÖ Completed 181/931 (19%)\n",
      "‚úÖ Completed 182/931 (20%)\n",
      "‚úÖ Completed 183/931 (20%)\n",
      "‚úÖ Completed 184/931 (20%)\n",
      "‚úÖ Completed 185/931 (20%)\n",
      "‚úÖ Completed 186/931 (20%)\n",
      "‚úÖ Completed 187/931 (20%)\n",
      "‚úÖ Completed 188/931 (20%)\n",
      "‚úÖ Completed 189/931 (20%)\n",
      "‚úÖ Completed 190/931 (20%)\n",
      "‚úÖ Completed 191/931 (21%)\n",
      "‚úÖ Completed 192/931 (21%)\n",
      "‚úÖ Completed 193/931 (21%)\n",
      "‚úÖ Completed 194/931 (21%)\n",
      "‚úÖ Completed 195/931 (21%)\n",
      "‚úÖ Completed 196/931 (21%)\n",
      "‚úÖ Completed 197/931 (21%)\n",
      "‚úÖ Completed 198/931 (21%)\n",
      "‚úÖ Completed 199/931 (21%)\n",
      "‚úÖ Completed 200/931 (21%)\n",
      "‚úÖ Completed 201/931 (22%)\n",
      "‚úÖ Completed 202/931 (22%)\n",
      "‚úÖ Completed 203/931 (22%)\n",
      "‚úÖ Completed 204/931 (22%)\n",
      "‚úÖ Completed 205/931 (22%)\n",
      "‚úÖ Completed 206/931 (22%)\n",
      "‚úÖ Completed 207/931 (22%)\n",
      "‚úÖ Completed 208/931 (22%)\n",
      "‚úÖ Completed 209/931 (22%)\n",
      "‚úÖ Completed 210/931 (23%)\n",
      "‚úÖ Completed 211/931 (23%)\n",
      "‚úÖ Completed 212/931 (23%)\n",
      "‚úÖ Completed 213/931 (23%)\n",
      "‚úÖ Completed 214/931 (23%)\n",
      "‚úÖ Completed 215/931 (23%)\n",
      "‚úÖ Completed 216/931 (23%)\n",
      "‚úÖ Completed 217/931 (23%)\n",
      "‚úÖ Completed 218/931 (23%)\n",
      "‚úÖ Completed 219/931 (24%)\n",
      "‚úÖ Completed 220/931 (24%)\n",
      "‚úÖ Completed 221/931 (24%)\n",
      "‚úÖ Completed 222/931 (24%)\n",
      "‚úÖ Completed 223/931 (24%)\n",
      "‚úÖ Completed 224/931 (24%)\n",
      "‚úÖ Completed 225/931 (24%)\n",
      "‚úÖ Completed 226/931 (24%)\n",
      "‚úÖ Completed 227/931 (24%)\n",
      "‚úÖ Completed 228/931 (24%)\n",
      "‚úÖ Completed 229/931 (25%)\n",
      "‚úÖ Completed 230/931 (25%)\n",
      "‚úÖ Completed 231/931 (25%)\n",
      "‚úÖ Completed 232/931 (25%)\n",
      "‚úÖ Completed 233/931 (25%)\n",
      "‚úÖ Completed 234/931 (25%)\n",
      "‚úÖ Completed 235/931 (25%)\n",
      "‚úÖ Completed 236/931 (25%)\n",
      "‚úÖ Completed 237/931 (25%)\n",
      "‚úÖ Completed 238/931 (26%)\n",
      "‚úÖ Completed 239/931 (26%)\n",
      "‚úÖ Completed 240/931 (26%)\n",
      "‚úÖ Completed 241/931 (26%)\n",
      "‚úÖ Completed 242/931 (26%)\n",
      "‚úÖ Completed 243/931 (26%)\n",
      "‚úÖ Completed 244/931 (26%)\n",
      "‚úÖ Completed 245/931 (26%)\n",
      "‚úÖ Completed 246/931 (26%)\n",
      "‚úÖ Completed 247/931 (27%)\n",
      "‚úÖ Completed 248/931 (27%)\n",
      "‚úÖ Completed 249/931 (27%)\n",
      "‚úÖ Completed 250/931 (27%)\n",
      "‚úÖ Completed 251/931 (27%)\n",
      "‚úÖ Completed 252/931 (27%)\n",
      "‚úÖ Completed 253/931 (27%)\n",
      "‚úÖ Completed 254/931 (27%)\n",
      "‚úÖ Completed 255/931 (27%)\n",
      "‚úÖ Completed 256/931 (27%)\n",
      "‚úÖ Completed 257/931 (28%)\n",
      "‚úÖ Completed 258/931 (28%)\n",
      "‚úÖ Completed 259/931 (28%)\n",
      "‚úÖ Completed 260/931 (28%)\n",
      "‚úÖ Completed 261/931 (28%)\n",
      "‚úÖ Completed 262/931 (28%)\n",
      "‚úÖ Completed 263/931 (28%)\n",
      "‚úÖ Completed 264/931 (28%)\n",
      "‚úÖ Completed 265/931 (28%)\n",
      "‚úÖ Completed 266/931 (29%)\n",
      "‚úÖ Completed 267/931 (29%)\n",
      "‚úÖ Completed 268/931 (29%)\n",
      "‚úÖ Completed 269/931 (29%)\n",
      "‚úÖ Completed 270/931 (29%)\n",
      "‚úÖ Completed 271/931 (29%)\n",
      "‚úÖ Completed 272/931 (29%)\n",
      "‚úÖ Completed 273/931 (29%)\n",
      "‚úÖ Completed 274/931 (29%)\n",
      "‚úÖ Completed 275/931 (30%)\n",
      "‚úÖ Completed 276/931 (30%)\n",
      "‚úÖ Completed 277/931 (30%)\n",
      "‚úÖ Completed 278/931 (30%)\n",
      "‚úÖ Completed 279/931 (30%)\n",
      "‚úÖ Completed 280/931 (30%)\n",
      "‚úÖ Completed 281/931 (30%)\n",
      "‚úÖ Completed 282/931 (30%)\n",
      "‚úÖ Completed 283/931 (30%)\n",
      "‚úÖ Completed 284/931 (31%)\n",
      "‚úÖ Completed 285/931 (31%)\n",
      "‚úÖ Completed 286/931 (31%)\n",
      "‚úÖ Completed 287/931 (31%)\n",
      "‚úÖ Completed 288/931 (31%)\n",
      "‚úÖ Completed 289/931 (31%)\n",
      "‚úÖ Completed 290/931 (31%)\n",
      "‚úÖ Completed 291/931 (31%)\n",
      "‚úÖ Completed 292/931 (31%)\n",
      "‚úÖ Completed 293/931 (31%)\n",
      "‚úÖ Completed 294/931 (32%)\n",
      "‚úÖ Completed 295/931 (32%)\n",
      "‚úÖ Completed 296/931 (32%)\n",
      "‚úÖ Completed 297/931 (32%)\n",
      "‚úÖ Completed 298/931 (32%)\n",
      "‚úÖ Completed 299/931 (32%)\n",
      "‚úÖ Completed 300/931 (32%)\n",
      "‚úÖ Completed 301/931 (32%)\n",
      "‚úÖ Completed 302/931 (32%)\n",
      "‚úÖ Completed 303/931 (33%)\n",
      "‚úÖ Completed 304/931 (33%)\n",
      "‚úÖ Completed 305/931 (33%)\n",
      "‚úÖ Completed 306/931 (33%)\n",
      "‚úÖ Completed 307/931 (33%)\n",
      "‚úÖ Completed 308/931 (33%)\n",
      "‚úÖ Completed 309/931 (33%)\n",
      "‚úÖ Completed 310/931 (33%)\n",
      "‚úÖ Completed 311/931 (33%)\n",
      "‚úÖ Completed 312/931 (34%)\n",
      "‚úÖ Completed 313/931 (34%)\n",
      "‚úÖ Completed 314/931 (34%)\n",
      "‚úÖ Completed 315/931 (34%)\n",
      "‚úÖ Completed 316/931 (34%)\n",
      "‚úÖ Completed 317/931 (34%)\n",
      "‚úÖ Completed 318/931 (34%)\n",
      "‚úÖ Completed 319/931 (34%)\n",
      "‚úÖ Completed 320/931 (34%)\n",
      "‚úÖ Completed 321/931 (34%)\n",
      "‚úÖ Completed 322/931 (35%)\n",
      "‚úÖ Completed 323/931 (35%)\n",
      "‚úÖ Completed 324/931 (35%)\n",
      "‚úÖ Completed 325/931 (35%)\n",
      "‚úÖ Completed 326/931 (35%)\n",
      "‚úÖ Completed 327/931 (35%)\n",
      "‚úÖ Completed 328/931 (35%)\n",
      "‚úÖ Completed 329/931 (35%)\n",
      "‚úÖ Completed 330/931 (35%)\n",
      "‚úÖ Completed 331/931 (36%)\n",
      "‚úÖ Completed 332/931 (36%)\n",
      "‚úÖ Completed 333/931 (36%)\n",
      "‚úÖ Completed 334/931 (36%)\n",
      "‚úÖ Completed 335/931 (36%)\n",
      "‚úÖ Completed 336/931 (36%)\n",
      "‚úÖ Completed 337/931 (36%)\n",
      "‚úÖ Completed 338/931 (36%)\n",
      "‚úÖ Completed 339/931 (36%)\n",
      "‚úÖ Completed 340/931 (37%)\n",
      "‚úÖ Completed 341/931 (37%)\n",
      "‚úÖ Completed 342/931 (37%)\n",
      "‚úÖ Completed 343/931 (37%)\n",
      "‚úÖ Completed 344/931 (37%)\n",
      "‚úÖ Completed 345/931 (37%)\n",
      "‚úÖ Completed 346/931 (37%)\n",
      "‚úÖ Completed 347/931 (37%)\n",
      "‚úÖ Completed 348/931 (37%)\n",
      "‚úÖ Completed 349/931 (37%)\n",
      "‚úÖ Completed 350/931 (38%)\n",
      "‚úÖ Completed 351/931 (38%)\n",
      "‚úÖ Completed 352/931 (38%)\n",
      "‚úÖ Completed 353/931 (38%)\n",
      "‚úÖ Completed 354/931 (38%)\n",
      "‚úÖ Completed 355/931 (38%)\n",
      "‚úÖ Completed 356/931 (38%)\n",
      "‚úÖ Completed 357/931 (38%)\n",
      "‚úÖ Completed 358/931 (38%)\n",
      "‚úÖ Completed 359/931 (39%)\n",
      "‚úÖ Completed 360/931 (39%)\n",
      "‚úÖ Completed 361/931 (39%)\n",
      "‚úÖ Completed 362/931 (39%)\n",
      "‚úÖ Completed 363/931 (39%)\n",
      "‚úÖ Completed 364/931 (39%)\n",
      "‚úÖ Completed 365/931 (39%)\n",
      "‚úÖ Completed 366/931 (39%)\n",
      "‚úÖ Completed 367/931 (39%)\n",
      "‚úÖ Completed 368/931 (40%)\n",
      "‚úÖ Completed 369/931 (40%)\n",
      "‚úÖ Completed 370/931 (40%)\n",
      "‚úÖ Completed 371/931 (40%)\n",
      "‚úÖ Completed 372/931 (40%)\n",
      "‚úÖ Completed 373/931 (40%)\n",
      "‚úÖ Completed 374/931 (40%)\n",
      "‚úÖ Completed 375/931 (40%)\n",
      "‚úÖ Completed 376/931 (40%)\n",
      "‚úÖ Completed 377/931 (40%)\n",
      "‚úÖ Completed 378/931 (41%)\n",
      "‚úÖ Completed 379/931 (41%)\n",
      "‚úÖ Completed 380/931 (41%)\n",
      "‚úÖ Completed 381/931 (41%)\n",
      "‚úÖ Completed 382/931 (41%)\n",
      "‚úÖ Completed 383/931 (41%)\n",
      "‚úÖ Completed 384/931 (41%)\n",
      "‚úÖ Completed 385/931 (41%)\n",
      "‚úÖ Completed 386/931 (41%)\n",
      "‚úÖ Completed 387/931 (42%)\n",
      "‚úÖ Completed 388/931 (42%)\n",
      "‚úÖ Completed 389/931 (42%)\n",
      "‚úÖ Completed 390/931 (42%)\n",
      "‚úÖ Completed 391/931 (42%)\n",
      "‚úÖ Completed 392/931 (42%)\n",
      "‚úÖ Completed 393/931 (42%)\n",
      "‚úÖ Completed 394/931 (42%)\n",
      "‚úÖ Completed 395/931 (42%)\n",
      "‚úÖ Completed 396/931 (43%)\n",
      "‚úÖ Completed 397/931 (43%)\n",
      "‚úÖ Completed 398/931 (43%)\n",
      "‚úÖ Completed 399/931 (43%)\n",
      "‚úÖ Completed 400/931 (43%)\n",
      "‚úÖ Completed 401/931 (43%)\n",
      "‚úÖ Completed 402/931 (43%)\n",
      "‚úÖ Completed 403/931 (43%)\n",
      "‚úÖ Completed 404/931 (43%)\n",
      "‚úÖ Completed 405/931 (44%)\n",
      "‚úÖ Completed 406/931 (44%)\n",
      "‚úÖ Completed 407/931 (44%)\n",
      "‚úÖ Completed 408/931 (44%)\n",
      "‚úÖ Completed 409/931 (44%)\n",
      "‚úÖ Completed 410/931 (44%)\n",
      "‚úÖ Completed 411/931 (44%)\n",
      "‚úÖ Completed 412/931 (44%)\n",
      "‚úÖ Completed 413/931 (44%)\n",
      "‚úÖ Completed 414/931 (44%)\n",
      "‚úÖ Completed 415/931 (45%)\n",
      "‚úÖ Completed 416/931 (45%)\n",
      "‚úÖ Completed 417/931 (45%)\n",
      "‚úÖ Completed 418/931 (45%)\n",
      "‚úÖ Completed 419/931 (45%)\n",
      "‚úÖ Completed 420/931 (45%)\n",
      "‚úÖ Completed 421/931 (45%)\n",
      "‚úÖ Completed 422/931 (45%)\n",
      "‚úÖ Completed 423/931 (45%)\n",
      "‚úÖ Completed 424/931 (46%)\n",
      "‚úÖ Completed 425/931 (46%)\n",
      "‚úÖ Completed 426/931 (46%)\n",
      "‚úÖ Completed 427/931 (46%)\n",
      "‚úÖ Completed 428/931 (46%)\n",
      "‚úÖ Completed 429/931 (46%)\n",
      "‚úÖ Completed 430/931 (46%)\n",
      "‚úÖ Completed 431/931 (46%)\n",
      "‚úÖ Completed 432/931 (46%)\n",
      "‚úÖ Completed 433/931 (47%)\n",
      "‚úÖ Completed 434/931 (47%)\n",
      "‚úÖ Completed 435/931 (47%)\n",
      "‚úÖ Completed 436/931 (47%)\n",
      "‚úÖ Completed 437/931 (47%)\n",
      "‚úÖ Completed 438/931 (47%)\n",
      "‚úÖ Completed 439/931 (47%)\n",
      "‚úÖ Completed 440/931 (47%)\n",
      "‚úÖ Completed 441/931 (47%)\n",
      "‚úÖ Completed 442/931 (47%)\n",
      "‚úÖ Completed 443/931 (48%)\n",
      "‚úÖ Completed 444/931 (48%)\n",
      "‚úÖ Completed 445/931 (48%)\n",
      "‚úÖ Completed 446/931 (48%)\n",
      "‚úÖ Completed 447/931 (48%)\n",
      "‚úÖ Completed 448/931 (48%)\n",
      "‚úÖ Completed 449/931 (48%)\n",
      "‚úÖ Completed 450/931 (48%)\n",
      "‚úÖ Completed 451/931 (48%)\n",
      "‚úÖ Completed 452/931 (49%)\n",
      "‚úÖ Completed 453/931 (49%)\n",
      "‚úÖ Completed 454/931 (49%)\n",
      "‚úÖ Completed 455/931 (49%)\n",
      "‚úÖ Completed 456/931 (49%)\n",
      "‚úÖ Completed 457/931 (49%)\n",
      "‚úÖ Completed 458/931 (49%)\n",
      "‚úÖ Completed 459/931 (49%)\n",
      "‚úÖ Completed 460/931 (49%)\n",
      "‚úÖ Completed 461/931 (50%)\n",
      "‚úÖ Completed 462/931 (50%)\n",
      "‚úÖ Completed 463/931 (50%)\n",
      "‚úÖ Completed 464/931 (50%)\n",
      "‚úÖ Completed 465/931 (50%)\n",
      "‚úÖ Completed 466/931 (50%)\n",
      "‚úÖ Completed 467/931 (50%)\n",
      "‚úÖ Completed 468/931 (50%)\n",
      "‚úÖ Completed 469/931 (50%)\n",
      "‚úÖ Completed 470/931 (50%)\n",
      "‚úÖ Completed 471/931 (51%)\n",
      "‚úÖ Completed 472/931 (51%)\n",
      "‚úÖ Completed 473/931 (51%)\n",
      "‚úÖ Completed 474/931 (51%)\n",
      "‚úÖ Completed 475/931 (51%)\n",
      "‚úÖ Completed 476/931 (51%)\n",
      "‚úÖ Completed 477/931 (51%)\n",
      "‚úÖ Completed 478/931 (51%)\n",
      "‚úÖ Completed 479/931 (51%)\n",
      "‚úÖ Completed 480/931 (52%)\n",
      "‚úÖ Completed 481/931 (52%)\n",
      "‚úÖ Completed 482/931 (52%)\n",
      "‚úÖ Completed 483/931 (52%)\n",
      "‚úÖ Completed 484/931 (52%)\n",
      "‚úÖ Completed 485/931 (52%)\n",
      "‚úÖ Completed 486/931 (52%)\n",
      "‚úÖ Completed 487/931 (52%)\n",
      "‚úÖ Completed 488/931 (52%)\n",
      "‚úÖ Completed 489/931 (53%)\n",
      "‚úÖ Completed 490/931 (53%)\n",
      "‚úÖ Completed 491/931 (53%)\n",
      "‚úÖ Completed 492/931 (53%)\n",
      "‚úÖ Completed 493/931 (53%)\n",
      "‚úÖ Completed 494/931 (53%)\n",
      "‚úÖ Completed 495/931 (53%)\n",
      "‚úÖ Completed 496/931 (53%)\n",
      "‚úÖ Completed 497/931 (53%)\n",
      "‚úÖ Completed 498/931 (53%)\n",
      "‚úÖ Completed 499/931 (54%)\n",
      "‚úÖ Completed 500/931 (54%)\n",
      "‚úÖ Completed 501/931 (54%)\n",
      "‚úÖ Completed 502/931 (54%)\n",
      "‚úÖ Completed 503/931 (54%)\n",
      "‚úÖ Completed 504/931 (54%)\n",
      "‚úÖ Completed 505/931 (54%)\n",
      "‚úÖ Completed 506/931 (54%)\n",
      "‚úÖ Completed 507/931 (54%)\n",
      "‚úÖ Completed 508/931 (55%)\n",
      "‚úÖ Completed 509/931 (55%)\n",
      "‚úÖ Completed 510/931 (55%)\n",
      "‚úÖ Completed 511/931 (55%)\n",
      "‚úÖ Completed 512/931 (55%)\n",
      "‚úÖ Completed 513/931 (55%)\n",
      "‚úÖ Completed 514/931 (55%)\n",
      "‚úÖ Completed 515/931 (55%)\n",
      "‚úÖ Completed 516/931 (55%)\n",
      "‚úÖ Completed 517/931 (56%)\n",
      "‚úÖ Completed 518/931 (56%)\n",
      "‚úÖ Completed 519/931 (56%)\n",
      "‚úÖ Completed 520/931 (56%)\n",
      "‚úÖ Completed 521/931 (56%)\n",
      "‚úÖ Completed 522/931 (56%)\n",
      "‚úÖ Completed 523/931 (56%)\n",
      "‚úÖ Completed 524/931 (56%)\n",
      "‚úÖ Completed 525/931 (56%)\n",
      "‚úÖ Completed 526/931 (56%)\n",
      "‚úÖ Completed 527/931 (57%)\n",
      "‚úÖ Completed 528/931 (57%)\n",
      "‚úÖ Completed 529/931 (57%)\n",
      "‚úÖ Completed 530/931 (57%)\n",
      "‚úÖ Completed 531/931 (57%)\n",
      "‚úÖ Completed 532/931 (57%)\n",
      "‚úÖ Completed 533/931 (57%)\n",
      "‚úÖ Completed 534/931 (57%)\n",
      "‚úÖ Completed 535/931 (57%)\n",
      "‚úÖ Completed 536/931 (58%)\n",
      "‚úÖ Completed 537/931 (58%)\n",
      "‚úÖ Completed 538/931 (58%)\n",
      "‚úÖ Completed 539/931 (58%)\n",
      "‚úÖ Completed 540/931 (58%)\n",
      "‚úÖ Completed 541/931 (58%)\n",
      "‚úÖ Completed 542/931 (58%)\n",
      "‚úÖ Completed 543/931 (58%)\n",
      "‚úÖ Completed 544/931 (58%)\n",
      "‚úÖ Completed 545/931 (59%)\n",
      "‚úÖ Completed 546/931 (59%)\n",
      "‚úÖ Completed 547/931 (59%)\n",
      "‚úÖ Completed 548/931 (59%)\n",
      "‚úÖ Completed 549/931 (59%)\n",
      "‚úÖ Completed 550/931 (59%)\n",
      "‚úÖ Completed 551/931 (59%)\n",
      "‚úÖ Completed 552/931 (59%)\n",
      "‚úÖ Completed 553/931 (59%)\n",
      "‚úÖ Completed 554/931 (60%)\n",
      "‚úÖ Completed 555/931 (60%)\n",
      "‚úÖ Completed 556/931 (60%)\n",
      "‚úÖ Completed 557/931 (60%)\n",
      "‚úÖ Completed 558/931 (60%)\n",
      "‚úÖ Completed 559/931 (60%)\n",
      "‚úÖ Completed 560/931 (60%)\n",
      "‚úÖ Completed 561/931 (60%)\n",
      "‚úÖ Completed 562/931 (60%)\n",
      "‚úÖ Completed 563/931 (60%)\n",
      "‚úÖ Completed 564/931 (61%)\n",
      "‚úÖ Completed 565/931 (61%)\n",
      "‚úÖ Completed 566/931 (61%)\n",
      "‚úÖ Completed 567/931 (61%)\n",
      "‚úÖ Completed 568/931 (61%)\n",
      "‚úÖ Completed 569/931 (61%)\n",
      "‚úÖ Completed 570/931 (61%)\n",
      "‚úÖ Completed 571/931 (61%)\n",
      "‚úÖ Completed 572/931 (61%)\n",
      "‚úÖ Completed 573/931 (62%)\n",
      "‚úÖ Completed 574/931 (62%)\n",
      "‚úÖ Completed 575/931 (62%)\n",
      "‚úÖ Completed 576/931 (62%)\n",
      "‚úÖ Completed 577/931 (62%)\n",
      "‚úÖ Completed 578/931 (62%)\n",
      "‚úÖ Completed 579/931 (62%)\n",
      "‚úÖ Completed 580/931 (62%)\n",
      "‚úÖ Completed 581/931 (62%)\n",
      "‚úÖ Completed 582/931 (63%)\n",
      "‚úÖ Completed 583/931 (63%)\n",
      "‚úÖ Completed 584/931 (63%)\n",
      "‚úÖ Completed 585/931 (63%)\n",
      "‚úÖ Completed 586/931 (63%)\n",
      "‚úÖ Completed 587/931 (63%)\n",
      "‚úÖ Completed 588/931 (63%)\n",
      "‚úÖ Completed 589/931 (63%)\n",
      "‚úÖ Completed 590/931 (63%)\n",
      "‚úÖ Completed 591/931 (63%)\n",
      "‚úÖ Completed 592/931 (64%)\n",
      "‚úÖ Completed 593/931 (64%)\n",
      "‚úÖ Completed 594/931 (64%)\n",
      "‚úÖ Completed 595/931 (64%)\n",
      "‚úÖ Completed 596/931 (64%)\n",
      "‚úÖ Completed 597/931 (64%)\n",
      "‚úÖ Completed 598/931 (64%)\n",
      "‚úÖ Completed 599/931 (64%)\n",
      "‚úÖ Completed 600/931 (64%)\n",
      "‚úÖ Completed 601/931 (65%)\n",
      "‚úÖ Completed 602/931 (65%)\n",
      "‚úÖ Completed 603/931 (65%)\n",
      "‚úÖ Completed 604/931 (65%)\n",
      "‚úÖ Completed 605/931 (65%)\n",
      "‚úÖ Completed 606/931 (65%)\n",
      "‚úÖ Completed 607/931 (65%)\n",
      "‚úÖ Completed 608/931 (65%)\n",
      "‚úÖ Completed 609/931 (65%)\n",
      "‚úÖ Completed 610/931 (66%)\n",
      "‚úÖ Completed 611/931 (66%)\n",
      "‚úÖ Completed 612/931 (66%)\n",
      "‚úÖ Completed 613/931 (66%)\n",
      "‚úÖ Completed 614/931 (66%)\n",
      "‚úÖ Completed 615/931 (66%)\n",
      "‚úÖ Completed 616/931 (66%)\n",
      "‚úÖ Completed 617/931 (66%)\n",
      "‚úÖ Completed 618/931 (66%)\n",
      "‚úÖ Completed 619/931 (66%)\n",
      "‚úÖ Completed 620/931 (67%)\n",
      "‚úÖ Completed 621/931 (67%)\n",
      "‚úÖ Completed 622/931 (67%)\n",
      "‚úÖ Completed 623/931 (67%)\n",
      "‚úÖ Completed 624/931 (67%)\n",
      "‚úÖ Completed 625/931 (67%)\n",
      "‚úÖ Completed 626/931 (67%)\n",
      "‚úÖ Completed 627/931 (67%)\n",
      "‚úÖ Completed 628/931 (67%)\n",
      "‚úÖ Completed 629/931 (68%)\n",
      "‚úÖ Completed 630/931 (68%)\n",
      "‚úÖ Completed 631/931 (68%)\n",
      "‚úÖ Completed 632/931 (68%)\n",
      "‚úÖ Completed 633/931 (68%)\n",
      "‚úÖ Completed 634/931 (68%)\n",
      "‚úÖ Completed 635/931 (68%)\n",
      "‚úÖ Completed 636/931 (68%)\n",
      "‚úÖ Completed 637/931 (68%)\n",
      "‚úÖ Completed 638/931 (69%)\n",
      "‚úÖ Completed 639/931 (69%)\n",
      "‚úÖ Completed 640/931 (69%)\n",
      "‚úÖ Completed 641/931 (69%)\n",
      "‚úÖ Completed 642/931 (69%)\n",
      "‚úÖ Completed 643/931 (69%)\n",
      "‚úÖ Completed 644/931 (69%)\n",
      "‚úÖ Completed 645/931 (69%)\n",
      "‚úÖ Completed 646/931 (69%)\n",
      "‚úÖ Completed 647/931 (69%)\n",
      "‚úÖ Completed 648/931 (70%)\n",
      "‚úÖ Completed 649/931 (70%)\n",
      "‚úÖ Completed 650/931 (70%)\n",
      "‚úÖ Completed 651/931 (70%)\n",
      "‚úÖ Completed 652/931 (70%)\n",
      "‚úÖ Completed 653/931 (70%)\n",
      "‚úÖ Completed 654/931 (70%)\n",
      "‚úÖ Completed 655/931 (70%)\n",
      "‚úÖ Completed 656/931 (70%)\n",
      "‚úÖ Completed 657/931 (71%)\n",
      "‚úÖ Completed 658/931 (71%)\n",
      "‚úÖ Completed 659/931 (71%)\n",
      "‚úÖ Completed 660/931 (71%)\n",
      "‚úÖ Completed 661/931 (71%)\n",
      "‚úÖ Completed 662/931 (71%)\n",
      "‚úÖ Completed 663/931 (71%)\n",
      "‚úÖ Completed 664/931 (71%)\n",
      "‚úÖ Completed 665/931 (71%)\n",
      "‚úÖ Completed 666/931 (72%)\n",
      "‚úÖ Completed 667/931 (72%)\n",
      "‚úÖ Completed 668/931 (72%)\n",
      "‚úÖ Completed 669/931 (72%)\n",
      "‚úÖ Completed 670/931 (72%)\n",
      "‚úÖ Completed 671/931 (72%)\n",
      "‚úÖ Completed 672/931 (72%)\n",
      "‚úÖ Completed 673/931 (72%)\n",
      "‚úÖ Completed 674/931 (72%)\n",
      "‚úÖ Completed 675/931 (73%)\n",
      "‚úÖ Completed 676/931 (73%)\n",
      "‚úÖ Completed 677/931 (73%)\n",
      "‚úÖ Completed 678/931 (73%)\n",
      "‚úÖ Completed 679/931 (73%)\n",
      "‚úÖ Completed 680/931 (73%)\n",
      "‚úÖ Completed 681/931 (73%)\n",
      "‚úÖ Completed 682/931 (73%)\n",
      "‚úÖ Completed 683/931 (73%)\n",
      "‚úÖ Completed 684/931 (73%)\n",
      "‚úÖ Completed 685/931 (74%)\n",
      "‚úÖ Completed 686/931 (74%)\n",
      "‚úÖ Completed 687/931 (74%)\n",
      "‚úÖ Completed 688/931 (74%)\n",
      "‚úÖ Completed 689/931 (74%)\n",
      "‚úÖ Completed 690/931 (74%)\n",
      "‚úÖ Completed 691/931 (74%)\n",
      "‚úÖ Completed 692/931 (74%)\n",
      "‚úÖ Completed 693/931 (74%)\n",
      "‚úÖ Completed 694/931 (75%)\n",
      "‚úÖ Completed 695/931 (75%)\n",
      "‚úÖ Completed 696/931 (75%)\n",
      "‚úÖ Completed 697/931 (75%)\n",
      "‚úÖ Completed 698/931 (75%)\n",
      "‚úÖ Completed 699/931 (75%)\n",
      "‚úÖ Completed 700/931 (75%)\n",
      "‚úÖ Completed 701/931 (75%)\n",
      "‚úÖ Completed 702/931 (75%)\n",
      "‚úÖ Completed 703/931 (76%)\n",
      "‚úÖ Completed 704/931 (76%)\n",
      "‚úÖ Completed 705/931 (76%)\n",
      "‚úÖ Completed 706/931 (76%)\n",
      "‚úÖ Completed 707/931 (76%)\n",
      "‚úÖ Completed 708/931 (76%)\n",
      "‚úÖ Completed 709/931 (76%)\n",
      "‚úÖ Completed 710/931 (76%)\n",
      "‚úÖ Completed 711/931 (76%)\n",
      "‚úÖ Completed 712/931 (76%)\n",
      "‚úÖ Completed 713/931 (77%)\n",
      "‚úÖ Completed 714/931 (77%)\n",
      "‚úÖ Completed 715/931 (77%)\n",
      "‚úÖ Completed 716/931 (77%)\n",
      "‚úÖ Completed 717/931 (77%)\n",
      "‚úÖ Completed 718/931 (77%)\n",
      "‚úÖ Completed 719/931 (77%)\n",
      "‚úÖ Completed 720/931 (77%)\n",
      "‚úÖ Completed 721/931 (77%)\n",
      "‚úÖ Completed 722/931 (78%)\n",
      "‚úÖ Completed 723/931 (78%)\n",
      "‚úÖ Completed 724/931 (78%)\n",
      "‚úÖ Completed 725/931 (78%)\n",
      "‚úÖ Completed 726/931 (78%)\n",
      "‚úÖ Completed 727/931 (78%)\n",
      "‚úÖ Completed 728/931 (78%)\n",
      "‚úÖ Completed 729/931 (78%)\n",
      "‚úÖ Completed 730/931 (78%)\n",
      "‚úÖ Completed 731/931 (79%)\n",
      "‚úÖ Completed 732/931 (79%)\n",
      "‚úÖ Completed 733/931 (79%)\n",
      "‚úÖ Completed 734/931 (79%)\n",
      "‚úÖ Completed 735/931 (79%)\n",
      "‚úÖ Completed 736/931 (79%)\n",
      "‚úÖ Completed 737/931 (79%)\n",
      "‚úÖ Completed 738/931 (79%)\n",
      "‚úÖ Completed 739/931 (79%)\n",
      "‚úÖ Completed 740/931 (79%)\n",
      "‚úÖ Completed 741/931 (80%)\n",
      "‚úÖ Completed 742/931 (80%)\n",
      "‚úÖ Completed 743/931 (80%)\n",
      "‚úÖ Completed 744/931 (80%)\n",
      "‚úÖ Completed 745/931 (80%)\n",
      "‚úÖ Completed 746/931 (80%)\n",
      "‚úÖ Completed 747/931 (80%)\n",
      "‚úÖ Completed 748/931 (80%)\n",
      "‚úÖ Completed 749/931 (80%)\n",
      "‚úÖ Completed 750/931 (81%)\n",
      "‚úÖ Completed 751/931 (81%)\n",
      "‚úÖ Completed 752/931 (81%)\n",
      "‚úÖ Completed 753/931 (81%)\n",
      "‚úÖ Completed 754/931 (81%)\n",
      "‚úÖ Completed 755/931 (81%)\n",
      "‚úÖ Completed 756/931 (81%)\n",
      "‚úÖ Completed 757/931 (81%)\n",
      "‚úÖ Completed 758/931 (81%)\n",
      "‚úÖ Completed 759/931 (82%)\n",
      "‚úÖ Completed 760/931 (82%)\n",
      "‚úÖ Completed 761/931 (82%)\n",
      "‚úÖ Completed 762/931 (82%)\n",
      "‚úÖ Completed 763/931 (82%)\n",
      "‚úÖ Completed 764/931 (82%)\n",
      "‚úÖ Completed 765/931 (82%)\n",
      "‚úÖ Completed 766/931 (82%)\n",
      "‚úÖ Completed 767/931 (82%)\n",
      "‚úÖ Completed 768/931 (82%)\n",
      "‚úÖ Completed 769/931 (83%)\n",
      "‚úÖ Completed 770/931 (83%)\n",
      "‚úÖ Completed 771/931 (83%)\n",
      "‚úÖ Completed 772/931 (83%)\n",
      "‚úÖ Completed 773/931 (83%)\n",
      "‚úÖ Completed 774/931 (83%)\n",
      "‚úÖ Completed 775/931 (83%)\n",
      "‚úÖ Completed 776/931 (83%)\n",
      "‚úÖ Completed 777/931 (83%)\n",
      "‚úÖ Completed 778/931 (84%)\n",
      "‚úÖ Completed 779/931 (84%)\n",
      "‚úÖ Completed 780/931 (84%)\n",
      "‚úÖ Completed 781/931 (84%)\n",
      "‚úÖ Completed 782/931 (84%)\n",
      "‚úÖ Completed 783/931 (84%)\n",
      "‚úÖ Completed 784/931 (84%)\n",
      "‚úÖ Completed 785/931 (84%)\n",
      "‚úÖ Completed 786/931 (84%)\n",
      "‚úÖ Completed 787/931 (85%)\n",
      "‚úÖ Completed 788/931 (85%)\n",
      "‚úÖ Completed 789/931 (85%)\n",
      "‚úÖ Completed 790/931 (85%)\n",
      "‚úÖ Completed 791/931 (85%)\n",
      "‚úÖ Completed 792/931 (85%)\n",
      "‚úÖ Completed 793/931 (85%)\n",
      "‚úÖ Completed 794/931 (85%)\n",
      "‚úÖ Completed 795/931 (85%)\n",
      "‚úÖ Completed 796/931 (85%)\n",
      "‚úÖ Completed 797/931 (86%)\n",
      "‚úÖ Completed 798/931 (86%)\n",
      "‚úÖ Completed 799/931 (86%)\n",
      "‚úÖ Completed 800/931 (86%)\n",
      "‚úÖ Completed 801/931 (86%)\n",
      "‚úÖ Completed 802/931 (86%)\n",
      "‚úÖ Completed 803/931 (86%)\n",
      "‚úÖ Completed 804/931 (86%)\n",
      "‚úÖ Completed 805/931 (86%)\n",
      "‚úÖ Completed 806/931 (87%)\n",
      "‚úÖ Completed 807/931 (87%)\n",
      "‚úÖ Completed 808/931 (87%)\n",
      "‚úÖ Completed 809/931 (87%)\n",
      "‚úÖ Completed 810/931 (87%)\n",
      "‚úÖ Completed 811/931 (87%)\n",
      "‚úÖ Completed 812/931 (87%)\n",
      "‚úÖ Completed 813/931 (87%)\n",
      "‚úÖ Completed 814/931 (87%)\n",
      "‚úÖ Completed 815/931 (88%)\n",
      "‚úÖ Completed 816/931 (88%)\n",
      "‚úÖ Completed 817/931 (88%)\n",
      "‚úÖ Completed 818/931 (88%)\n",
      "‚úÖ Completed 819/931 (88%)\n",
      "‚úÖ Completed 820/931 (88%)\n",
      "‚úÖ Completed 821/931 (88%)\n",
      "‚úÖ Completed 822/931 (88%)\n",
      "‚úÖ Completed 823/931 (88%)\n",
      "‚úÖ Completed 824/931 (89%)\n",
      "‚úÖ Completed 825/931 (89%)\n",
      "‚úÖ Completed 826/931 (89%)\n",
      "‚úÖ Completed 827/931 (89%)\n",
      "‚úÖ Completed 828/931 (89%)\n",
      "‚úÖ Completed 829/931 (89%)\n",
      "‚úÖ Completed 830/931 (89%)\n",
      "‚úÖ Completed 831/931 (89%)\n",
      "‚úÖ Completed 832/931 (89%)\n",
      "‚úÖ Completed 833/931 (89%)\n",
      "‚úÖ Completed 834/931 (90%)\n",
      "‚úÖ Completed 835/931 (90%)\n",
      "‚úÖ Completed 836/931 (90%)\n",
      "‚úÖ Completed 837/931 (90%)\n",
      "‚úÖ Completed 838/931 (90%)\n",
      "‚úÖ Completed 839/931 (90%)\n",
      "‚úÖ Completed 840/931 (90%)\n",
      "‚úÖ Completed 841/931 (90%)\n",
      "‚úÖ Completed 842/931 (90%)\n",
      "‚úÖ Completed 843/931 (91%)\n",
      "‚úÖ Completed 844/931 (91%)\n",
      "‚úÖ Completed 845/931 (91%)\n",
      "‚úÖ Completed 846/931 (91%)\n",
      "‚úÖ Completed 847/931 (91%)\n",
      "‚úÖ Completed 848/931 (91%)\n",
      "‚úÖ Completed 849/931 (91%)\n",
      "‚úÖ Completed 850/931 (91%)\n",
      "‚úÖ Completed 851/931 (91%)\n",
      "‚úÖ Completed 852/931 (92%)\n",
      "‚úÖ Completed 853/931 (92%)\n",
      "‚úÖ Completed 854/931 (92%)\n",
      "‚úÖ Completed 855/931 (92%)\n",
      "‚úÖ Completed 856/931 (92%)\n",
      "‚úÖ Completed 857/931 (92%)\n",
      "‚úÖ Completed 858/931 (92%)\n",
      "‚úÖ Completed 859/931 (92%)\n",
      "‚úÖ Completed 860/931 (92%)\n",
      "‚úÖ Completed 861/931 (92%)\n",
      "‚úÖ Completed 862/931 (93%)\n",
      "‚úÖ Completed 863/931 (93%)\n",
      "‚úÖ Completed 864/931 (93%)\n",
      "‚úÖ Completed 865/931 (93%)\n",
      "‚úÖ Completed 866/931 (93%)\n",
      "‚úÖ Completed 867/931 (93%)\n",
      "‚úÖ Completed 868/931 (93%)\n",
      "‚úÖ Completed 869/931 (93%)\n",
      "‚úÖ Completed 870/931 (93%)\n",
      "‚úÖ Completed 871/931 (94%)\n",
      "‚úÖ Completed 872/931 (94%)\n",
      "‚úÖ Completed 873/931 (94%)\n",
      "‚úÖ Completed 874/931 (94%)\n",
      "‚úÖ Completed 875/931 (94%)\n",
      "‚úÖ Completed 876/931 (94%)\n",
      "‚úÖ Completed 877/931 (94%)\n",
      "‚úÖ Completed 878/931 (94%)\n",
      "‚úÖ Completed 879/931 (94%)\n",
      "‚úÖ Completed 880/931 (95%)\n",
      "‚úÖ Completed 881/931 (95%)\n",
      "‚úÖ Completed 882/931 (95%)\n",
      "‚úÖ Completed 883/931 (95%)\n",
      "‚úÖ Completed 884/931 (95%)\n",
      "‚úÖ Completed 885/931 (95%)\n",
      "‚úÖ Completed 886/931 (95%)\n",
      "‚úÖ Completed 887/931 (95%)\n",
      "‚úÖ Completed 888/931 (95%)\n",
      "‚úÖ Completed 889/931 (95%)\n",
      "‚úÖ Completed 890/931 (96%)\n",
      "‚úÖ Completed 891/931 (96%)\n",
      "‚úÖ Completed 892/931 (96%)\n",
      "‚úÖ Completed 893/931 (96%)\n",
      "‚úÖ Completed 894/931 (96%)\n",
      "‚úÖ Completed 895/931 (96%)\n",
      "‚úÖ Completed 896/931 (96%)\n",
      "‚úÖ Completed 897/931 (96%)\n",
      "‚úÖ Completed 898/931 (96%)\n",
      "‚úÖ Completed 899/931 (97%)\n",
      "‚úÖ Completed 900/931 (97%)\n",
      "‚úÖ Completed 901/931 (97%)\n",
      "‚úÖ Completed 902/931 (97%)\n",
      "‚úÖ Completed 903/931 (97%)\n",
      "‚úÖ Completed 904/931 (97%)\n",
      "‚úÖ Completed 905/931 (97%)\n",
      "‚úÖ Completed 906/931 (97%)\n",
      "‚úÖ Completed 907/931 (97%)\n",
      "‚úÖ Completed 908/931 (98%)\n",
      "‚úÖ Completed 909/931 (98%)\n",
      "‚úÖ Completed 910/931 (98%)\n",
      "‚úÖ Completed 911/931 (98%)\n",
      "‚úÖ Completed 912/931 (98%)\n",
      "‚úÖ Completed 913/931 (98%)\n",
      "‚úÖ Completed 914/931 (98%)\n",
      "‚úÖ Completed 915/931 (98%)\n",
      "‚úÖ Completed 916/931 (98%)\n",
      "‚úÖ Completed 917/931 (98%)\n",
      "‚úÖ Completed 918/931 (99%)\n",
      "‚úÖ Completed 919/931 (99%)\n",
      "‚úÖ Completed 920/931 (99%)\n",
      "‚úÖ Completed 921/931 (99%)\n",
      "‚úÖ Completed 922/931 (99%)\n",
      "‚úÖ Completed 923/931 (99%)\n",
      "‚úÖ Completed 924/931 (99%)\n",
      "‚úÖ Completed 925/931 (99%)\n",
      "‚úÖ Completed 926/931 (99%)\n",
      "‚úÖ Completed 927/931 (100%)\n",
      "‚úÖ Completed 928/931 (100%)\n",
      "‚úÖ Completed 929/931 (100%)\n",
      "‚úÖ Completed 930/931 (100%)\n",
      "‚úÖ Completed 931/931 (100%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DoorDash is hiring Tesla's robotics leader to ...</td>\n",
       "      <td>52646</td>\n",
       "      <td>DoorDash is adding Tesla's former robotics VP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skanska is hiring sustainability roles to win ...</td>\n",
       "      <td>2809</td>\n",
       "      <td>Skanska is embedding sustainability roles in p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skanska is building Skanska Direkt to capture ...</td>\n",
       "      <td>2808</td>\n",
       "      <td>Skanska is targeting small projects in Sweden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skanska is hiring cloud and IT talent to moder...</td>\n",
       "      <td>2807</td>\n",
       "      <td>Skanska is hiring project leaders to deliver c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skanska is hiring heavy‚Äëcivil leaders to expan...</td>\n",
       "      <td>2806</td>\n",
       "      <td>Skanska is recruiting senior civil constructio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turner is reinforcing project engineering with...</td>\n",
       "      <td>2805</td>\n",
       "      <td>Turner is hiring senior engineers with BIM ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Turner is hiring field security and survey tec...</td>\n",
       "      <td>2804</td>\n",
       "      <td>Turner is posting confused job descriptions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Turner is hiring HR admins to scale regional p...</td>\n",
       "      <td>2803</td>\n",
       "      <td>Turner is hiring HR staff to capture early-car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MX Build is offering brand-voice AI templates</td>\n",
       "      <td>2802</td>\n",
       "      <td>SMBs are comparing Claude, Gemini and Perplexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MX Build is consolidating AI for quoting and o...</td>\n",
       "      <td>2801</td>\n",
       "      <td>Small businesses are abandoning ChatGPT for AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DoorDash is blaming merchants for price spikes...</td>\n",
       "      <td>2800</td>\n",
       "      <td>DoorDash is blaming partners for pricing error...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skanska is locking in national grid contracts ...</td>\n",
       "      <td>2799</td>\n",
       "      <td>Skanska is locking in national grid contracts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skanska is using its Fortune award to win prem...</td>\n",
       "      <td>2798</td>\n",
       "      <td>Skanska is using its Fortune award to win gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Clayco is self-performing complex mechanical a...</td>\n",
       "      <td>2797</td>\n",
       "      <td>Clayco is self-performing complex mechanical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Clayco is hiring heavily to fuel expansion and...</td>\n",
       "      <td>2796</td>\n",
       "      <td>Clayco is hiring across all levels to support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Clayco is hiring specialized safety staff to w...</td>\n",
       "      <td>2795</td>\n",
       "      <td>Clayco is hiring specialized safety and techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clayco is building in-house MEP teams to cut o...</td>\n",
       "      <td>2794</td>\n",
       "      <td>Clayco is building in-house MEP teams to cut o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Clark Builders is leading preconstruction for ...</td>\n",
       "      <td>2793</td>\n",
       "      <td>Clark Builders is leading NorQuest's preconstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Turner is hiring dedicated safety staff on pro...</td>\n",
       "      <td>2792</td>\n",
       "      <td>Turner is hiring dedicated safety and quality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Turner is centralizing finance operations to r...</td>\n",
       "      <td>2791</td>\n",
       "      <td>Turner is splitting finance into centralized s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Turner is expanding self-perform drywall to co...</td>\n",
       "      <td>2790</td>\n",
       "      <td>Turner is expanding self-perform work into car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Turner is building a traveling senior team to ...</td>\n",
       "      <td>2789</td>\n",
       "      <td>Turner is building traveling specialist teams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SourceBlue is using Turner Construction's sale...</td>\n",
       "      <td>2788</td>\n",
       "      <td>SourceBlue is using Turner Construction's proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Turner is building an offsite factory to contr...</td>\n",
       "      <td>2787</td>\n",
       "      <td>Turner is building offsite factories to contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Turner is recruiting 2026 interns now to lock ...</td>\n",
       "      <td>2786</td>\n",
       "      <td>Turner is recruiting 2026 interns now to lock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Skanska is hiring procurement and finance spec...</td>\n",
       "      <td>2785</td>\n",
       "      <td>Skanska is hiring procurement and finance tale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Skanska is embedding safety and quality specia...</td>\n",
       "      <td>2784</td>\n",
       "      <td>Skanska is embedding safety specialists on pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skanska is hiring managers and paving crews to...</td>\n",
       "      <td>2783</td>\n",
       "      <td>Skanska is hiring across Swedish regions to ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Skanska is hiring specialized schedulers with ...</td>\n",
       "      <td>2782</td>\n",
       "      <td>Skanska is hiring claims specialists to reduce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Skanska is centralizing data center expertise ...</td>\n",
       "      <td>2781</td>\n",
       "      <td>Skanska is centralizing mission-critical exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Skanska is marketing recycling metrics to win ...</td>\n",
       "      <td>2780</td>\n",
       "      <td>Skanska is marketing verified recycling data t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Skanska is recruiting graduates years early to...</td>\n",
       "      <td>2779</td>\n",
       "      <td>Skanska is recruiting graduates years early to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Skanska is claiming ownership of water resilie...</td>\n",
       "      <td>2778</td>\n",
       "      <td>Skanska is owning the water crisis narrative t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Jobber and CurbWaste are winning small junk ha...</td>\n",
       "      <td>2777</td>\n",
       "      <td>Jobber and CurbWaste are capturing small junk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Workiz lost its partnerships leader to Palmett...</td>\n",
       "      <td>2776</td>\n",
       "      <td>Workiz lost its partnerships leader to Palmett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WEX is modernizing its legacy COBOL payments p...</td>\n",
       "      <td>2775</td>\n",
       "      <td>WEX is modernizing its aging T-Chek platform t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Housecall Pro is hiring a mid-market sales tea...</td>\n",
       "      <td>2774</td>\n",
       "      <td>Housecall Pro is hiring mid-market sales reps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Housecall Pro is hiring migration specialists ...</td>\n",
       "      <td>2773</td>\n",
       "      <td>Housecall Pro is hiring migration specialists ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ServiceTitan is automating HR and marketing wi...</td>\n",
       "      <td>2772</td>\n",
       "      <td>ServiceTitan is using AI to automate recruitin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Jobber is building a workforce management team...</td>\n",
       "      <td>2771</td>\n",
       "      <td>Jobber is expanding workforce management featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Jobber is building analytics teams to reduce c...</td>\n",
       "      <td>2770</td>\n",
       "      <td>Jobber is hiring analytics leaders to reduce c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jobber is building dedicated onboarding teams ...</td>\n",
       "      <td>2769</td>\n",
       "      <td>Jobber is building dedicated onboarding teams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ServiceTitan is claiming market leadership in ...</td>\n",
       "      <td>2768</td>\n",
       "      <td>ServiceTitan is running a multi-year ad campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ServiceTitan is publishing industry research t...</td>\n",
       "      <td>2767</td>\n",
       "      <td>ServiceTitan is publishing industry reports to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DoorDash is investing hundreds of millions in ...</td>\n",
       "      <td>2766</td>\n",
       "      <td>DoorDash is spending hundreds of millions to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DoorDash is suspending service during storms t...</td>\n",
       "      <td>2765</td>\n",
       "      <td>DoorDash is suspending service during storms t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DoorDash is using AI safety tools to attract w...</td>\n",
       "      <td>2764</td>\n",
       "      <td>DoorDash is using AI to screen chats and calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DoorDash, Uber and Instacart lost lawsuits blo...</td>\n",
       "      <td>2763</td>\n",
       "      <td>DoorDash is losing legal fights over worker pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DoorDash is targeting both wealthy and budget ...</td>\n",
       "      <td>2762</td>\n",
       "      <td>DoorDash is targeting both wealthy and budget ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Hibbett is using DoorDash to turn stores into ...</td>\n",
       "      <td>2761</td>\n",
       "      <td>Hibbett is using DoorDash to turn stores into ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title     id  \\\n",
       "0   DoorDash is hiring Tesla's robotics leader to ...  52646   \n",
       "1   Skanska is hiring sustainability roles to win ...   2809   \n",
       "2   Skanska is building Skanska Direkt to capture ...   2808   \n",
       "3   Skanska is hiring cloud and IT talent to moder...   2807   \n",
       "4   Skanska is hiring heavy‚Äëcivil leaders to expan...   2806   \n",
       "5   Turner is reinforcing project engineering with...   2805   \n",
       "6   Turner is hiring field security and survey tec...   2804   \n",
       "7   Turner is hiring HR admins to scale regional p...   2803   \n",
       "8       MX Build is offering brand-voice AI templates   2802   \n",
       "9   MX Build is consolidating AI for quoting and o...   2801   \n",
       "10  DoorDash is blaming merchants for price spikes...   2800   \n",
       "11  Skanska is locking in national grid contracts ...   2799   \n",
       "12  Skanska is using its Fortune award to win prem...   2798   \n",
       "13  Clayco is self-performing complex mechanical a...   2797   \n",
       "14  Clayco is hiring heavily to fuel expansion and...   2796   \n",
       "15  Clayco is hiring specialized safety staff to w...   2795   \n",
       "16  Clayco is building in-house MEP teams to cut o...   2794   \n",
       "17  Clark Builders is leading preconstruction for ...   2793   \n",
       "18  Turner is hiring dedicated safety staff on pro...   2792   \n",
       "19  Turner is centralizing finance operations to r...   2791   \n",
       "20  Turner is expanding self-perform drywall to co...   2790   \n",
       "21  Turner is building a traveling senior team to ...   2789   \n",
       "22  SourceBlue is using Turner Construction's sale...   2788   \n",
       "23  Turner is building an offsite factory to contr...   2787   \n",
       "24  Turner is recruiting 2026 interns now to lock ...   2786   \n",
       "25  Skanska is hiring procurement and finance spec...   2785   \n",
       "26  Skanska is embedding safety and quality specia...   2784   \n",
       "27  Skanska is hiring managers and paving crews to...   2783   \n",
       "28  Skanska is hiring specialized schedulers with ...   2782   \n",
       "29  Skanska is centralizing data center expertise ...   2781   \n",
       "30  Skanska is marketing recycling metrics to win ...   2780   \n",
       "31  Skanska is recruiting graduates years early to...   2779   \n",
       "32  Skanska is claiming ownership of water resilie...   2778   \n",
       "33  Jobber and CurbWaste are winning small junk ha...   2777   \n",
       "34  Workiz lost its partnerships leader to Palmett...   2776   \n",
       "35  WEX is modernizing its legacy COBOL payments p...   2775   \n",
       "36  Housecall Pro is hiring a mid-market sales tea...   2774   \n",
       "37  Housecall Pro is hiring migration specialists ...   2773   \n",
       "38  ServiceTitan is automating HR and marketing wi...   2772   \n",
       "39  Jobber is building a workforce management team...   2771   \n",
       "40  Jobber is building analytics teams to reduce c...   2770   \n",
       "41  Jobber is building dedicated onboarding teams ...   2769   \n",
       "42  ServiceTitan is claiming market leadership in ...   2768   \n",
       "43  ServiceTitan is publishing industry research t...   2767   \n",
       "44  DoorDash is investing hundreds of millions in ...   2766   \n",
       "45  DoorDash is suspending service during storms t...   2765   \n",
       "46  DoorDash is using AI safety tools to attract w...   2764   \n",
       "47  DoorDash, Uber and Instacart lost lawsuits blo...   2763   \n",
       "48  DoorDash is targeting both wealthy and budget ...   2762   \n",
       "49  Hibbett is using DoorDash to turn stores into ...   2761   \n",
       "\n",
       "                                             response  \n",
       "0   DoorDash is adding Tesla's former robotics VP ...  \n",
       "1   Skanska is embedding sustainability roles in p...  \n",
       "2   Skanska is targeting small projects in Sweden ...  \n",
       "3   Skanska is hiring project leaders to deliver c...  \n",
       "4   Skanska is recruiting senior civil constructio...  \n",
       "5   Turner is hiring senior engineers with BIM ski...  \n",
       "6   Turner is posting confused job descriptions th...  \n",
       "7   Turner is hiring HR staff to capture early-car...  \n",
       "8   SMBs are comparing Claude, Gemini and Perplexi...  \n",
       "9   Small businesses are abandoning ChatGPT for AI...  \n",
       "10  DoorDash is blaming partners for pricing error...  \n",
       "11  Skanska is locking in national grid contracts ...  \n",
       "12  Skanska is using its Fortune award to win gove...  \n",
       "13  Clayco is self-performing complex mechanical a...  \n",
       "14  Clayco is hiring across all levels to support ...  \n",
       "15  Clayco is hiring specialized safety and techni...  \n",
       "16  Clayco is building in-house MEP teams to cut o...  \n",
       "17  Clark Builders is leading NorQuest's preconstr...  \n",
       "18  Turner is hiring dedicated safety and quality ...  \n",
       "19  Turner is splitting finance into centralized s...  \n",
       "20  Turner is expanding self-perform work into car...  \n",
       "21  Turner is building traveling specialist teams ...  \n",
       "22  SourceBlue is using Turner Construction's proj...  \n",
       "23  Turner is building offsite factories to contro...  \n",
       "24  Turner is recruiting 2026 interns now to lock ...  \n",
       "25  Skanska is hiring procurement and finance tale...  \n",
       "26  Skanska is embedding safety specialists on pro...  \n",
       "27  Skanska is hiring across Swedish regions to ca...  \n",
       "28  Skanska is hiring claims specialists to reduce...  \n",
       "29  Skanska is centralizing mission-critical exper...  \n",
       "30  Skanska is marketing verified recycling data t...  \n",
       "31  Skanska is recruiting graduates years early to...  \n",
       "32  Skanska is owning the water crisis narrative t...  \n",
       "33  Jobber and CurbWaste are capturing small junk ...  \n",
       "34  Workiz lost its partnerships leader to Palmett...  \n",
       "35  WEX is modernizing its aging T-Chek platform t...  \n",
       "36  Housecall Pro is hiring mid-market sales reps ...  \n",
       "37  Housecall Pro is hiring migration specialists ...  \n",
       "38  ServiceTitan is using AI to automate recruitin...  \n",
       "39  Jobber is expanding workforce management featu...  \n",
       "40  Jobber is hiring analytics leaders to reduce c...  \n",
       "41  Jobber is building dedicated onboarding teams ...  \n",
       "42  ServiceTitan is running a multi-year ad campai...  \n",
       "43  ServiceTitan is publishing industry reports to...  \n",
       "44  DoorDash is spending hundreds of millions to e...  \n",
       "45  DoorDash is suspending service during storms t...  \n",
       "46  DoorDash is using AI to screen chats and calls...  \n",
       "47  DoorDash is losing legal fights over worker pa...  \n",
       "48  DoorDash is targeting both wealthy and budget ...  \n",
       "49  Hibbett is using DoorDash to turn stores into ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = AsyncAnthropic(api_key=anthropic_api_key)\n",
    "MODEL_NAME = \"claude-sonnet-4-5-20250929\"\n",
    "MAX_CONCURRENCY = 100\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENCY)\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "async def fetch_response(prompt, title, id, progress):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await client.messages.create(\n",
    "                model=MODEL_NAME,\n",
    "                max_tokens=1200,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Claude returns content as a list of blocks\n",
    "            text = response.content[0].text if response.content else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            text = None\n",
    "            print(f\"‚ö†Ô∏è Error for id {headline}: {e}\")\n",
    "\n",
    "        # Update progress safely\n",
    "        async with lock:\n",
    "            progress[\"done\"] += 1\n",
    "            done = progress[\"done\"]\n",
    "            total = progress[\"total\"]\n",
    "            print(f\"‚úÖ Completed {done}/{total} ({done/total:.0%})\")\n",
    "\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"id\" : id,\n",
    "            \"response\": text\n",
    "        }\n",
    "\n",
    "async def process_all(df):\n",
    "    total = len(df)\n",
    "    progress = {\"done\": 0, \"total\": total}\n",
    "    tasks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = f\"\"\"\n",
    "## Task\n",
    "\n",
    "You are a competitive intelligence analyst. Your job is to write a clear, scannable headline that tells the reader what a competitor is doing and why it matters.\n",
    "\n",
    "## Headline Guidelines\n",
    "\n",
    "- One sentence, under 12 words\n",
    "- Start with \"[Company] is [verb-ing]...\"\n",
    "- State what they're doing and the consequence‚Äîskip the mechanism/how\n",
    "- Write in plain language‚Äîif it sounds like jargon, rewrite it\n",
    "- No filler adjectives (aggressively, strategically, actively)\n",
    "- No business jargon (GTM, leverage, scale, accelerate, lock-in)\n",
    "- No period at the end\n",
    "- Do not say \"our\" or \"we\"‚Äîthis is for a client\n",
    "- Be specific‚Äîgeneralizations don't help\n",
    "\n",
    "Just provide the title as your response, nothing else.\n",
    "\n",
    "## Good Examples\n",
    "\n",
    "- Square is freezing merchant accounts and holding funds for 90+ days\n",
    "- DoorDash is using vague policies to avoid refunds and shift costs to restaurants\n",
    "- DoorDash is recruiting liquor stores to grow selection and block rivals\n",
    "- Uber Eats is using its scale to pressure restaurants into higher fees\n",
    "\n",
    "## Bad Examples\n",
    "\n",
    "- \"Square is freezing merchant accounts with automated triggers and holding funds for 90+ days to limit fraud risk.\" (too long, includes mechanism)\n",
    "- \"DoorDash: Leveraging Policy Ambiguity to Reduce Payout Exposure\" (jargon, colon format)\n",
    "- \"Aggressively targeting alcohol merchants\" (filler adjective, no company, no consequence)\n",
    "- \"New product features announced.\" (generic, passive, has period)\n",
    "\n",
    "            ---\n",
    "            \n",
    "            ## Brief to Summarize\n",
    "\n",
    "            {row['details']}\n",
    "            \"\"\"\n",
    "        # print(prompt)\n",
    "        tasks.append(fetch_response(prompt, row[\"title\"], row[\"id\"], progress))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "signal_details = await process_all(existing_signals)\n",
    "signal_details_df = pd.DataFrame(signal_details)\n",
    "signal_details_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edecb2e8-08be-41d1-9ee0-c825b2a0715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals updated...\n"
     ]
    }
   ],
   "source": [
    "def update_signal_details(df):\n",
    "    for _, row in df.iterrows():\n",
    "        signal_id = int(row[\"id\"])\n",
    "        output = row[\"response\"]\n",
    "        # summary = row[\"summary\"]\n",
    "\n",
    "        if not signal_id or pd.isna(signal_id):\n",
    "            print(f\"‚ö†Ô∏è Skipping row with no signal_id: {row}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            resp = (\n",
    "                supabase.table(\"signals\")\n",
    "                .update({\n",
    "                        \"title\": output,\n",
    "                        # \"details\": output,\n",
    "                    })\n",
    "                .eq(\"id\", signal_id)\n",
    "                .execute()\n",
    "            )\n",
    "            # print(f\"‚úÖ Updated signal_id {signal_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error updating signal_id {signal_id}: {e}\")\n",
    "\n",
    "# Run updates\n",
    "update_signal_details(signal_details_df)\n",
    "print(\"Signals updated...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a5d41-e768-4edc-8bcc-e5f7bb37280a",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
